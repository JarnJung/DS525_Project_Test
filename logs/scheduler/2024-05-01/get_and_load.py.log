[2024-05-01T00:00:15.543+0000] {processor.py:161} INFO - Started process (PID=19735) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:15.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:00:15.548+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:00:15.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:15.572+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:00:15.568+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:00:15.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:15.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.112 seconds
[2024-05-01T00:00:46.561+0000] {processor.py:161} INFO - Started process (PID=19766) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:46.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:00:46.566+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:00:46.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:46.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:00:46.586+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:00:46.592+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:00:46.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:01:17.576+0000] {processor.py:161} INFO - Started process (PID=19797) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:17.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:01:17.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:01:17.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:17.606+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:01:17.601+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:01:17.607+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:17.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:01:48.558+0000] {processor.py:161} INFO - Started process (PID=19828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:48.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:01:48.565+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:01:48.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:48.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:01:48.585+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:01:48.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:01:48.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:02:19.258+0000] {processor.py:161} INFO - Started process (PID=19859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:19.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:02:19.264+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:02:19.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:19.289+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:02:19.284+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:02:19.290+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:19.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:02:50.246+0000] {processor.py:161} INFO - Started process (PID=19890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:50.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:02:50.251+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:02:50.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:50.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:02:50.270+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:02:50.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:02:50.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:03:21.361+0000] {processor.py:161} INFO - Started process (PID=19921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:21.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:03:21.367+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:03:21.366+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:21.392+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:03:21.387+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:03:21.393+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:21.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:03:52.423+0000] {processor.py:161} INFO - Started process (PID=19951) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:52.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:03:52.431+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:03:52.430+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:52.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:03:52.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:03:52.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:03:52.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T00:04:23.407+0000] {processor.py:161} INFO - Started process (PID=19982) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:23.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:04:23.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:04:23.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:23.437+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:04:23.433+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:04:23.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:23.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:04:54.205+0000] {processor.py:161} INFO - Started process (PID=20013) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:54.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:04:54.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:04:54.209+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:54.234+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:04:54.230+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:04:54.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:04:54.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T00:05:25.204+0000] {processor.py:161} INFO - Started process (PID=20044) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:25.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:05:25.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:05:25.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:25.240+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:05:25.235+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:05:25.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:25.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T00:05:56.171+0000] {processor.py:161} INFO - Started process (PID=20075) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:56.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:05:56.177+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:05:56.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:56.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:05:56.196+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:05:56.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:05:56.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:06:27.142+0000] {processor.py:161} INFO - Started process (PID=20112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:27.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:06:27.148+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:06:27.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:27.172+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:06:27.167+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:06:27.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:27.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:06:58.108+0000] {processor.py:161} INFO - Started process (PID=20143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:58.111+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:06:58.113+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:06:58.112+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:58.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:06:58.133+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:06:58.139+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:06:58.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:07:29.198+0000] {processor.py:161} INFO - Started process (PID=20174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:07:29.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:07:29.205+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:07:29.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:07:29.231+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:07:29.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:07:29.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:07:29.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T00:08:00.187+0000] {processor.py:161} INFO - Started process (PID=20205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:00.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:08:00.193+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:08:00.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:00.217+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:08:00.212+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:08:00.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:00.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:08:31.202+0000] {processor.py:161} INFO - Started process (PID=20236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:31.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:08:31.208+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:08:31.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:31.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:08:31.228+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:08:31.233+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:08:31.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:09:02.208+0000] {processor.py:161} INFO - Started process (PID=20268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:02.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:09:02.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:09:02.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:02.237+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:09:02.232+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:09:02.238+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:02.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T00:09:33.267+0000] {processor.py:161} INFO - Started process (PID=20299) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:33.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:09:33.273+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:09:33.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:33.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:09:33.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:09:33.298+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:09:33.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:10:04.327+0000] {processor.py:161} INFO - Started process (PID=20329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:04.331+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:10:04.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:10:04.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:04.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:10:04.353+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:10:04.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:04.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:10:35.306+0000] {processor.py:161} INFO - Started process (PID=20360) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:35.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:10:35.312+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:10:35.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:35.337+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:10:35.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:10:35.338+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:10:35.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:11:06.304+0000] {processor.py:161} INFO - Started process (PID=20391) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:06.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:11:06.310+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:11:06.309+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:06.334+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:11:06.329+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:11:06.335+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:06.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:11:37.397+0000] {processor.py:161} INFO - Started process (PID=20422) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:37.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:11:37.403+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:11:37.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:37.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:11:37.422+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:11:37.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:11:37.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:12:08.392+0000] {processor.py:161} INFO - Started process (PID=20454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:08.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:12:08.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:12:08.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:08.423+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:12:08.418+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:12:08.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:08.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:12:39.386+0000] {processor.py:161} INFO - Started process (PID=20485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:39.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:12:39.392+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:12:39.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:39.417+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:12:39.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:12:39.418+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:12:39.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:13:10.392+0000] {processor.py:161} INFO - Started process (PID=20516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:10.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:13:10.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:13:10.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:10.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:13:10.422+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:13:10.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:10.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T00:13:41.366+0000] {processor.py:161} INFO - Started process (PID=20547) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:41.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:13:41.371+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:13:41.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:41.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:13:41.391+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:13:41.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:13:41.447+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:14:12.370+0000] {processor.py:161} INFO - Started process (PID=20578) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:12.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:14:12.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:14:12.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:12.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:14:12.394+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:14:12.399+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:12.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:14:43.390+0000] {processor.py:161} INFO - Started process (PID=20609) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:43.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:14:43.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:14:43.394+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:43.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:14:43.414+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:14:43.420+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:14:43.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:15:14.464+0000] {processor.py:161} INFO - Started process (PID=20642) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:14.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:15:14.471+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:15:14.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:14.498+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:15:14.492+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:15:14.499+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:14.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T00:15:45.455+0000] {processor.py:161} INFO - Started process (PID=20673) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:45.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:15:45.466+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:15:45.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:45.497+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:15:45.491+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:15:45.498+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:15:45.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.113 seconds
[2024-05-01T00:16:16.425+0000] {processor.py:161} INFO - Started process (PID=20704) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:16.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:16:16.430+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:16:16.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:16.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:16:16.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:16:16.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:16.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:16:47.433+0000] {processor.py:161} INFO - Started process (PID=20735) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:47.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:16:47.439+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:16:47.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:47.463+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:16:47.459+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:16:47.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:16:47.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T00:17:18.424+0000] {processor.py:161} INFO - Started process (PID=20766) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:18.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:17:18.430+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:17:18.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:18.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:17:18.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:17:18.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:18.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:17:49.461+0000] {processor.py:161} INFO - Started process (PID=20797) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:49.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:17:49.466+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:17:49.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:49.490+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:17:49.485+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:17:49.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:17:49.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:18:20.499+0000] {processor.py:161} INFO - Started process (PID=20828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:20.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:18:20.505+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:18:20.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:20.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:18:20.524+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:18:20.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:20.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:18:51.538+0000] {processor.py:161} INFO - Started process (PID=20859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:51.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:18:51.544+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:18:51.543+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:51.568+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:18:51.564+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:18:51.569+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:18:51.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:19:22.525+0000] {processor.py:161} INFO - Started process (PID=20890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:22.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:19:22.531+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:19:22.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:22.555+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:19:22.551+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:19:22.556+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:22.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:19:53.574+0000] {processor.py:161} INFO - Started process (PID=20921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:53.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:19:53.581+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:19:53.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:53.607+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:19:53.602+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:19:53.609+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:19:53.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T00:20:24.354+0000] {processor.py:161} INFO - Started process (PID=20952) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:24.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:20:24.363+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:20:24.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:24.387+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:20:24.383+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:20:24.388+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:24.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T00:20:55.376+0000] {processor.py:161} INFO - Started process (PID=20983) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:55.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:20:55.382+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:20:55.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:55.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:20:55.401+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:20:55.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:20:55.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:21:26.402+0000] {processor.py:161} INFO - Started process (PID=21014) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:26.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:21:26.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:21:26.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:26.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:21:26.429+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:21:26.435+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:26.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T00:21:57.407+0000] {processor.py:161} INFO - Started process (PID=21045) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:57.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:21:57.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:21:57.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:57.437+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:21:57.432+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:21:57.438+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:21:57.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:22:28.448+0000] {processor.py:161} INFO - Started process (PID=21076) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:28.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:22:28.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:22:28.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:28.479+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:22:28.474+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:22:28.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:28.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T00:22:59.125+0000] {processor.py:161} INFO - Started process (PID=21107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:59.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:22:59.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:22:59.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:59.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:22:59.151+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:22:59.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:22:59.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:23:30.133+0000] {processor.py:161} INFO - Started process (PID=21138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:23:30.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:23:30.139+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:23:30.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:23:30.163+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:23:30.158+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:23:30.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:23:30.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:24:00.846+0000] {processor.py:161} INFO - Started process (PID=21169) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:00.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:24:00.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:24:00.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:00.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:24:00.871+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:24:00.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:00.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:24:31.902+0000] {processor.py:161} INFO - Started process (PID=21200) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:31.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:24:31.908+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:24:31.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:31.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:24:31.927+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:24:31.933+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:24:31.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T00:25:02.935+0000] {processor.py:161} INFO - Started process (PID=21237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:02.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:25:02.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:25:02.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:02.965+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:25:02.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:25:02.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:03.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:25:33.627+0000] {processor.py:161} INFO - Started process (PID=21268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:33.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:25:33.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:25:33.632+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:33.657+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:25:33.653+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:25:33.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:25:33.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T00:26:04.596+0000] {processor.py:161} INFO - Started process (PID=21299) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:04.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:26:04.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:26:04.601+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:04.626+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:26:04.621+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:26:04.627+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:04.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:26:35.579+0000] {processor.py:161} INFO - Started process (PID=21330) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:35.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:26:35.584+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:26:35.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:35.608+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:26:35.604+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:26:35.609+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:26:35.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:27:06.296+0000] {processor.py:161} INFO - Started process (PID=21361) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:06.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:27:06.302+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:27:06.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:06.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:27:06.322+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:27:06.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:06.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T00:27:37.379+0000] {processor.py:161} INFO - Started process (PID=21392) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:37.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:27:37.384+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:27:37.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:37.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:27:37.404+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:27:37.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:27:37.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.117 seconds
[2024-05-01T00:28:08.177+0000] {processor.py:161} INFO - Started process (PID=21423) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:08.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:28:08.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:28:08.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:08.207+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:28:08.202+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:28:08.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:08.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:28:39.174+0000] {processor.py:161} INFO - Started process (PID=21454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:39.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:28:39.180+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:28:39.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:39.204+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:28:39.200+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:28:39.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:28:39.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:29:10.156+0000] {processor.py:161} INFO - Started process (PID=21485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:10.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:29:10.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:29:10.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:10.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:29:10.181+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:29:10.187+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:10.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T00:29:41.194+0000] {processor.py:161} INFO - Started process (PID=21516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:41.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:29:41.202+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:29:41.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:41.233+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:29:41.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:29:41.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:29:41.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T00:30:11.990+0000] {processor.py:161} INFO - Started process (PID=21549) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:11.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:30:11.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:30:11.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:12.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:30:12.014+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:30:12.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:12.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T00:30:43.028+0000] {processor.py:161} INFO - Started process (PID=21580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:43.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:30:43.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:30:43.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:43.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:30:43.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:30:43.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:30:43.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:31:14.018+0000] {processor.py:161} INFO - Started process (PID=21611) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:14.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:31:14.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:31:14.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:14.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:31:14.045+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:31:14.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:14.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:31:45.025+0000] {processor.py:161} INFO - Started process (PID=21642) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:45.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:31:45.031+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:31:45.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:45.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:31:45.050+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:31:45.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:31:45.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:32:16.057+0000] {processor.py:161} INFO - Started process (PID=21674) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:16.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:32:16.062+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:32:16.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:16.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:32:16.082+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:32:16.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:16.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:32:47.051+0000] {processor.py:161} INFO - Started process (PID=21705) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:47.054+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:32:47.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:32:47.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:47.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:32:47.077+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:32:47.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:32:47.136+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:33:18.098+0000] {processor.py:161} INFO - Started process (PID=21736) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:18.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:33:18.103+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:33:18.102+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:18.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:33:18.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:33:18.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:18.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:33:49.161+0000] {processor.py:161} INFO - Started process (PID=21767) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:49.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:33:49.168+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:33:49.166+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:49.195+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:33:49.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:33:49.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:33:49.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T00:34:20.150+0000] {processor.py:161} INFO - Started process (PID=21798) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:20.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:34:20.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:34:20.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:20.180+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:34:20.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:34:20.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:20.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T00:34:51.240+0000] {processor.py:161} INFO - Started process (PID=21829) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:51.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:34:51.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:34:51.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:51.270+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:34:51.266+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:34:51.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:34:51.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:35:22.264+0000] {processor.py:161} INFO - Started process (PID=21861) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:22.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:35:22.270+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:35:22.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:22.296+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:35:22.292+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:35:22.297+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:22.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:35:53.271+0000] {processor.py:161} INFO - Started process (PID=21892) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:53.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:35:53.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:35:53.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:53.302+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:35:53.297+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:35:53.303+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:35:53.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:36:24.077+0000] {processor.py:161} INFO - Started process (PID=21923) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:24.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:36:24.083+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:36:24.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:24.107+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:36:24.103+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:36:24.108+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:24.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:36:55.094+0000] {processor.py:161} INFO - Started process (PID=21954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:55.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:36:55.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:36:55.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:55.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:36:55.119+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:36:55.125+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:36:55.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:37:26.150+0000] {processor.py:161} INFO - Started process (PID=21985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:26.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:37:26.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:37:26.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:26.196+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:37:26.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:37:26.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:26.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.117 seconds
[2024-05-01T00:37:56.961+0000] {processor.py:161} INFO - Started process (PID=22016) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:56.963+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:37:56.966+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:37:56.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:56.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:37:56.986+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:37:56.991+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:37:57.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T00:38:27.935+0000] {processor.py:161} INFO - Started process (PID=22047) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:27.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:38:27.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:38:27.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:27.965+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:38:27.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:38:27.966+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:28.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:38:58.996+0000] {processor.py:161} INFO - Started process (PID=22078) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:59.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:38:59.003+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:38:59.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:59.029+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:38:59.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:38:59.031+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:38:59.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T00:39:30.100+0000] {processor.py:161} INFO - Started process (PID=22109) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:39:30.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:39:30.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:39:30.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:39:30.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:39:30.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:39:30.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:39:30.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:40:01.210+0000] {processor.py:161} INFO - Started process (PID=22140) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:01.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:40:01.216+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:40:01.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:01.240+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:40:01.235+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:40:01.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:01.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:40:32.236+0000] {processor.py:161} INFO - Started process (PID=22171) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:32.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:40:32.242+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:40:32.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:32.267+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:40:32.262+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:40:32.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:40:32.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:41:03.270+0000] {processor.py:161} INFO - Started process (PID=22202) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:03.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:41:03.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:41:03.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:03.301+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:41:03.296+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:41:03.302+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:03.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:41:34.318+0000] {processor.py:161} INFO - Started process (PID=22232) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:34.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:41:34.328+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:41:34.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:34.364+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:41:34.360+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:41:34.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:41:34.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T00:42:05.363+0000] {processor.py:161} INFO - Started process (PID=22263) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:05.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:42:05.369+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:42:05.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:05.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:42:05.389+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:42:05.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:05.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:42:36.073+0000] {processor.py:161} INFO - Started process (PID=22294) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:36.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:42:36.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:42:36.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:36.104+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:42:36.099+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:42:36.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:42:36.158+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T00:43:07.087+0000] {processor.py:161} INFO - Started process (PID=22325) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:07.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:43:07.092+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:43:07.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:07.116+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:43:07.111+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:43:07.117+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:07.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:43:38.069+0000] {processor.py:161} INFO - Started process (PID=22356) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:38.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:43:38.075+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:43:38.074+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:38.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:43:38.100+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:43:38.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:43:38.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T00:44:09.044+0000] {processor.py:161} INFO - Started process (PID=22393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:09.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:44:09.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:44:09.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:09.074+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:44:09.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:44:09.076+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:09.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:44:40.075+0000] {processor.py:161} INFO - Started process (PID=22424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:40.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:44:40.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:44:40.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:40.109+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:44:40.104+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:44:40.110+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:44:40.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:45:11.208+0000] {processor.py:161} INFO - Started process (PID=22455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:11.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:45:11.214+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:45:11.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:11.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:45:11.238+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:45:11.246+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:11.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.140 seconds
[2024-05-01T00:45:42.070+0000] {processor.py:161} INFO - Started process (PID=22486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:42.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:45:42.076+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:45:42.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:42.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:45:42.095+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:45:42.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:45:42.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:46:13.068+0000] {processor.py:161} INFO - Started process (PID=22517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:13.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:46:13.074+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:46:13.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:13.098+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:46:13.094+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:46:13.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:13.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:46:44.104+0000] {processor.py:161} INFO - Started process (PID=22548) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:44.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:46:44.109+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:46:44.108+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:44.133+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:46:44.128+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:46:44.134+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:46:44.185+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:47:15.256+0000] {processor.py:161} INFO - Started process (PID=22579) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:15.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:47:15.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:47:15.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:15.285+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:47:15.281+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:47:15.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:15.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:47:46.286+0000] {processor.py:161} INFO - Started process (PID=22610) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:46.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:47:46.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:47:46.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:46.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:47:46.312+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:47:46.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:47:46.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:48:17.297+0000] {processor.py:161} INFO - Started process (PID=22641) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:17.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:48:17.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:48:17.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:17.328+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:48:17.323+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:48:17.329+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:17.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:48:48.334+0000] {processor.py:161} INFO - Started process (PID=22672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:48.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:48:48.340+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:48:48.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:48.364+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:48:48.359+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:48:48.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:48:48.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:49:19.376+0000] {processor.py:161} INFO - Started process (PID=22703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:19.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:49:19.382+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:49:19.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:19.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:49:19.401+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:49:19.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:19.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:49:50.452+0000] {processor.py:161} INFO - Started process (PID=22734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:50.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:49:50.458+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:49:50.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:50.482+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:49:50.477+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:49:50.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:49:50.534+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:50:21.403+0000] {processor.py:161} INFO - Started process (PID=22765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:21.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:50:21.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:50:21.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:21.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:50:21.428+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:50:21.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:21.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:50:52.352+0000] {processor.py:161} INFO - Started process (PID=22796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:52.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:50:52.359+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:50:52.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:52.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:50:52.380+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:50:52.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:50:52.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T00:51:23.342+0000] {processor.py:161} INFO - Started process (PID=22828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:23.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:51:23.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:51:23.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:23.379+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:51:23.374+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:51:23.380+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:23.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T00:51:54.377+0000] {processor.py:161} INFO - Started process (PID=22859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:54.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:51:54.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:51:54.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:54.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:51:54.404+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:51:54.410+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:51:54.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T00:52:25.381+0000] {processor.py:161} INFO - Started process (PID=22890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:25.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:52:25.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:52:25.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:25.411+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:52:25.406+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:52:25.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:25.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:52:56.483+0000] {processor.py:161} INFO - Started process (PID=22921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:56.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:52:56.490+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:52:56.488+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:56.514+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:52:56.510+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:52:56.515+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:52:56.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T00:53:27.445+0000] {processor.py:161} INFO - Started process (PID=22952) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:27.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:53:27.451+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:53:27.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:27.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:53:27.471+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:53:27.477+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:27.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:53:58.425+0000] {processor.py:161} INFO - Started process (PID=22984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:58.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:53:58.431+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:53:58.430+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:58.456+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:53:58.451+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:53:58.457+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:53:58.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:54:29.436+0000] {processor.py:161} INFO - Started process (PID=23015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:29.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:54:29.442+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:54:29.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:29.465+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:54:29.461+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:54:29.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:29.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:54:59.621+0000] {processor.py:161} INFO - Started process (PID=23046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:59.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:54:59.627+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:54:59.626+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:59.651+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:54:59.646+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:54:59.652+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:54:59.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:55:30.616+0000] {processor.py:161} INFO - Started process (PID=23077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:55:30.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:55:30.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:55:30.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:55:30.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:55:30.642+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:55:30.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:55:30.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:56:01.557+0000] {processor.py:161} INFO - Started process (PID=23108) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:01.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:56:01.563+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:56:01.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:01.587+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:56:01.582+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:56:01.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:01.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:56:32.645+0000] {processor.py:161} INFO - Started process (PID=23139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:32.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:56:32.651+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:56:32.650+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:32.675+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:56:32.670+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:56:32.676+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:56:32.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T00:57:03.665+0000] {processor.py:161} INFO - Started process (PID=23170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:03.669+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:57:03.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:57:03.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:03.696+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:57:03.691+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:57:03.697+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:03.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:57:34.635+0000] {processor.py:161} INFO - Started process (PID=23200) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:34.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:57:34.641+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:57:34.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:34.665+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:57:34.661+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:57:34.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:57:34.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T00:58:05.650+0000] {processor.py:161} INFO - Started process (PID=23231) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:05.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:58:05.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:58:05.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:05.680+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:58:05.676+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:58:05.682+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:05.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T00:58:36.716+0000] {processor.py:161} INFO - Started process (PID=23262) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:36.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:58:36.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:58:36.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:36.746+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:58:36.741+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:58:36.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:58:36.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T00:59:07.721+0000] {processor.py:161} INFO - Started process (PID=23293) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:07.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:59:07.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:59:07.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:07.750+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:59:07.745+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:59:07.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:07.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T00:59:38.707+0000] {processor.py:161} INFO - Started process (PID=23324) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:38.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T00:59:38.714+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:59:38.713+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:38.745+0000] {logging_mixin.py:188} INFO - [2024-05-01T00:59:38.739+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T00:59:38.746+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T00:59:38.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T01:00:09.765+0000] {processor.py:161} INFO - Started process (PID=23355) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:09.768+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:00:09.771+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:00:09.770+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:09.795+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:00:09.790+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:00:09.801+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:09.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T01:00:40.831+0000] {processor.py:161} INFO - Started process (PID=23386) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:40.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:00:40.842+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:00:40.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:40.875+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:00:40.869+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:00:40.876+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:00:40.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.117 seconds
[2024-05-01T01:01:11.847+0000] {processor.py:161} INFO - Started process (PID=23417) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:11.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:01:11.853+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:01:11.852+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:11.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:01:11.873+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:01:11.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:11.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:01:42.868+0000] {processor.py:161} INFO - Started process (PID=23448) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:42.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:01:42.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:01:42.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:42.898+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:01:42.893+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:01:42.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:01:42.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T01:02:13.865+0000] {processor.py:161} INFO - Started process (PID=23479) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:13.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:02:13.871+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:02:13.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:13.896+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:02:13.891+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:02:13.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:13.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:02:44.888+0000] {processor.py:161} INFO - Started process (PID=23516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:44.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:02:44.896+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:02:44.894+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:44.922+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:02:44.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:02:44.923+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:02:44.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T01:03:15.881+0000] {processor.py:161} INFO - Started process (PID=23547) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:15.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:03:15.886+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:03:15.885+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:15.910+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:03:15.905+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:03:15.911+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:15.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T01:03:46.916+0000] {processor.py:161} INFO - Started process (PID=23578) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:46.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:03:46.922+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:03:46.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:46.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:03:46.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:03:46.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:03:46.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:04:17.892+0000] {processor.py:161} INFO - Started process (PID=23609) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:17.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:04:17.897+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:04:17.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:17.926+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:04:17.920+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:04:17.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:17.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T01:04:48.919+0000] {processor.py:161} INFO - Started process (PID=23640) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:48.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:04:48.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:04:48.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:48.964+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:04:48.959+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:04:48.965+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:04:49.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.119 seconds
[2024-05-01T01:05:20.000+0000] {processor.py:161} INFO - Started process (PID=23671) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:20.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:05:20.006+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:05:20.005+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:20.030+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:05:20.025+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:05:20.031+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:20.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:05:51.007+0000] {processor.py:161} INFO - Started process (PID=23702) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:51.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:05:51.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:05:51.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:51.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:05:51.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:05:51.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:05:51.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:06:22.047+0000] {processor.py:161} INFO - Started process (PID=23733) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:22.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:06:22.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:06:22.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:22.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:06:22.073+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:06:22.078+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:22.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:06:53.024+0000] {processor.py:161} INFO - Started process (PID=23764) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:53.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:06:53.030+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:06:53.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:53.054+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:06:53.049+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:06:53.055+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:06:53.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:07:24.014+0000] {processor.py:161} INFO - Started process (PID=23795) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:24.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:07:24.020+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:07:24.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:24.044+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:07:24.039+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:07:24.045+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:24.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:07:55.113+0000] {processor.py:161} INFO - Started process (PID=23826) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:55.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:07:55.120+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:07:55.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:55.148+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:07:55.142+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:07:55.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:07:55.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T01:08:26.120+0000] {processor.py:161} INFO - Started process (PID=23857) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:26.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:08:26.126+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:08:26.125+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:26.150+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:08:26.146+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:08:26.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:26.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:08:57.085+0000] {processor.py:161} INFO - Started process (PID=23888) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:57.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:08:57.092+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:08:57.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:57.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:08:57.112+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:08:57.118+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:08:57.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:09:28.177+0000] {processor.py:161} INFO - Started process (PID=23919) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:28.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:09:28.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:09:28.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:28.207+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:09:28.202+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:09:28.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:28.259+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:09:58.869+0000] {processor.py:161} INFO - Started process (PID=23950) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:58.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:09:58.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:09:58.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:58.900+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:09:58.895+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:09:58.901+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:09:58.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:10:29.859+0000] {processor.py:161} INFO - Started process (PID=23981) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:10:29.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:10:29.867+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:10:29.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:10:29.894+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:10:29.889+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:10:29.895+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:10:29.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T01:11:00.828+0000] {processor.py:161} INFO - Started process (PID=24012) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:00.831+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:11:00.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:11:00.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:00.857+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:11:00.853+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:11:00.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:00.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:11:31.893+0000] {processor.py:161} INFO - Started process (PID=24044) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:31.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:11:31.900+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:11:31.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:31.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:11:31.919+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:11:31.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:11:31.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:12:02.886+0000] {processor.py:161} INFO - Started process (PID=24076) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:02.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:12:02.893+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:12:02.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:02.920+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:12:02.914+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:12:02.921+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:02.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T01:12:33.868+0000] {processor.py:161} INFO - Started process (PID=24107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:33.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:12:33.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:12:33.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:33.898+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:12:33.893+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:12:33.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:12:33.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:13:04.875+0000] {processor.py:161} INFO - Started process (PID=24138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:04.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:13:04.880+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:13:04.879+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:04.904+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:13:04.899+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:13:04.905+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:04.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:13:35.908+0000] {processor.py:161} INFO - Started process (PID=24169) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:35.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:13:35.918+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:13:35.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:35.946+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:13:35.941+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:13:35.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:13:36.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.107 seconds
[2024-05-01T01:14:06.574+0000] {processor.py:161} INFO - Started process (PID=24200) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:06.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:14:06.579+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:14:06.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:06.603+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:14:06.599+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:14:06.605+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:06.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T01:14:37.629+0000] {processor.py:161} INFO - Started process (PID=24231) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:37.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:14:37.637+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:14:37.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:37.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:14:37.662+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:14:37.668+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:14:37.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T01:15:08.704+0000] {processor.py:161} INFO - Started process (PID=24266) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:08.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:15:08.710+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:15:08.709+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:08.734+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:15:08.729+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:15:08.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:08.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:15:39.694+0000] {processor.py:161} INFO - Started process (PID=24297) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:39.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:15:39.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:15:39.699+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:39.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:15:39.719+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:15:39.725+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:15:39.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:16:10.657+0000] {processor.py:161} INFO - Started process (PID=24328) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:10.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:16:10.663+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:16:10.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:10.687+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:16:10.682+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:16:10.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:10.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:16:41.648+0000] {processor.py:161} INFO - Started process (PID=24359) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:41.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:16:41.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:16:41.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:41.678+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:16:41.673+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:16:41.679+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:16:41.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:17:12.423+0000] {processor.py:161} INFO - Started process (PID=24390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:12.426+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:17:12.429+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:17:12.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:12.453+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:17:12.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:17:12.454+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:12.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:17:43.492+0000] {processor.py:161} INFO - Started process (PID=24421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:43.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:17:43.501+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:17:43.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:43.525+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:17:43.521+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:17:43.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:17:43.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:18:14.500+0000] {processor.py:161} INFO - Started process (PID=24453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:14.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:18:14.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:18:14.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:14.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:18:14.527+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:18:14.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:14.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:18:45.640+0000] {processor.py:161} INFO - Started process (PID=24485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:45.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:18:45.653+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:18:45.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:45.689+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:18:45.684+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:18:45.690+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:18:45.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.121 seconds
[2024-05-01T01:19:16.691+0000] {processor.py:161} INFO - Started process (PID=24516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:16.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:19:16.697+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:19:16.696+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:16.721+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:19:16.716+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:19:16.722+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:16.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:19:47.763+0000] {processor.py:161} INFO - Started process (PID=24546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:47.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:19:47.769+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:19:47.768+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:47.793+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:19:47.788+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:19:47.794+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:19:47.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:20:18.792+0000] {processor.py:161} INFO - Started process (PID=24577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:18.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:20:18.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:20:18.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:18.821+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:20:18.817+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:20:18.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:18.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:20:49.764+0000] {processor.py:161} INFO - Started process (PID=24609) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:49.767+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:20:49.770+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:20:49.769+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:49.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:20:49.790+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:20:49.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:20:49.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:21:20.805+0000] {processor.py:161} INFO - Started process (PID=24647) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:20.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:21:20.811+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:21:20.810+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:20.835+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:21:20.830+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:21:20.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:20.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:21:51.774+0000] {processor.py:161} INFO - Started process (PID=24678) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:51.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:21:51.780+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:21:51.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:51.804+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:21:51.800+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:21:51.806+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:21:51.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:22:22.800+0000] {processor.py:161} INFO - Started process (PID=24710) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:22.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:22:22.806+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:22:22.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:22.830+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:22:22.825+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:22:22.831+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:22.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:22:53.496+0000] {processor.py:161} INFO - Started process (PID=24741) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:53.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:22:53.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:22:53.502+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:53.530+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:22:53.525+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:22:53.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:22:53.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T01:23:24.511+0000] {processor.py:161} INFO - Started process (PID=24772) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:24.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:23:24.517+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:23:24.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:24.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:23:24.537+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:23:24.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:24.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:23:55.488+0000] {processor.py:161} INFO - Started process (PID=24803) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:55.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:23:55.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:23:55.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:55.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:23:55.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:23:55.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:23:55.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:24:26.488+0000] {processor.py:161} INFO - Started process (PID=24834) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:26.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:24:26.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:24:26.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:26.521+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:24:26.516+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:24:26.523+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:26.579+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T01:24:57.655+0000] {processor.py:161} INFO - Started process (PID=24865) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:57.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:24:57.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:24:57.665+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:57.707+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:24:57.701+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:24:57.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:24:57.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.125 seconds
[2024-05-01T01:25:28.430+0000] {processor.py:161} INFO - Started process (PID=24896) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:28.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:25:28.439+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:25:28.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:28.462+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:25:28.458+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:25:28.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:28.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T01:25:59.398+0000] {processor.py:161} INFO - Started process (PID=24927) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:59.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:25:59.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:25:59.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:59.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:25:59.428+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:25:59.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:25:59.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T01:26:30.422+0000] {processor.py:161} INFO - Started process (PID=24958) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:26:30.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:26:30.428+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:26:30.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:26:30.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:26:30.449+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:26:30.456+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:26:30.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T01:27:01.495+0000] {processor.py:161} INFO - Started process (PID=24989) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:01.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:27:01.501+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:27:01.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:01.525+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:27:01.520+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:27:01.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:01.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T01:27:32.562+0000] {processor.py:161} INFO - Started process (PID=25020) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:32.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:27:32.568+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:27:32.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:32.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:27:32.587+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:27:32.593+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:27:32.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:28:03.544+0000] {processor.py:161} INFO - Started process (PID=25051) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:03.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:28:03.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:28:03.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:03.573+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:28:03.568+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:28:03.574+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:03.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:28:34.523+0000] {processor.py:161} INFO - Started process (PID=25082) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:34.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:28:34.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:28:34.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:34.553+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:28:34.548+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:28:34.554+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:28:34.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:29:05.514+0000] {processor.py:161} INFO - Started process (PID=25113) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:05.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:29:05.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:29:05.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:05.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:29:05.538+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:29:05.544+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:05.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:29:36.641+0000] {processor.py:161} INFO - Started process (PID=25144) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:36.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:29:36.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:29:36.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:36.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:29:36.667+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:29:36.673+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:29:36.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T01:30:07.330+0000] {processor.py:161} INFO - Started process (PID=25175) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:07.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:30:07.337+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:30:07.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:07.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:30:07.356+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:30:07.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:07.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:30:38.337+0000] {processor.py:161} INFO - Started process (PID=25206) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:38.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:30:38.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:30:38.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:38.368+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:30:38.363+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:30:38.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:30:38.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:31:09.367+0000] {processor.py:161} INFO - Started process (PID=25237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:09.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:31:09.373+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:31:09.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:09.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:31:09.394+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:31:09.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:09.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T01:31:40.360+0000] {processor.py:161} INFO - Started process (PID=25268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:40.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:31:40.366+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:31:40.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:40.390+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:31:40.385+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:31:40.391+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:31:40.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:32:11.104+0000] {processor.py:161} INFO - Started process (PID=25299) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:11.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:32:11.110+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:32:11.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:11.134+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:32:11.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:32:11.135+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:11.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:32:42.123+0000] {processor.py:161} INFO - Started process (PID=25331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:42.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:32:42.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:32:42.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:42.153+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:32:42.148+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:32:42.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:32:42.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:33:13.085+0000] {processor.py:161} INFO - Started process (PID=25363) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:13.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:33:13.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:33:13.089+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:13.114+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:33:13.109+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:33:13.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:13.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:33:44.054+0000] {processor.py:161} INFO - Started process (PID=25394) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:44.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:33:44.060+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:33:44.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:44.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:33:44.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:33:44.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:33:44.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T01:34:15.007+0000] {processor.py:161} INFO - Started process (PID=25425) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:15.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:34:15.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:34:15.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:15.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:34:15.032+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:34:15.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:15.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:34:46.008+0000] {processor.py:161} INFO - Started process (PID=25456) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:46.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:34:46.014+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:34:46.013+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:46.038+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:34:46.034+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:34:46.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:34:46.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:35:17.083+0000] {processor.py:161} INFO - Started process (PID=25488) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:17.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:35:17.089+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:35:17.088+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:17.113+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:35:17.108+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:35:17.114+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:17.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:35:48.105+0000] {processor.py:161} INFO - Started process (PID=25519) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:48.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:35:48.111+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:35:48.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:48.134+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:35:48.130+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:35:48.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:35:48.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:36:19.120+0000] {processor.py:161} INFO - Started process (PID=25550) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:19.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:36:19.126+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:36:19.125+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:19.150+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:36:19.145+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:36:19.151+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:19.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T01:36:50.182+0000] {processor.py:161} INFO - Started process (PID=25581) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:50.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:36:50.188+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:36:50.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:50.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:36:50.207+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:36:50.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:36:50.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:37:21.293+0000] {processor.py:161} INFO - Started process (PID=25612) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:21.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:37:21.302+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:37:21.301+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:21.326+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:37:21.321+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:37:21.327+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:21.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T01:37:52.301+0000] {processor.py:161} INFO - Started process (PID=25643) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:52.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:37:52.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:37:52.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:52.335+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:37:52.330+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:37:52.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:37:52.387+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T01:38:23.355+0000] {processor.py:161} INFO - Started process (PID=25674) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:23.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:38:23.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:38:23.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:23.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:38:23.380+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:38:23.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:23.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:38:54.351+0000] {processor.py:161} INFO - Started process (PID=25705) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:54.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:38:54.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:38:54.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:54.381+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:38:54.376+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:38:54.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:38:54.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:39:25.354+0000] {processor.py:161} INFO - Started process (PID=25736) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:25.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:39:25.360+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:39:25.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:25.384+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:39:25.379+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:39:25.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:25.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:39:56.475+0000] {processor.py:161} INFO - Started process (PID=25773) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:56.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:39:56.485+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:39:56.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:56.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:39:56.507+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:39:56.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:39:56.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T01:40:27.540+0000] {processor.py:161} INFO - Started process (PID=25804) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:27.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:40:27.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:40:27.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:27.569+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:40:27.564+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:40:27.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:27.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:40:58.562+0000] {processor.py:161} INFO - Started process (PID=25835) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:58.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:40:58.569+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:40:58.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:58.596+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:40:58.591+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:40:58.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:40:58.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T01:41:29.525+0000] {processor.py:161} INFO - Started process (PID=25866) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:41:29.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:41:29.530+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:41:29.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:41:29.554+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:41:29.549+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:41:29.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:41:29.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:42:00.501+0000] {processor.py:161} INFO - Started process (PID=25897) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:00.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:42:00.507+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:42:00.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:00.531+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:42:00.526+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:42:00.532+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:00.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:42:31.538+0000] {processor.py:161} INFO - Started process (PID=25928) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:31.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:42:31.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:42:31.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:31.567+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:42:31.562+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:42:31.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:42:31.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:43:02.526+0000] {processor.py:161} INFO - Started process (PID=25959) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:02.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:43:02.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:43:02.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:02.556+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:43:02.551+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:43:02.557+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:02.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T01:43:33.577+0000] {processor.py:161} INFO - Started process (PID=25990) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:33.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:43:33.584+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:43:33.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:33.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:43:33.608+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:43:33.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:43:33.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T01:44:04.591+0000] {processor.py:161} INFO - Started process (PID=26021) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:04.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:44:04.597+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:44:04.596+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:04.620+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:44:04.616+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:44:04.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:04.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:44:35.589+0000] {processor.py:161} INFO - Started process (PID=26052) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:35.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:44:35.594+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:44:35.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:35.618+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:44:35.613+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:44:35.619+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:44:35.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T01:45:06.451+0000] {processor.py:161} INFO - Started process (PID=26083) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:06.454+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:45:06.457+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:45:06.456+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:06.481+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:45:06.476+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:45:06.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:06.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:45:37.433+0000] {processor.py:161} INFO - Started process (PID=26114) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:37.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:45:37.438+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:45:37.437+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:37.462+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:45:37.457+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:45:37.463+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:45:37.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:46:08.493+0000] {processor.py:161} INFO - Started process (PID=26145) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:08.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:46:08.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:46:08.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:08.526+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:46:08.521+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:46:08.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:08.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.115 seconds
[2024-05-01T01:46:39.498+0000] {processor.py:161} INFO - Started process (PID=26176) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:39.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:46:39.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:46:39.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:39.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:46:39.534+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:46:39.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:46:39.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T01:47:10.482+0000] {processor.py:161} INFO - Started process (PID=26207) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:10.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:47:10.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:47:10.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:10.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:47:10.508+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:47:10.515+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:10.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T01:47:41.531+0000] {processor.py:161} INFO - Started process (PID=26238) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:41.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:47:41.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:47:41.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:41.561+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:47:41.556+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:47:41.562+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:47:41.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T01:48:12.500+0000] {processor.py:161} INFO - Started process (PID=26269) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:12.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:48:12.506+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:48:12.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:12.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:48:12.525+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:48:12.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:12.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:48:43.516+0000] {processor.py:161} INFO - Started process (PID=26300) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:43.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:48:43.522+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:48:43.521+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:43.546+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:48:43.541+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:48:43.547+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:48:43.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:49:14.584+0000] {processor.py:161} INFO - Started process (PID=26331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:14.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:49:14.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:49:14.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:14.614+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:49:14.610+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:49:14.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:14.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T01:49:45.607+0000] {processor.py:161} INFO - Started process (PID=26362) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:45.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:49:45.613+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:49:45.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:45.637+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:49:45.633+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:49:45.638+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:49:45.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:50:16.709+0000] {processor.py:161} INFO - Started process (PID=26393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:16.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:50:16.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:50:16.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:16.739+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:50:16.734+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:50:16.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:16.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:50:47.735+0000] {processor.py:161} INFO - Started process (PID=26424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:47.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:50:47.740+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:50:47.739+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:47.765+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:50:47.760+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:50:47.766+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:50:47.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:51:18.722+0000] {processor.py:161} INFO - Started process (PID=26455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:18.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:51:18.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:51:18.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:18.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:51:18.748+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:51:18.754+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:18.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:51:49.768+0000] {processor.py:161} INFO - Started process (PID=26486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:49.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:51:49.773+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:51:49.772+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:49.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:51:49.792+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:51:49.798+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:51:49.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:52:20.813+0000] {processor.py:161} INFO - Started process (PID=26517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:20.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:52:20.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:52:20.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:20.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:52:20.854+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:52:20.860+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:20.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.114 seconds
[2024-05-01T01:52:51.826+0000] {processor.py:161} INFO - Started process (PID=26548) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:51.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:52:51.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:52:51.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:51.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:52:51.854+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:52:51.860+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:52:51.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T01:53:22.855+0000] {processor.py:161} INFO - Started process (PID=26579) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:22.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:53:22.860+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:53:22.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:22.884+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:53:22.879+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:53:22.885+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:22.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:53:53.865+0000] {processor.py:161} INFO - Started process (PID=26610) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:53.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:53:53.871+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:53:53.870+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:53.895+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:53:53.890+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:53:53.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:53:53.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:54:24.843+0000] {processor.py:161} INFO - Started process (PID=26641) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:24.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:54:24.848+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:54:24.847+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:24.872+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:54:24.867+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:54:24.873+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:24.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T01:54:55.998+0000] {processor.py:161} INFO - Started process (PID=26672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:56.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:54:56.004+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:54:56.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:56.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:54:56.023+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:54:56.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:54:56.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T01:55:26.758+0000] {processor.py:161} INFO - Started process (PID=26703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:26.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:55:26.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:55:26.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:26.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:55:26.786+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:55:26.791+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:26.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.182 seconds
[2024-05-01T01:55:57.781+0000] {processor.py:161} INFO - Started process (PID=26734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:57.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:55:57.787+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:55:57.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:57.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:55:57.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:55:57.812+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:55:57.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.129 seconds
[2024-05-01T01:56:28.813+0000] {processor.py:161} INFO - Started process (PID=26765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:28.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:56:28.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:56:28.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:28.843+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:56:28.838+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:56:28.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:28.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T01:56:59.803+0000] {processor.py:161} INFO - Started process (PID=26796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:59.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:56:59.809+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:56:59.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:59.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:56:59.828+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:56:59.834+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:56:59.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T01:57:30.820+0000] {processor.py:161} INFO - Started process (PID=26827) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:57:30.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:57:30.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:57:30.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:57:30.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:57:30.845+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:57:30.851+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:57:30.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.139 seconds
[2024-05-01T01:58:01.885+0000] {processor.py:161} INFO - Started process (PID=26858) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:01.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:58:01.890+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:58:01.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:01.914+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:58:01.909+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:58:01.915+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:01.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T01:58:32.869+0000] {processor.py:161} INFO - Started process (PID=26895) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:32.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:58:32.875+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:58:32.874+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:32.899+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:58:32.895+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:58:32.900+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:58:32.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T01:59:03.895+0000] {processor.py:161} INFO - Started process (PID=26926) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:03.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:59:03.900+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:59:03.899+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:03.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:59:03.919+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:59:03.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:03.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T01:59:34.966+0000] {processor.py:161} INFO - Started process (PID=26957) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:34.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T01:59:34.972+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:59:34.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:34.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T01:59:34.991+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T01:59:34.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T01:59:35.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T02:00:06.027+0000] {processor.py:161} INFO - Started process (PID=26988) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:06.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:00:06.033+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:00:06.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:06.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:00:06.052+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:00:06.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:06.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:00:37.050+0000] {processor.py:161} INFO - Started process (PID=27019) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:37.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:00:37.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:00:37.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:37.087+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:00:37.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:00:37.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:00:37.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T02:01:08.060+0000] {processor.py:161} INFO - Started process (PID=27050) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:08.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:01:08.066+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:01:08.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:08.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:01:08.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:01:08.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:08.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:01:39.075+0000] {processor.py:161} INFO - Started process (PID=27081) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:39.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:01:39.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:01:39.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:39.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:01:39.101+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:01:39.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:01:39.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:02:10.137+0000] {processor.py:161} INFO - Started process (PID=27112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:10.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:02:10.150+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:02:10.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:10.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:02:10.173+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:02:10.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:10.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.120 seconds
[2024-05-01T02:02:41.146+0000] {processor.py:161} INFO - Started process (PID=27143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:41.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:02:41.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:02:41.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:41.176+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:02:41.172+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:02:41.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:02:41.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:03:12.147+0000] {processor.py:161} INFO - Started process (PID=27174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:12.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:03:12.154+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:03:12.153+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:12.182+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:03:12.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:03:12.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:12.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T02:03:43.139+0000] {processor.py:161} INFO - Started process (PID=27205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:43.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:03:43.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:03:43.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:43.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:03:43.165+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:03:43.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:03:43.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:04:14.209+0000] {processor.py:161} INFO - Started process (PID=27236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:14.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:04:14.215+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:04:14.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:14.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:04:14.234+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:04:14.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:14.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:04:45.172+0000] {processor.py:161} INFO - Started process (PID=27268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:45.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:04:45.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:04:45.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:45.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:04:45.204+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:04:45.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:04:45.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T02:05:15.999+0000] {processor.py:161} INFO - Started process (PID=27300) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:16.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:05:16.005+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:05:16.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:16.029+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:05:16.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:05:16.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:16.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:05:47.051+0000] {processor.py:161} INFO - Started process (PID=27331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:47.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:05:47.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:05:47.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:47.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:05:47.077+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:05:47.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:05:47.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:06:18.127+0000] {processor.py:161} INFO - Started process (PID=27362) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:18.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:06:18.133+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:06:18.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:18.157+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:06:18.152+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:06:18.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:18.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:06:49.227+0000] {processor.py:161} INFO - Started process (PID=27393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:49.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:06:49.233+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:06:49.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:49.257+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:06:49.252+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:06:49.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:06:49.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T02:07:20.269+0000] {processor.py:161} INFO - Started process (PID=27424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:20.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:07:20.312+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:07:20.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:20.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:07:20.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:07:20.338+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:20.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.128 seconds
[2024-05-01T02:07:51.111+0000] {processor.py:161} INFO - Started process (PID=27455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:51.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:07:51.122+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:07:51.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:51.146+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:07:51.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:07:51.147+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:07:51.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T02:08:22.139+0000] {processor.py:161} INFO - Started process (PID=27486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:22.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:08:22.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:08:22.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:22.168+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:08:22.164+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:08:22.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:22.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:08:53.170+0000] {processor.py:161} INFO - Started process (PID=27517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:53.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:08:53.181+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:08:53.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:53.217+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:08:53.212+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:08:53.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:08:53.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.120 seconds
[2024-05-01T02:09:23.952+0000] {processor.py:161} INFO - Started process (PID=27548) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:23.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:09:23.958+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:09:23.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:23.982+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:09:23.977+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:09:23.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:24.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:09:54.992+0000] {processor.py:161} INFO - Started process (PID=27579) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:54.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:09:54.998+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:09:54.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:55.022+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:09:55.018+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:09:55.023+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:09:55.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:10:26.029+0000] {processor.py:161} INFO - Started process (PID=27610) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:26.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:10:26.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:10:26.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:26.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:10:26.054+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:10:26.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:26.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:10:57.037+0000] {processor.py:161} INFO - Started process (PID=27641) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:57.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:10:57.042+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:10:57.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:57.066+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:10:57.062+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:10:57.068+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:10:57.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T02:11:28.007+0000] {processor.py:161} INFO - Started process (PID=27672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:28.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:11:28.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:11:28.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:28.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:11:28.032+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:11:28.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:28.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:11:59.036+0000] {processor.py:161} INFO - Started process (PID=27703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:59.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:11:59.041+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:11:59.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:59.065+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:11:59.060+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:11:59.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:11:59.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:12:30.021+0000] {processor.py:161} INFO - Started process (PID=27734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:12:30.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:12:30.027+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:12:30.026+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:12:30.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:12:30.046+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:12:30.052+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:12:30.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:13:01.012+0000] {processor.py:161} INFO - Started process (PID=27765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:01.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:13:01.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:13:01.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:01.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:13:01.050+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:13:01.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:01.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.115 seconds
[2024-05-01T02:13:32.028+0000] {processor.py:161} INFO - Started process (PID=27796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:32.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:13:32.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:13:32.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:32.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:13:32.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:13:32.059+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:13:32.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.120 seconds
[2024-05-01T02:14:03.100+0000] {processor.py:161} INFO - Started process (PID=27827) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:03.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:14:03.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:14:03.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:03.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:14:03.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:14:03.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:03.181+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:14:34.065+0000] {processor.py:161} INFO - Started process (PID=27859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:34.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:14:34.071+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:14:34.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:34.095+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:14:34.090+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:14:34.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:14:34.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:15:05.073+0000] {processor.py:161} INFO - Started process (PID=27892) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:05.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:15:05.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:15:05.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:05.104+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:15:05.099+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:15:05.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:05.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:15:36.138+0000] {processor.py:161} INFO - Started process (PID=27923) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:36.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:15:36.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:15:36.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:36.168+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:15:36.163+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:15:36.169+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:15:36.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:16:07.180+0000] {processor.py:161} INFO - Started process (PID=27954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:07.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:16:07.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:16:07.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:07.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:16:07.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:16:07.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:07.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:16:38.138+0000] {processor.py:161} INFO - Started process (PID=27991) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:38.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:16:38.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:16:38.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:38.170+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:16:38.166+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:16:38.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:16:38.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:17:09.118+0000] {processor.py:161} INFO - Started process (PID=28022) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:09.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:17:09.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:17:09.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:09.147+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:17:09.143+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:17:09.149+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:09.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:17:39.812+0000] {processor.py:161} INFO - Started process (PID=28053) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:39.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:17:39.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:17:39.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:39.842+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:17:39.837+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:17:39.843+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:17:39.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:18:10.757+0000] {processor.py:161} INFO - Started process (PID=28084) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:10.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:18:10.763+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:18:10.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:10.788+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:18:10.783+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:18:10.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:10.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:18:41.786+0000] {processor.py:161} INFO - Started process (PID=28115) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:41.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:18:41.792+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:18:41.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:41.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:18:41.813+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:18:41.820+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:18:41.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T02:19:12.781+0000] {processor.py:161} INFO - Started process (PID=28146) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:12.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:19:12.786+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:19:12.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:12.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:19:12.805+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:19:12.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:12.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:19:43.754+0000] {processor.py:161} INFO - Started process (PID=28177) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:43.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:19:43.759+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:19:43.758+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:43.783+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:19:43.779+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:19:43.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:19:43.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:20:14.820+0000] {processor.py:161} INFO - Started process (PID=28208) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:14.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:20:14.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:20:14.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:14.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:20:14.846+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:20:14.852+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:14.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:20:45.782+0000] {processor.py:161} INFO - Started process (PID=28239) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:45.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:20:45.788+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:20:45.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:45.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:20:45.808+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:20:45.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:20:45.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:21:16.818+0000] {processor.py:161} INFO - Started process (PID=28270) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:16.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:21:16.824+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:21:16.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:16.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:21:16.844+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:21:16.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:16.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:21:47.796+0000] {processor.py:161} INFO - Started process (PID=28301) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:47.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:21:47.802+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:21:47.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:47.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:21:47.822+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:21:47.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:21:47.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:22:18.793+0000] {processor.py:161} INFO - Started process (PID=28333) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:18.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:22:18.798+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:22:18.797+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:18.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:22:18.818+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:22:18.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:18.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:22:49.791+0000] {processor.py:161} INFO - Started process (PID=28364) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:49.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:22:49.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:22:49.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:49.820+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:22:49.816+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:22:49.822+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:22:49.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:23:20.625+0000] {processor.py:161} INFO - Started process (PID=28395) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:20.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:23:20.632+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:23:20.631+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:20.659+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:23:20.653+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:23:20.660+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:20.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:23:51.606+0000] {processor.py:161} INFO - Started process (PID=28426) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:51.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:23:51.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:23:51.611+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:51.636+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:23:51.631+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:23:51.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:23:51.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:24:22.588+0000] {processor.py:161} INFO - Started process (PID=28457) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:22.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:24:22.593+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:24:22.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:22.618+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:24:22.613+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:24:22.619+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:22.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T02:24:53.642+0000] {processor.py:161} INFO - Started process (PID=28488) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:53.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:24:53.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:24:53.671+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:53.736+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:24:53.724+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:24:53.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:24:53.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.183 seconds
[2024-05-01T02:25:24.729+0000] {processor.py:161} INFO - Started process (PID=28519) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:24.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:25:24.735+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:25:24.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:24.759+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:25:24.754+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:25:24.760+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:24.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T02:25:55.683+0000] {processor.py:161} INFO - Started process (PID=28550) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:55.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:25:55.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:25:55.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:55.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:25:55.708+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:25:55.713+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:25:55.767+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:26:26.739+0000] {processor.py:161} INFO - Started process (PID=28581) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:26.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:26:26.745+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:26:26.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:26.769+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:26:26.764+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:26:26.770+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:26.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:26:57.724+0000] {processor.py:161} INFO - Started process (PID=28612) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:57.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:26:57.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:26:57.729+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:57.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:26:57.749+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:26:57.755+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:26:57.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:27:28.714+0000] {processor.py:161} INFO - Started process (PID=28643) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:28.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:27:28.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:27:28.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:28.747+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:27:28.742+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:27:28.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:28.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:27:59.749+0000] {processor.py:161} INFO - Started process (PID=28674) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:59.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:27:59.755+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:27:59.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:59.779+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:27:59.774+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:27:59.780+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:27:59.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:28:30.847+0000] {processor.py:161} INFO - Started process (PID=28705) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:28:30.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:28:30.853+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:28:30.852+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:28:30.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:28:30.872+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:28:30.878+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:28:30.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:29:01.928+0000] {processor.py:161} INFO - Started process (PID=28736) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:01.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:29:01.934+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:29:01.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:01.958+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:29:01.953+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:29:01.959+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:02.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.149 seconds
[2024-05-01T02:29:32.927+0000] {processor.py:161} INFO - Started process (PID=28767) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:32.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:29:32.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:29:32.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:32.956+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:29:32.952+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:29:32.958+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:29:33.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:30:03.993+0000] {processor.py:161} INFO - Started process (PID=28798) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:03.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:30:03.998+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:30:03.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:04.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:30:04.018+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:30:04.024+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:04.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:30:34.962+0000] {processor.py:161} INFO - Started process (PID=28830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:34.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:30:34.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:30:34.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:34.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:30:34.987+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:30:34.993+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:30:35.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:31:05.979+0000] {processor.py:161} INFO - Started process (PID=28861) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:05.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:31:05.986+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:31:05.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:06.012+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:31:06.006+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:31:06.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:06.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T02:31:36.973+0000] {processor.py:161} INFO - Started process (PID=28891) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:36.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:31:36.978+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:31:36.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:37.003+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:31:36.998+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:31:37.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:31:37.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:32:07.938+0000] {processor.py:161} INFO - Started process (PID=28922) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:07.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:32:07.944+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:32:07.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:07.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:32:07.964+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:32:07.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:08.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:32:39.012+0000] {processor.py:161} INFO - Started process (PID=28953) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:39.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:32:39.018+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:32:39.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:39.042+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:32:39.038+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:32:39.043+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:32:39.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:33:10.097+0000] {processor.py:161} INFO - Started process (PID=28984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:10.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:33:10.103+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:33:10.102+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:10.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:33:10.123+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:33:10.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:10.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T02:33:41.100+0000] {processor.py:161} INFO - Started process (PID=29015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:41.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:33:41.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:33:41.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:41.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:33:41.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:33:41.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:33:41.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:34:12.175+0000] {processor.py:161} INFO - Started process (PID=29046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:12.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:34:12.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:34:12.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:12.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:34:12.205+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:34:12.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:12.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T02:34:43.269+0000] {processor.py:161} INFO - Started process (PID=29077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:43.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:34:43.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:34:43.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:43.299+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:34:43.294+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:34:43.300+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:34:43.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:35:14.303+0000] {processor.py:161} INFO - Started process (PID=29115) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:14.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:35:14.309+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:35:14.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:14.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:35:14.328+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:35:14.334+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:14.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:35:45.324+0000] {processor.py:161} INFO - Started process (PID=29146) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:45.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:35:45.330+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:35:45.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:45.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:35:45.349+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:35:45.355+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:35:45.410+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:36:16.325+0000] {processor.py:161} INFO - Started process (PID=29177) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:16.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:36:16.331+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:36:16.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:16.355+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:36:16.350+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:36:16.356+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:16.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:36:47.124+0000] {processor.py:161} INFO - Started process (PID=29208) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:47.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:36:47.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:36:47.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:47.154+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:36:47.149+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:36:47.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:36:47.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:37:18.180+0000] {processor.py:161} INFO - Started process (PID=29239) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:18.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:37:18.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:37:18.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:18.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:37:18.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:37:18.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:18.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:37:49.236+0000] {processor.py:161} INFO - Started process (PID=29270) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:49.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:37:49.245+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:37:49.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:49.278+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:37:49.274+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:37:49.279+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:37:49.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.113 seconds
[2024-05-01T02:38:19.960+0000] {processor.py:161} INFO - Started process (PID=29302) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:19.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:38:19.966+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:38:19.965+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:19.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:38:19.986+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:38:19.992+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:20.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T02:38:50.949+0000] {processor.py:161} INFO - Started process (PID=29334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:50.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:38:50.954+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:38:50.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:50.978+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:38:50.973+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:38:50.979+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:38:51.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:39:21.916+0000] {processor.py:161} INFO - Started process (PID=29365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:21.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:39:21.922+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:39:21.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:21.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:39:21.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:39:21.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:21.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:39:52.911+0000] {processor.py:161} INFO - Started process (PID=29396) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:52.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:39:52.917+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:39:52.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:52.942+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:39:52.937+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:39:52.943+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:39:52.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:40:23.973+0000] {processor.py:161} INFO - Started process (PID=29427) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:23.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:40:23.979+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:40:23.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:24.003+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:40:23.998+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:40:24.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:24.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:40:54.952+0000] {processor.py:161} INFO - Started process (PID=29458) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:54.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:40:54.958+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:40:54.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:54.982+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:40:54.978+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:40:54.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:40:55.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:41:26.031+0000] {processor.py:161} INFO - Started process (PID=29489) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:26.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:41:26.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:41:26.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:26.061+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:41:26.057+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:41:26.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:26.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:41:57.066+0000] {processor.py:161} INFO - Started process (PID=29520) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:57.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:41:57.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:41:57.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:57.096+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:41:57.092+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:41:57.098+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:41:57.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:42:28.078+0000] {processor.py:161} INFO - Started process (PID=29551) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:28.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:42:28.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:42:28.084+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:28.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:42:28.117+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:42:28.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:28.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.114 seconds
[2024-05-01T02:42:59.134+0000] {processor.py:161} INFO - Started process (PID=29582) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:59.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:42:59.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:42:59.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:59.175+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:42:59.163+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:42:59.179+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:42:59.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T02:43:30.124+0000] {processor.py:161} INFO - Started process (PID=29613) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:43:30.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:43:30.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:43:30.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:43:30.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:43:30.150+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:43:30.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:43:30.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:44:01.194+0000] {processor.py:161} INFO - Started process (PID=29644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:01.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:44:01.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:44:01.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:01.223+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:44:01.219+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:44:01.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:01.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:44:32.153+0000] {processor.py:161} INFO - Started process (PID=29675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:32.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:44:32.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:44:32.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:32.185+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:44:32.180+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:44:32.186+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:44:32.244+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T02:45:03.224+0000] {processor.py:161} INFO - Started process (PID=29706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:03.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:45:03.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:45:03.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:03.254+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:45:03.249+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:45:03.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:03.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:45:34.304+0000] {processor.py:161} INFO - Started process (PID=29737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:34.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:45:34.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:45:34.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:34.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:45:34.331+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:45:34.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:45:34.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T02:46:05.313+0000] {processor.py:161} INFO - Started process (PID=29768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:05.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:46:05.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:46:05.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:05.342+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:46:05.337+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:46:05.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:05.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:46:36.314+0000] {processor.py:161} INFO - Started process (PID=29799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:36.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:46:36.321+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:46:36.319+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:36.347+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:46:36.342+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:46:36.349+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:46:36.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:47:07.282+0000] {processor.py:161} INFO - Started process (PID=29830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:07.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:47:07.287+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:47:07.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:07.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:47:07.306+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:47:07.312+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:07.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T02:47:38.258+0000] {processor.py:161} INFO - Started process (PID=29861) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:38.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:47:38.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:47:38.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:38.287+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:47:38.282+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:47:38.288+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:47:38.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:48:09.301+0000] {processor.py:161} INFO - Started process (PID=29892) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:09.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:48:09.309+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:48:09.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:09.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:48:09.337+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:48:09.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:09.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.145 seconds
[2024-05-01T02:48:40.293+0000] {processor.py:161} INFO - Started process (PID=29923) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:40.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:48:40.299+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:48:40.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:40.323+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:48:40.319+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:48:40.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:48:40.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:49:11.332+0000] {processor.py:161} INFO - Started process (PID=29954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:11.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:49:11.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:49:11.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:11.368+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:49:11.363+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:49:11.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:11.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T02:49:42.342+0000] {processor.py:161} INFO - Started process (PID=29985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:42.346+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:49:42.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:49:42.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:42.372+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:49:42.368+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:49:42.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:49:42.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:50:13.408+0000] {processor.py:161} INFO - Started process (PID=30016) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:13.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:50:13.414+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:50:13.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:13.438+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:50:13.433+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:50:13.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:13.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:50:44.411+0000] {processor.py:161} INFO - Started process (PID=30047) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:44.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:50:44.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:50:44.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:44.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:50:44.435+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:50:44.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:50:44.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:51:15.478+0000] {processor.py:161} INFO - Started process (PID=30078) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:15.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:51:15.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:51:15.483+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:15.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:51:15.503+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:51:15.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:15.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:51:46.224+0000] {processor.py:161} INFO - Started process (PID=30109) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:46.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:51:46.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:51:46.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:46.254+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:51:46.249+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:51:46.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:51:46.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:52:17.033+0000] {processor.py:161} INFO - Started process (PID=30140) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:17.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:52:17.040+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:52:17.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:17.067+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:52:17.062+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:52:17.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:17.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T02:52:48.141+0000] {processor.py:161} INFO - Started process (PID=30171) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:48.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:52:48.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:52:48.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:48.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:52:48.180+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:52:48.188+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:52:48.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T02:53:19.179+0000] {processor.py:161} INFO - Started process (PID=30202) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:19.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:53:19.185+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:53:19.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:19.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:53:19.205+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:53:19.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:19.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:53:50.206+0000] {processor.py:161} INFO - Started process (PID=30239) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:50.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:53:50.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:53:50.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:50.236+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:53:50.232+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:53:50.237+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:53:50.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T02:54:21.200+0000] {processor.py:161} INFO - Started process (PID=30270) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:21.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:54:21.206+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:54:21.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:21.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:54:21.225+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:54:21.231+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:21.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T02:54:51.958+0000] {processor.py:161} INFO - Started process (PID=30301) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:51.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:54:51.964+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:54:51.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:51.988+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:54:51.983+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:54:51.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:54:52.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:55:23.066+0000] {processor.py:161} INFO - Started process (PID=30332) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:23.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:55:23.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:55:23.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:23.096+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:55:23.091+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:55:23.097+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:23.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:55:54.131+0000] {processor.py:161} INFO - Started process (PID=30363) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:54.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:55:54.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:55:54.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:54.161+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:55:54.156+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:55:54.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:55:54.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T02:56:25.232+0000] {processor.py:161} INFO - Started process (PID=30394) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:25.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:56:25.242+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:56:25.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:25.274+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:56:25.269+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:56:25.275+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:25.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.114 seconds
[2024-05-01T02:56:56.265+0000] {processor.py:161} INFO - Started process (PID=30425) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:56.270+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:56:56.273+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:56:56.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:56.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:56:56.302+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:56:56.309+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:56:56.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T02:57:27.335+0000] {processor.py:161} INFO - Started process (PID=30455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:27.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:57:27.341+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:57:27.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:27.365+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:57:27.361+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:57:27.366+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:27.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T02:57:58.355+0000] {processor.py:161} INFO - Started process (PID=30486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:58.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:57:58.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:57:58.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:58.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:57:58.381+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:57:58.386+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:57:58.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:58:29.483+0000] {processor.py:161} INFO - Started process (PID=30518) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:58:29.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:58:29.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:58:29.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:58:29.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:58:29.507+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:58:29.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:58:29.563+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T02:59:00.454+0000] {processor.py:161} INFO - Started process (PID=30549) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:00.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:59:00.460+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:59:00.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:00.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:59:00.480+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:59:00.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:00.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T02:59:31.194+0000] {processor.py:161} INFO - Started process (PID=30580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:31.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T02:59:31.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:59:31.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:31.224+0000] {logging_mixin.py:188} INFO - [2024-05-01T02:59:31.219+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T02:59:31.225+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T02:59:31.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:00:02.213+0000] {processor.py:161} INFO - Started process (PID=30611) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:02.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:00:02.220+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:00:02.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:02.243+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:00:02.239+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:00:02.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:02.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:00:33.243+0000] {processor.py:161} INFO - Started process (PID=30642) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:33.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:00:33.250+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:00:33.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:33.282+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:00:33.274+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:00:33.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:00:33.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.123 seconds
[2024-05-01T03:01:04.259+0000] {processor.py:161} INFO - Started process (PID=30673) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:04.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:01:04.264+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:01:04.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:04.288+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:01:04.283+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:01:04.289+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:04.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T03:01:35.309+0000] {processor.py:161} INFO - Started process (PID=30704) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:35.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:01:35.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:01:35.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:35.339+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:01:35.334+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:01:35.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:01:35.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T03:02:05.919+0000] {processor.py:161} INFO - Started process (PID=30734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:05.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:02:05.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:02:05.923+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:05.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:02:05.943+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:02:05.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:06.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:02:36.952+0000] {processor.py:161} INFO - Started process (PID=30765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:36.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:02:36.960+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:02:36.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:36.993+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:02:36.987+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:02:36.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:02:37.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.117 seconds
[2024-05-01T03:03:07.970+0000] {processor.py:161} INFO - Started process (PID=30796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:07.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:03:07.976+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:03:07.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:08.003+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:03:07.998+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:03:08.005+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:08.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T03:03:39.077+0000] {processor.py:161} INFO - Started process (PID=30828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:39.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:03:39.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:03:39.084+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:39.114+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:03:39.109+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:03:39.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:03:39.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T03:04:10.113+0000] {processor.py:161} INFO - Started process (PID=30859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:10.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:04:10.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:04:10.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:10.142+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:04:10.137+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:04:10.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:10.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T03:04:41.094+0000] {processor.py:161} INFO - Started process (PID=30890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:41.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:04:41.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:04:41.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:41.128+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:04:41.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:04:41.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:04:41.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T03:05:11.286+0000] {processor.py:161} INFO - Started process (PID=30921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:11.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:05:11.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:05:11.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:11.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:05:11.311+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:05:11.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:11.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:05:42.343+0000] {processor.py:161} INFO - Started process (PID=30952) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:42.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:05:42.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:05:42.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:42.372+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:05:42.367+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:05:42.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:05:42.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T03:06:13.349+0000] {processor.py:161} INFO - Started process (PID=30983) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:13.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:06:13.359+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:06:13.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:13.389+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:06:13.384+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:06:13.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:13.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.107 seconds
[2024-05-01T03:06:43.540+0000] {processor.py:161} INFO - Started process (PID=31014) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:43.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:06:43.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:06:43.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:43.569+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:06:43.564+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:06:43.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:06:43.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T03:07:14.585+0000] {processor.py:161} INFO - Started process (PID=31045) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:14.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:07:14.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:07:14.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:14.615+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:07:14.610+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:07:14.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:14.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T03:07:45.609+0000] {processor.py:161} INFO - Started process (PID=31076) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:45.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:07:45.614+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:07:45.613+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:45.638+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:07:45.633+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:07:45.639+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:07:45.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T03:08:15.839+0000] {processor.py:161} INFO - Started process (PID=31107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:15.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:08:15.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:08:15.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:15.869+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:08:15.865+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:08:15.870+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:15.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:08:46.928+0000] {processor.py:161} INFO - Started process (PID=31138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:46.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:08:46.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:08:46.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:46.956+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:08:46.952+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:08:46.958+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:08:47.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:09:17.981+0000] {processor.py:161} INFO - Started process (PID=31169) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:17.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:09:17.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:09:17.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:18.011+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:09:18.007+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:09:18.012+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:18.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:09:49.104+0000] {processor.py:161} INFO - Started process (PID=31200) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:49.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:09:49.110+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:09:49.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:49.134+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:09:49.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:09:49.135+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:09:49.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:10:20.172+0000] {processor.py:161} INFO - Started process (PID=31231) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:20.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:10:20.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:10:20.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:20.202+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:10:20.197+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:10:20.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:20.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:10:51.173+0000] {processor.py:161} INFO - Started process (PID=31262) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:51.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:10:51.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:10:51.178+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:51.202+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:10:51.198+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:10:51.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:10:51.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:11:21.339+0000] {processor.py:161} INFO - Started process (PID=31293) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:21.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:11:21.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:11:21.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:21.369+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:11:21.365+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:11:21.370+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:21.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:11:52.301+0000] {processor.py:161} INFO - Started process (PID=31324) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:52.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:11:52.307+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:11:52.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:52.335+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:11:52.329+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:11:52.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:11:52.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T03:12:23.306+0000] {processor.py:161} INFO - Started process (PID=31355) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:23.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:12:23.312+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:12:23.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:23.352+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:12:23.343+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:12:23.354+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:23.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.146 seconds
[2024-05-01T03:12:54.488+0000] {processor.py:161} INFO - Started process (PID=31386) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:54.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:12:54.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:12:54.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:54.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:12:54.514+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:12:54.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:12:54.578+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T03:13:25.487+0000] {processor.py:161} INFO - Started process (PID=31418) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:25.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:13:25.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:13:25.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:25.516+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:13:25.511+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:13:25.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:25.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:13:56.550+0000] {processor.py:161} INFO - Started process (PID=31449) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:56.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:13:56.558+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:13:56.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:56.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:13:56.585+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:13:56.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:13:56.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.117 seconds
[2024-05-01T03:14:27.697+0000] {processor.py:161} INFO - Started process (PID=31486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:27.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:14:27.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:14:27.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:27.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:14:27.722+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:14:27.728+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:27.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:14:58.730+0000] {processor.py:161} INFO - Started process (PID=31517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:58.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:14:58.736+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:14:58.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:58.760+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:14:58.755+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:14:58.761+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:14:58.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:15:29.226+0000] {processor.py:161} INFO - Started process (PID=31549) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:29.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:15:29.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:15:29.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:29.256+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:15:29.251+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:15:29.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:29.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:15:59.389+0000] {processor.py:161} INFO - Started process (PID=31580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:59.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:15:59.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:15:59.394+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:59.420+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:15:59.415+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:15:59.421+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:15:59.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T03:16:30.331+0000] {processor.py:161} INFO - Started process (PID=31611) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:16:30.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:16:30.337+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:16:30.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:16:30.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:16:30.356+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:16:30.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:16:30.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:17:00.535+0000] {processor.py:161} INFO - Started process (PID=31643) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:00.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:17:00.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:17:00.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:00.565+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:17:00.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:17:00.566+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:00.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T03:17:30.703+0000] {processor.py:161} INFO - Started process (PID=31674) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:30.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:17:30.709+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:17:30.708+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:30.733+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:17:30.729+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:17:30.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:17:30.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:18:01.456+0000] {processor.py:161} INFO - Started process (PID=31705) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:01.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:18:01.462+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:18:01.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:01.486+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:18:01.482+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:18:01.487+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:01.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:18:32.293+0000] {processor.py:161} INFO - Started process (PID=31736) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:32.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:18:32.299+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:18:32.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:32.324+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:18:32.319+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:18:32.325+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:18:32.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:19:02.506+0000] {processor.py:161} INFO - Started process (PID=31767) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:02.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:19:02.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:19:02.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:02.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:19:02.532+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:19:02.538+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:02.591+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:19:33.465+0000] {processor.py:161} INFO - Started process (PID=31798) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:33.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:19:33.470+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:19:33.469+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:33.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:19:33.490+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:19:33.496+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:19:33.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:20:03.900+0000] {processor.py:161} INFO - Started process (PID=31829) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:03.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:20:03.907+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:20:03.906+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:03.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:20:03.928+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:20:03.935+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:03.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T03:20:34.657+0000] {processor.py:161} INFO - Started process (PID=31860) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:34.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:20:34.663+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:20:34.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:35.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:20:35.147+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:20:35.153+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:20:35.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.550 seconds
[2024-05-01T03:21:05.357+0000] {processor.py:161} INFO - Started process (PID=31891) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:05.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:21:05.363+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:21:05.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:05.397+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:21:05.392+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:21:05.399+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:05.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T03:21:35.650+0000] {processor.py:161} INFO - Started process (PID=31922) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:35.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:21:35.658+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:21:35.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:35.690+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:21:35.680+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:21:35.692+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:21:35.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T03:22:05.993+0000] {processor.py:161} INFO - Started process (PID=31953) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:05.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:22:06.000+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:22:05.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:06.024+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:22:06.019+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:22:06.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:06.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.122 seconds
[2024-05-01T03:22:36.376+0000] {processor.py:161} INFO - Started process (PID=31984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:36.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:22:36.382+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:22:36.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:36.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:22:36.402+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:22:36.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:22:36.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:23:06.709+0000] {processor.py:161} INFO - Started process (PID=32015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:06.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:23:06.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:23:06.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:06.739+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:23:06.735+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:23:06.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:06.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T03:23:37.048+0000] {processor.py:161} INFO - Started process (PID=32046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:37.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:23:37.054+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:23:37.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:37.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:23:37.073+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:23:37.079+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:23:37.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:24:07.378+0000] {processor.py:161} INFO - Started process (PID=32077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:07.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:24:07.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:24:07.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:07.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:24:07.403+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:24:07.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:07.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:24:37.709+0000] {processor.py:161} INFO - Started process (PID=32109) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:37.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:24:37.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:24:37.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:37.740+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:24:37.735+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:24:37.741+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:24:37.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:25:08.096+0000] {processor.py:161} INFO - Started process (PID=32140) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:08.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:25:08.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:25:08.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:08.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:25:08.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:25:08.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:08.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.108 seconds
[2024-05-01T03:25:38.402+0000] {processor.py:161} INFO - Started process (PID=32171) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:38.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:25:38.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:25:38.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:38.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:25:38.428+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:25:38.434+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:25:38.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:26:08.717+0000] {processor.py:161} INFO - Started process (PID=32202) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:08.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:26:08.723+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:26:08.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:08.747+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:26:08.743+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:26:08.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:08.803+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T03:26:39.509+0000] {processor.py:161} INFO - Started process (PID=32233) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:39.512+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:26:39.515+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:26:39.514+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:39.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:26:39.534+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:26:39.540+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:26:39.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T03:27:10.409+0000] {processor.py:161} INFO - Started process (PID=32264) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:10.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:27:10.414+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:27:10.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:10.438+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:27:10.434+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:27:10.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:10.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:27:41.404+0000] {processor.py:161} INFO - Started process (PID=32295) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:41.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:27:41.410+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:27:41.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:41.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:27:41.429+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:27:41.435+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:27:41.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:28:12.359+0000] {processor.py:161} INFO - Started process (PID=32326) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:12.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:28:12.364+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:28:12.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:12.388+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:28:12.383+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:28:12.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:12.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T03:28:43.366+0000] {processor.py:161} INFO - Started process (PID=32357) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:43.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:28:43.372+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:28:43.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:43.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:28:43.391+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:28:43.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:28:43.448+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:29:14.078+0000] {processor.py:161} INFO - Started process (PID=32388) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:14.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:29:14.084+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:29:14.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:14.111+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:29:14.106+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:29:14.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:14.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T03:29:44.999+0000] {processor.py:161} INFO - Started process (PID=32419) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:45.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:29:45.005+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:29:45.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:45.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:29:45.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:29:45.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:29:45.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:30:15.972+0000] {processor.py:161} INFO - Started process (PID=32450) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:15.975+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:30:15.978+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:30:15.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:16.002+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:30:15.997+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:30:16.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:16.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:30:46.963+0000] {processor.py:161} INFO - Started process (PID=32482) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:46.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:30:46.969+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:30:46.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:46.993+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:30:46.988+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:30:46.994+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:30:47.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:31:17.680+0000] {processor.py:161} INFO - Started process (PID=32513) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:17.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:31:17.686+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:31:17.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:17.716+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:31:17.706+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:31:17.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:17.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.161 seconds
[2024-05-01T03:31:48.665+0000] {processor.py:161} INFO - Started process (PID=32544) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:48.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:31:48.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:31:48.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:48.695+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:31:48.690+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:31:48.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:31:48.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:32:19.686+0000] {processor.py:161} INFO - Started process (PID=32575) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:19.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:32:19.692+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:32:19.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:19.716+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:32:19.711+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:32:19.717+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:19.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:32:50.630+0000] {processor.py:161} INFO - Started process (PID=32606) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:50.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:32:50.637+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:32:50.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:50.661+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:32:50.656+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:32:50.662+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:32:50.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:33:21.635+0000] {processor.py:161} INFO - Started process (PID=32637) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:21.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:33:21.641+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:33:21.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:21.665+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:33:21.660+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:33:21.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:21.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:33:52.636+0000] {processor.py:161} INFO - Started process (PID=32668) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:52.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:33:52.642+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:33:52.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:52.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:33:52.664+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:33:52.671+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:33:52.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T03:34:23.549+0000] {processor.py:161} INFO - Started process (PID=32699) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:23.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:34:23.555+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:34:23.554+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:23.579+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:34:23.574+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:34:23.580+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:23.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:34:54.461+0000] {processor.py:161} INFO - Started process (PID=32730) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:54.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:34:54.467+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:34:54.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:54.491+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:34:54.486+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:34:54.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:34:54.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:35:25.449+0000] {processor.py:161} INFO - Started process (PID=32761) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:25.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:35:25.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:35:25.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:25.486+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:35:25.482+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:35:25.488+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:25.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T03:35:56.433+0000] {processor.py:161} INFO - Started process (PID=32792) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:56.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:35:56.444+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:35:56.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:56.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:35:56.463+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:35:56.469+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:35:56.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T03:36:27.415+0000] {processor.py:161} INFO - Started process (PID=32822) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:27.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:36:27.421+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:36:27.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:27.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:36:27.441+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:36:27.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:27.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:36:58.405+0000] {processor.py:161} INFO - Started process (PID=32853) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:58.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:36:58.411+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:36:58.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:58.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:36:58.454+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:36:58.460+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:36:58.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.123 seconds
[2024-05-01T03:37:29.385+0000] {processor.py:161} INFO - Started process (PID=32884) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:37:29.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:37:29.391+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:37:29.390+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:37:29.415+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:37:29.410+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:37:29.416+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:37:29.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:38:00.380+0000] {processor.py:161} INFO - Started process (PID=32915) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:00.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:38:00.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:38:00.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:00.410+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:38:00.405+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:38:00.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:00.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:38:31.346+0000] {processor.py:161} INFO - Started process (PID=32946) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:31.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:38:31.352+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:38:31.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:31.375+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:38:31.371+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:38:31.377+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:38:31.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:39:02.112+0000] {processor.py:161} INFO - Started process (PID=32977) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:02.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:39:02.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:39:02.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:02.142+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:39:02.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:39:02.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:02.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:39:33.105+0000] {processor.py:161} INFO - Started process (PID=33008) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:33.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:39:33.114+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:39:33.112+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:33.142+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:39:33.137+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:39:33.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:39:33.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T03:40:03.989+0000] {processor.py:161} INFO - Started process (PID=33039) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:03.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:40:03.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:40:03.994+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:04.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:40:04.014+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:40:04.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:04.072+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:40:34.980+0000] {processor.py:161} INFO - Started process (PID=33070) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:34.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:40:34.985+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:40:34.984+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:35.010+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:40:35.005+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:40:35.012+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:40:35.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T03:41:05.984+0000] {processor.py:161} INFO - Started process (PID=33101) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:05.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:41:05.994+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:41:05.992+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:06.024+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:41:06.018+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:41:06.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:06.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.113 seconds
[2024-05-01T03:41:36.934+0000] {processor.py:161} INFO - Started process (PID=33139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:36.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:41:36.943+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:41:36.941+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:36.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:41:36.973+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:41:36.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:41:37.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T03:42:07.903+0000] {processor.py:161} INFO - Started process (PID=33171) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:07.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:42:07.909+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:42:07.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:07.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:42:07.928+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:42:07.934+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:07.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:42:38.855+0000] {processor.py:161} INFO - Started process (PID=33202) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:38.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:42:38.862+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:42:38.861+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:38.887+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:42:38.882+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:42:38.888+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:42:38.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T03:43:09.839+0000] {processor.py:161} INFO - Started process (PID=33233) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:09.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:43:09.844+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:43:09.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:09.868+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:43:09.863+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:43:09.869+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:09.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:43:40.747+0000] {processor.py:161} INFO - Started process (PID=33264) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:40.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:43:40.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:43:40.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:40.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:43:40.772+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:43:40.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:43:40.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:44:11.674+0000] {processor.py:161} INFO - Started process (PID=33295) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:11.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:44:11.680+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:44:11.679+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:11.704+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:44:11.699+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:44:11.705+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:11.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:44:42.647+0000] {processor.py:161} INFO - Started process (PID=33326) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:42.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:44:42.652+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:44:42.651+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:42.677+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:44:42.672+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:44:42.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:44:42.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:45:13.663+0000] {processor.py:161} INFO - Started process (PID=33357) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:13.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:45:13.669+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:45:13.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:13.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:45:13.689+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:45:13.695+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:13.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:45:44.662+0000] {processor.py:161} INFO - Started process (PID=33388) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:44.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:45:44.669+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:45:44.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:44.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:45:44.695+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:45:44.706+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:45:44.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.134 seconds
[2024-05-01T03:46:15.575+0000] {processor.py:161} INFO - Started process (PID=33420) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:15.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:46:15.581+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:46:15.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:15.605+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:46:15.600+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:46:15.606+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:15.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:46:46.531+0000] {processor.py:161} INFO - Started process (PID=33451) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:46.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:46:46.536+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:46:46.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:46.560+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:46:46.555+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:46:46.561+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:46:46.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:47:17.462+0000] {processor.py:161} INFO - Started process (PID=33482) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:17.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:47:17.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:47:17.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:17.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:47:17.487+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:47:17.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:17.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:47:48.481+0000] {processor.py:161} INFO - Started process (PID=33513) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:48.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:47:48.487+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:47:48.486+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:48.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:47:48.507+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:47:48.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:47:48.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:48:19.398+0000] {processor.py:161} INFO - Started process (PID=33544) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:19.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:48:19.404+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:48:19.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:19.428+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:48:19.423+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:48:19.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:19.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:48:50.377+0000] {processor.py:161} INFO - Started process (PID=33575) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:50.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:48:50.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:48:50.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:50.407+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:48:50.402+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:48:50.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:48:50.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T03:49:21.294+0000] {processor.py:161} INFO - Started process (PID=33606) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:21.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:49:21.301+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:49:21.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:21.328+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:49:21.323+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:49:21.329+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:21.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T03:49:52.220+0000] {processor.py:161} INFO - Started process (PID=33637) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:52.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:49:52.226+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:49:52.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:52.250+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:49:52.245+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:49:52.251+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:49:52.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:50:23.237+0000] {processor.py:161} INFO - Started process (PID=33668) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:23.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:50:23.243+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:50:23.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:23.266+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:50:23.262+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:50:23.268+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:23.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T03:50:54.210+0000] {processor.py:161} INFO - Started process (PID=33700) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:54.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:50:54.217+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:50:54.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:54.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:50:54.239+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:50:54.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:50:54.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T03:51:25.241+0000] {processor.py:161} INFO - Started process (PID=33731) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:25.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:51:25.247+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:51:25.246+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:25.271+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:51:25.266+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:51:25.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:25.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:51:56.260+0000] {processor.py:161} INFO - Started process (PID=33762) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:56.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:51:56.266+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:51:56.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:56.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:51:56.285+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:51:56.291+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:51:56.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:52:27.189+0000] {processor.py:161} INFO - Started process (PID=33793) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:27.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:52:27.195+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:52:27.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:27.219+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:52:27.214+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:52:27.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:27.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:52:57.965+0000] {processor.py:161} INFO - Started process (PID=33824) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:57.968+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:52:57.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:52:57.970+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:57.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:52:57.990+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:52:57.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:52:58.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:53:28.926+0000] {processor.py:161} INFO - Started process (PID=33856) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:28.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:53:28.931+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:53:28.930+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:28.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:53:28.950+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:53:28.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:29.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:53:59.835+0000] {processor.py:161} INFO - Started process (PID=33887) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:59.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:53:59.841+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:53:59.840+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:59.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:53:59.860+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:53:59.866+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:53:59.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:54:30.781+0000] {processor.py:161} INFO - Started process (PID=33918) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:54:30.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:54:30.787+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:54:30.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:54:30.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:54:30.812+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:54:30.819+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:54:30.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.106 seconds
[2024-05-01T03:55:01.770+0000] {processor.py:161} INFO - Started process (PID=33950) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:01.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:55:01.781+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:55:01.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:01.815+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:55:01.810+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:55:01.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:01.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T03:55:32.748+0000] {processor.py:161} INFO - Started process (PID=33981) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:32.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:55:32.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:55:32.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:32.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:55:32.773+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:55:32.778+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:55:32.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T03:56:03.720+0000] {processor.py:161} INFO - Started process (PID=34013) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:03.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:56:03.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:56:03.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:03.750+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:56:03.745+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:56:03.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:03.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:56:34.686+0000] {processor.py:161} INFO - Started process (PID=34044) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:34.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:56:34.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:56:34.692+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:34.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:56:34.718+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:56:34.724+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:56:34.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T03:57:05.595+0000] {processor.py:161} INFO - Started process (PID=34075) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:05.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:57:05.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:57:05.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:05.625+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:57:05.621+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:57:05.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:05.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T03:57:36.511+0000] {processor.py:161} INFO - Started process (PID=34106) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:36.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:57:36.516+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:57:36.515+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:36.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:57:36.536+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:57:36.542+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:57:36.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T03:58:07.475+0000] {processor.py:161} INFO - Started process (PID=34137) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:07.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:58:07.481+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:58:07.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:07.506+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:58:07.501+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:58:07.507+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:07.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T03:58:38.187+0000] {processor.py:161} INFO - Started process (PID=34168) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:38.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:58:38.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:58:38.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:38.218+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:58:38.213+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:58:38.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:58:38.272+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T03:59:09.071+0000] {processor.py:161} INFO - Started process (PID=34199) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:09.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:59:09.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:59:09.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:09.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:59:09.096+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:59:09.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:09.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T03:59:40.057+0000] {processor.py:161} INFO - Started process (PID=34230) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:40.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T03:59:40.062+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:59:40.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:40.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T03:59:40.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T03:59:40.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T03:59:40.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:00:10.769+0000] {processor.py:161} INFO - Started process (PID=34261) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:10.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:00:10.775+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:00:10.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:10.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:00:10.801+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:00:10.810+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:10.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T04:00:41.699+0000] {processor.py:161} INFO - Started process (PID=34292) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:41.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:00:41.707+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:00:41.706+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:41.732+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:00:41.728+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:00:41.734+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:00:41.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T04:01:12.714+0000] {processor.py:161} INFO - Started process (PID=34329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:12.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:01:12.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:01:12.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:12.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:01:12.739+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:01:12.745+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:12.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:01:43.542+0000] {processor.py:161} INFO - Started process (PID=34360) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:43.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:01:43.548+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:01:43.547+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:43.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:01:43.570+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:01:43.576+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:01:43.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T04:02:14.286+0000] {processor.py:161} INFO - Started process (PID=34390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:14.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:02:14.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:02:14.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:14.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:02:14.311+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:02:14.317+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:14.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T04:02:45.255+0000] {processor.py:161} INFO - Started process (PID=34421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:45.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:02:45.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:02:45.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:45.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:02:45.285+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:02:45.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:02:45.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T04:03:16.285+0000] {processor.py:161} INFO - Started process (PID=34452) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:16.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:03:16.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:03:16.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:16.314+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:03:16.309+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:03:16.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:16.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:03:47.209+0000] {processor.py:161} INFO - Started process (PID=34483) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:47.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:03:47.215+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:03:47.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:47.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:03:47.234+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:03:47.240+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:03:47.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:04:18.121+0000] {processor.py:161} INFO - Started process (PID=34514) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:18.124+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:04:18.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:04:18.126+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:18.151+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:04:18.146+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:04:18.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:18.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:04:49.096+0000] {processor.py:161} INFO - Started process (PID=34545) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:49.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:04:49.106+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:04:49.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:49.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:04:49.132+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:04:49.138+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:04:49.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.116 seconds
[2024-05-01T04:05:20.049+0000] {processor.py:161} INFO - Started process (PID=34576) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:20.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:05:20.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:05:20.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:20.080+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:05:20.076+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:05:20.081+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:20.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:05:50.987+0000] {processor.py:161} INFO - Started process (PID=34607) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:50.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:05:50.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:05:50.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:51.016+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:05:51.012+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:05:51.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:05:51.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:06:21.952+0000] {processor.py:161} INFO - Started process (PID=34638) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:21.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:06:21.958+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:06:21.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:21.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:06:21.977+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:06:21.983+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:22.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:06:52.883+0000] {processor.py:161} INFO - Started process (PID=34670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:52.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:06:52.887+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:06:52.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:52.911+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:06:52.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:06:52.912+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:06:52.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:07:23.875+0000] {processor.py:161} INFO - Started process (PID=34701) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:23.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:07:23.886+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:07:23.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:23.918+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:07:23.913+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:07:23.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:23.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.118 seconds
[2024-05-01T04:07:54.817+0000] {processor.py:161} INFO - Started process (PID=34732) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:54.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:07:54.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:07:54.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:54.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:07:54.841+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:07:54.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:07:54.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:08:25.788+0000] {processor.py:161} INFO - Started process (PID=34763) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:25.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:08:25.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:08:25.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:25.817+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:08:25.813+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:08:25.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:25.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:08:56.692+0000] {processor.py:161} INFO - Started process (PID=34794) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:56.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:08:56.698+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:08:56.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:56.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:08:56.717+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:08:56.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:08:56.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:09:27.617+0000] {processor.py:161} INFO - Started process (PID=34825) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:27.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:09:27.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:09:27.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:27.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:09:27.641+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:09:27.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:27.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:09:58.529+0000] {processor.py:161} INFO - Started process (PID=34856) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:58.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:09:58.534+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:09:58.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:58.558+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:09:58.553+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:09:58.559+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:09:58.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:10:29.518+0000] {processor.py:161} INFO - Started process (PID=34887) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:10:29.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:10:29.524+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:10:29.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:10:29.548+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:10:29.543+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:10:29.549+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:10:29.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:11:00.466+0000] {processor.py:161} INFO - Started process (PID=34919) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:00.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:11:00.472+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:11:00.471+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:00.495+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:11:00.491+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:11:00.496+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:00.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T04:11:31.394+0000] {processor.py:161} INFO - Started process (PID=34950) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:31.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:11:31.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:11:31.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:31.423+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:11:31.419+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:11:31.424+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:11:31.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:12:02.379+0000] {processor.py:161} INFO - Started process (PID=34981) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:02.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:12:02.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:12:02.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:02.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:12:02.404+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:12:02.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:02.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:12:33.286+0000] {processor.py:161} INFO - Started process (PID=35012) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:33.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:12:33.291+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:12:33.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:33.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:12:33.310+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:12:33.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:12:33.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:13:04.285+0000] {processor.py:161} INFO - Started process (PID=35043) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:04.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:13:04.291+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:13:04.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:04.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:13:04.310+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:13:04.316+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:04.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:13:35.248+0000] {processor.py:161} INFO - Started process (PID=35074) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:35.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:13:35.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:13:35.258+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:35.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:13:35.298+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:13:35.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:13:35.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.179 seconds
[2024-05-01T04:14:06.240+0000] {processor.py:161} INFO - Started process (PID=35106) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:06.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:14:06.247+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:14:06.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:06.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:14:06.269+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:14:06.276+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:06.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T04:14:37.167+0000] {processor.py:161} INFO - Started process (PID=35137) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:37.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:14:37.174+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:14:37.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:37.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:14:37.195+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:14:37.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:14:37.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T04:15:08.203+0000] {processor.py:161} INFO - Started process (PID=35172) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:08.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:15:08.209+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:15:08.208+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:08.233+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:15:08.228+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:15:08.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:08.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T04:15:39.158+0000] {processor.py:161} INFO - Started process (PID=35203) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:39.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:15:39.164+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:15:39.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:39.190+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:15:39.185+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:15:39.191+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:15:39.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T04:16:10.153+0000] {processor.py:161} INFO - Started process (PID=35234) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:10.156+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:16:10.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:16:10.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:10.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:16:10.178+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:16:10.184+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:10.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:16:41.049+0000] {processor.py:161} INFO - Started process (PID=35267) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:41.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:16:41.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:16:41.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:41.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:16:41.074+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:16:41.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:16:41.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:17:11.952+0000] {processor.py:161} INFO - Started process (PID=35298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:11.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:17:11.957+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:17:11.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:11.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:17:11.976+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:17:11.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:12.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T04:17:42.874+0000] {processor.py:161} INFO - Started process (PID=35330) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:42.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:17:42.879+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:17:42.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:42.905+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:17:42.900+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:17:42.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:17:42.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T04:18:13.834+0000] {processor.py:161} INFO - Started process (PID=35361) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:13.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:18:13.839+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:18:13.838+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:13.863+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:18:13.858+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:18:13.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:13.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T04:18:44.552+0000] {processor.py:161} INFO - Started process (PID=35392) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:44.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:18:44.557+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:18:44.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:44.581+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:18:44.576+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:18:44.582+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:18:44.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:19:15.484+0000] {processor.py:161} INFO - Started process (PID=35423) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:15.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:19:15.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:19:15.488+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:15.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:19:15.508+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:19:15.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:15.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:19:46.410+0000] {processor.py:161} INFO - Started process (PID=35454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:46.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:19:46.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:19:46.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:46.439+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:19:46.435+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:19:46.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:19:46.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:20:17.383+0000] {processor.py:161} INFO - Started process (PID=35485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:17.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:20:17.388+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:20:17.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:17.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:20:17.407+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:20:17.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:17.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:20:48.311+0000] {processor.py:161} INFO - Started process (PID=35522) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:48.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:20:48.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:20:48.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:48.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:20:48.349+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:20:48.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:20:48.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T04:21:19.237+0000] {processor.py:161} INFO - Started process (PID=35553) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:19.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:21:19.242+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:21:19.241+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:19.268+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:21:19.263+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:21:19.270+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:19.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:21:50.135+0000] {processor.py:161} INFO - Started process (PID=35584) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:50.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:21:50.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:21:50.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:50.164+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:21:50.159+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:21:50.165+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:21:50.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:22:21.227+0000] {processor.py:161} INFO - Started process (PID=35614) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:21.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:22:21.233+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:22:21.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:21.257+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:22:21.252+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:22:21.258+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:21.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:22:52.145+0000] {processor.py:161} INFO - Started process (PID=35645) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:52.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:22:52.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:22:52.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:52.175+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:22:52.171+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:22:52.177+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:22:52.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:23:23.049+0000] {processor.py:161} INFO - Started process (PID=35676) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:23.052+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:23:23.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:23:23.054+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:23.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:23:23.074+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:23:23.080+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:23.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.099 seconds
[2024-05-01T04:23:54.024+0000] {processor.py:161} INFO - Started process (PID=35707) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:54.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:23:54.031+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:23:54.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:54.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:23:54.051+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:23:54.057+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:23:54.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:24:24.183+0000] {processor.py:161} INFO - Started process (PID=35738) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:24.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:24:24.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:24:24.188+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:24.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:24:24.208+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:24:24.214+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:24.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:24:54.904+0000] {processor.py:161} INFO - Started process (PID=35769) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:54.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:24:54.910+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:24:54.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:54.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:24:54.931+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:24:54.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:24:55.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T04:25:25.938+0000] {processor.py:161} INFO - Started process (PID=35800) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:25.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:25:25.944+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:25:25.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:25.975+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:25:25.970+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:25:25.976+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:26.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.121 seconds
[2024-05-01T04:25:56.984+0000] {processor.py:161} INFO - Started process (PID=35831) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:56.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:25:56.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:25:56.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:57.014+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:25:57.010+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:25:57.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:25:57.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:26:27.978+0000] {processor.py:161} INFO - Started process (PID=35862) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:27.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:26:27.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:26:27.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:28.007+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:26:28.003+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:26:28.008+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:28.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:26:58.876+0000] {processor.py:161} INFO - Started process (PID=35893) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:58.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:26:58.882+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:26:58.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:58.906+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:26:58.901+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:26:58.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:26:58.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:27:29.897+0000] {processor.py:161} INFO - Started process (PID=35924) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:27:29.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:27:29.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:27:29.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:27:29.926+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:27:29.922+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:27:29.927+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:27:29.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:28:00.824+0000] {processor.py:161} INFO - Started process (PID=35955) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:00.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:28:00.830+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:28:00.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:00.853+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:28:00.849+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:28:00.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:00.908+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:28:31.802+0000] {processor.py:161} INFO - Started process (PID=35986) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:31.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:28:31.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:28:31.807+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:31.834+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:28:31.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:28:31.836+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:28:31.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:29:02.745+0000] {processor.py:161} INFO - Started process (PID=36017) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:02.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:29:02.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:29:02.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:02.775+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:29:02.770+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:29:02.776+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:02.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:29:33.663+0000] {processor.py:161} INFO - Started process (PID=36048) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:33.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:29:33.668+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:29:33.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:33.692+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:29:33.687+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:29:33.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:29:33.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:30:04.556+0000] {processor.py:161} INFO - Started process (PID=36079) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:04.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:30:04.562+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:30:04.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:04.586+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:30:04.581+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:30:04.587+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:04.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:30:35.636+0000] {processor.py:161} INFO - Started process (PID=36110) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:35.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:30:35.643+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:30:35.642+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:35.676+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:30:35.670+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:30:35.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:30:35.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.113 seconds
[2024-05-01T04:31:06.370+0000] {processor.py:161} INFO - Started process (PID=36141) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:06.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:31:06.375+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:31:06.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:06.400+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:31:06.395+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:31:06.401+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:06.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T04:31:37.316+0000] {processor.py:161} INFO - Started process (PID=36173) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:37.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:31:37.322+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:31:37.321+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:37.346+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:31:37.341+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:31:37.347+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:31:37.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:32:08.261+0000] {processor.py:161} INFO - Started process (PID=36204) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:08.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:32:08.266+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:32:08.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:08.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:32:08.286+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:32:08.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:08.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:32:39.304+0000] {processor.py:161} INFO - Started process (PID=36235) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:39.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:32:39.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:32:39.309+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:39.338+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:32:39.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:32:39.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:32:39.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T04:33:10.294+0000] {processor.py:161} INFO - Started process (PID=36266) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:10.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:33:10.300+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:33:10.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:10.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:33:10.321+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:33:10.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:10.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T04:33:41.318+0000] {processor.py:161} INFO - Started process (PID=36297) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:41.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:33:41.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:33:41.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:41.351+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:33:41.347+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:33:41.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:33:41.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:34:12.267+0000] {processor.py:161} INFO - Started process (PID=36328) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:12.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:34:12.273+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:34:12.272+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:12.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:34:12.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:34:12.298+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:12.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:34:43.242+0000] {processor.py:161} INFO - Started process (PID=36359) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:43.246+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:34:43.249+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:34:43.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:43.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:34:43.283+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:34:43.292+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:34:43.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.125 seconds
[2024-05-01T04:35:14.213+0000] {processor.py:161} INFO - Started process (PID=36390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:14.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:35:14.219+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:35:14.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:14.243+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:35:14.239+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:35:14.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:14.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:35:45.163+0000] {processor.py:161} INFO - Started process (PID=36421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:45.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:35:45.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:35:45.168+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:45.193+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:35:45.188+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:35:45.194+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:35:45.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:36:16.137+0000] {processor.py:161} INFO - Started process (PID=36452) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:16.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:36:16.143+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:36:16.142+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:16.167+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:36:16.162+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:36:16.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:16.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:36:47.063+0000] {processor.py:161} INFO - Started process (PID=36483) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:47.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:36:47.069+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:36:47.068+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:47.095+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:36:47.090+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:36:47.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:36:47.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:37:18.059+0000] {processor.py:161} INFO - Started process (PID=36515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:18.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:37:18.066+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:37:18.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:18.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:37:18.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:37:18.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:18.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T04:37:49.130+0000] {processor.py:161} INFO - Started process (PID=36546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:49.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:37:49.135+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:37:49.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:49.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:37:49.154+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:37:49.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:37:49.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:38:20.114+0000] {processor.py:161} INFO - Started process (PID=36577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:20.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:38:20.120+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:38:20.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:20.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:38:20.140+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:38:20.146+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:20.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T04:38:51.076+0000] {processor.py:161} INFO - Started process (PID=36608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:51.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:38:51.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:38:51.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:51.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:38:51.100+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:38:51.106+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:38:51.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:39:22.002+0000] {processor.py:161} INFO - Started process (PID=36639) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:22.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:39:22.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:39:22.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:22.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:39:22.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:39:22.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:22.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.155 seconds
[2024-05-01T04:39:52.923+0000] {processor.py:161} INFO - Started process (PID=36670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:52.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:39:52.930+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:39:52.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:52.954+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:39:52.950+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:39:52.956+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:39:53.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:40:23.760+0000] {processor.py:161} INFO - Started process (PID=36701) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:23.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:40:23.767+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:40:23.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:23.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:40:23.789+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:40:23.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:23.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.107 seconds
[2024-05-01T04:40:54.748+0000] {processor.py:161} INFO - Started process (PID=36738) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:54.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:40:54.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:40:54.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:54.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:40:54.773+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:40:54.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:40:54.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T04:41:25.700+0000] {processor.py:161} INFO - Started process (PID=36769) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:25.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:41:25.706+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:41:25.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:25.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:41:25.725+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:41:25.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:25.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:41:56.707+0000] {processor.py:161} INFO - Started process (PID=36801) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:56.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:41:56.713+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:41:56.712+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:56.736+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:41:56.732+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:41:56.737+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:41:56.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:42:27.624+0000] {processor.py:161} INFO - Started process (PID=36832) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:27.628+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:42:27.631+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:42:27.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:27.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:42:27.650+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:42:27.656+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:27.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:42:58.609+0000] {processor.py:161} INFO - Started process (PID=36863) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:58.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:42:58.615+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:42:58.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:58.638+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:42:58.634+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:42:58.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:42:58.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:43:29.579+0000] {processor.py:161} INFO - Started process (PID=36894) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:43:29.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:43:29.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:43:29.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:43:29.609+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:43:29.604+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:43:29.610+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:43:29.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:44:00.583+0000] {processor.py:161} INFO - Started process (PID=36925) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:00.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:44:00.593+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:44:00.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:00.640+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:44:00.620+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:44:00.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:00.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.143 seconds
[2024-05-01T04:44:31.532+0000] {processor.py:161} INFO - Started process (PID=36956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:31.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:44:31.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:44:31.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:31.561+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:44:31.557+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:44:31.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:44:31.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:45:02.482+0000] {processor.py:161} INFO - Started process (PID=36987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:02.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:45:02.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:45:02.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:02.511+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:45:02.507+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:45:02.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:02.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:45:33.487+0000] {processor.py:161} INFO - Started process (PID=37018) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:33.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:45:33.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:45:33.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:33.516+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:45:33.511+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:45:33.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:45:33.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:46:04.461+0000] {processor.py:161} INFO - Started process (PID=37049) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:04.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:46:04.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:46:04.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:04.495+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:46:04.489+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:46:04.496+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:04.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.100 seconds
[2024-05-01T04:46:35.397+0000] {processor.py:161} INFO - Started process (PID=37080) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:35.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:46:35.403+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:46:35.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:35.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:46:35.422+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:46:35.428+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:46:35.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:47:06.364+0000] {processor.py:161} INFO - Started process (PID=37111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:06.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:47:06.370+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:47:06.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:06.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:47:06.389+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:47:06.394+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:06.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:47:37.438+0000] {processor.py:161} INFO - Started process (PID=37142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:37.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:47:37.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:47:37.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:37.469+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:47:37.464+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:47:37.470+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:47:37.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.105 seconds
[2024-05-01T04:48:08.393+0000] {processor.py:161} INFO - Started process (PID=37174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:08.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:48:08.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:48:08.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:08.421+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:48:08.417+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:48:08.423+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:08.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T04:48:39.452+0000] {processor.py:161} INFO - Started process (PID=37205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:39.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:48:39.458+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:48:39.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:39.482+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:48:39.477+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:48:39.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:48:39.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:49:10.387+0000] {processor.py:161} INFO - Started process (PID=37236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:10.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:49:10.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:49:10.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:10.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:49:10.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:49:10.417+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:10.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:49:41.299+0000] {processor.py:161} INFO - Started process (PID=37267) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:41.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:49:41.305+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:49:41.304+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:41.329+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:49:41.325+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:49:41.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:49:41.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:50:12.276+0000] {processor.py:161} INFO - Started process (PID=37298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:12.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:50:12.282+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:50:12.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:12.306+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:50:12.301+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:50:12.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:12.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T04:50:43.357+0000] {processor.py:161} INFO - Started process (PID=37329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:43.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:50:43.364+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:50:43.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:43.397+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:50:43.391+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:50:43.398+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:50:43.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.115 seconds
[2024-05-01T04:51:14.299+0000] {processor.py:161} INFO - Started process (PID=37360) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:14.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:51:14.305+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:51:14.304+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:14.329+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:51:14.325+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:51:14.330+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:14.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:51:45.309+0000] {processor.py:161} INFO - Started process (PID=37391) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:45.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:51:45.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:51:45.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:45.340+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:51:45.336+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:51:45.341+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:51:45.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T04:52:16.231+0000] {processor.py:161} INFO - Started process (PID=37422) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:16.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:52:16.236+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:52:16.235+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:16.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:52:16.256+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:52:16.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:16.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:52:47.187+0000] {processor.py:161} INFO - Started process (PID=37454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:47.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:52:47.193+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:52:47.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:47.217+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:52:47.212+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:52:47.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:52:47.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:53:18.124+0000] {processor.py:161} INFO - Started process (PID=37485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:18.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:53:18.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:53:18.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:18.153+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:53:18.149+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:53:18.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:18.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:53:49.061+0000] {processor.py:161} INFO - Started process (PID=37516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:49.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:53:49.067+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:53:49.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:49.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:53:49.086+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:53:49.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:53:49.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:54:20.060+0000] {processor.py:161} INFO - Started process (PID=37547) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:20.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:54:20.066+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:54:20.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:20.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:54:20.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:54:20.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:20.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:54:51.032+0000] {processor.py:161} INFO - Started process (PID=37578) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:51.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:54:51.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:54:51.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:51.060+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:54:51.056+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:54:51.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:54:51.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:55:22.017+0000] {processor.py:161} INFO - Started process (PID=37609) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:22.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:55:22.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:55:22.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:22.047+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:55:22.042+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:55:22.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:22.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:55:53.033+0000] {processor.py:161} INFO - Started process (PID=37640) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:53.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:55:53.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:55:53.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:53.063+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:55:53.058+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:55:53.064+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:55:53.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T04:56:23.958+0000] {processor.py:161} INFO - Started process (PID=37671) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:23.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:56:23.964+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:56:23.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:23.988+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:56:23.983+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:56:23.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:24.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T04:56:54.922+0000] {processor.py:161} INFO - Started process (PID=37702) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:54.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:56:54.927+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:56:54.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:54.951+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:56:54.946+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:56:54.952+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:56:55.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:57:25.858+0000] {processor.py:161} INFO - Started process (PID=37733) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:25.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:57:25.864+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:57:25.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:25.890+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:57:25.885+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:57:25.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:25.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T04:57:56.825+0000] {processor.py:161} INFO - Started process (PID=37764) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:56.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:57:56.830+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:57:56.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:56.854+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:57:56.849+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:57:56.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:57:56.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T04:58:27.774+0000] {processor.py:161} INFO - Started process (PID=37795) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:27.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:58:27.780+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:58:27.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:27.803+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:58:27.799+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:58:27.805+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:27.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T04:58:58.477+0000] {processor.py:161} INFO - Started process (PID=37826) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:58.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:58:58.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:58:58.483+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:58.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:58:58.506+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:58:58.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:58:58.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.102 seconds
[2024-05-01T04:59:29.395+0000] {processor.py:161} INFO - Started process (PID=37857) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T04:59:29.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T04:59:29.401+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:59:29.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:59:29.425+0000] {logging_mixin.py:188} INFO - [2024-05-01T04:59:29.420+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T04:59:29.426+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T04:59:29.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:00:00.350+0000] {processor.py:161} INFO - Started process (PID=37888) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:00.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:00:00.356+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:00:00.355+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:00.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:00:00.375+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:00:00.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:00.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:00:31.409+0000] {processor.py:161} INFO - Started process (PID=37925) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:31.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:00:31.415+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:00:31.414+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:31.439+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:00:31.435+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:00:31.440+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:00:31.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:01:02.139+0000] {processor.py:161} INFO - Started process (PID=37956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:02.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:01:02.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:01:02.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:02.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:01:02.164+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:01:02.170+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:02.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T05:01:33.062+0000] {processor.py:161} INFO - Started process (PID=37987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:33.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:01:33.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:01:33.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:33.091+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:01:33.087+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:01:33.092+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:01:33.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:02:03.999+0000] {processor.py:161} INFO - Started process (PID=38018) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:04.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:02:04.005+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:02:04.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:04.029+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:02:04.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:02:04.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:04.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T05:02:34.936+0000] {processor.py:161} INFO - Started process (PID=38049) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:34.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:02:34.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:02:34.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:34.966+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:02:34.962+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:02:34.967+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:02:35.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:03:05.958+0000] {processor.py:161} INFO - Started process (PID=38080) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:05.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:03:05.963+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:03:05.962+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:05.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:03:05.982+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:03:05.988+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:06.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:03:36.883+0000] {processor.py:161} INFO - Started process (PID=38111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:36.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:03:36.889+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:03:36.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:36.913+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:03:36.908+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:03:36.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:03:36.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:04:07.808+0000] {processor.py:161} INFO - Started process (PID=38142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:07.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:04:07.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:04:07.820+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:07.853+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:04:07.849+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:04:07.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:07.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.115 seconds
[2024-05-01T05:04:38.788+0000] {processor.py:161} INFO - Started process (PID=38174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:38.792+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:04:38.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:04:38.793+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:38.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:04:38.814+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:04:38.819+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:04:38.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:05:09.752+0000] {processor.py:161} INFO - Started process (PID=38205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:09.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:05:09.758+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:05:09.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:09.782+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:05:09.777+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:05:09.783+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:09.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:05:40.737+0000] {processor.py:161} INFO - Started process (PID=38237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:40.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:05:40.743+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:05:40.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:40.767+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:05:40.763+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:05:40.768+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:05:40.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:06:11.634+0000] {processor.py:161} INFO - Started process (PID=38268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:11.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:06:11.640+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:06:11.639+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:11.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:06:11.662+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:06:11.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:11.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.101 seconds
[2024-05-01T05:06:42.627+0000] {processor.py:161} INFO - Started process (PID=38299) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:42.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:06:42.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:06:42.632+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:42.657+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:06:42.653+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:06:42.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:06:42.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:07:13.586+0000] {processor.py:161} INFO - Started process (PID=38330) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:13.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:07:13.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:07:13.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:13.616+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:07:13.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:07:13.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:13.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:07:44.586+0000] {processor.py:161} INFO - Started process (PID=38361) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:44.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:07:44.592+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:07:44.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:44.616+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:07:44.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:07:44.617+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:07:44.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.094 seconds
[2024-05-01T05:08:15.580+0000] {processor.py:161} INFO - Started process (PID=38392) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:15.583+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:08:15.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:08:15.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:15.609+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:08:15.605+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:08:15.610+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:15.664+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:08:46.530+0000] {processor.py:161} INFO - Started process (PID=38423) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:46.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:08:46.536+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:08:46.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:46.560+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:08:46.555+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:08:46.561+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:08:46.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.090 seconds
[2024-05-01T05:09:17.458+0000] {processor.py:161} INFO - Started process (PID=38454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:17.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:09:17.464+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:09:17.463+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:17.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:09:17.483+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:09:17.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:17.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:09:48.454+0000] {processor.py:161} INFO - Started process (PID=38485) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:48.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:09:48.460+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:09:48.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:48.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:09:48.479+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:09:48.485+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:09:48.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:10:19.433+0000] {processor.py:161} INFO - Started process (PID=38516) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:19.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:10:19.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:10:19.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:19.467+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:10:19.462+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:10:19.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:19.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.096 seconds
[2024-05-01T05:10:50.359+0000] {processor.py:161} INFO - Started process (PID=38547) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:50.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:10:50.365+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:10:50.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:50.389+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:10:50.385+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:10:50.390+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:10:50.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:11:21.316+0000] {processor.py:161} INFO - Started process (PID=38579) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:21.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:11:21.321+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:11:21.320+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:21.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:11:21.340+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:11:21.346+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:21.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:11:52.280+0000] {processor.py:161} INFO - Started process (PID=38610) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:52.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:11:52.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:11:52.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:52.321+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:11:52.313+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:11:52.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:11:52.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.114 seconds
[2024-05-01T05:12:23.273+0000] {processor.py:161} INFO - Started process (PID=38641) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:23.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:12:23.278+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:12:23.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:23.302+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:12:23.297+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:12:23.303+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:23.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T05:12:54.216+0000] {processor.py:161} INFO - Started process (PID=38672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:54.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:12:54.222+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:12:54.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:54.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:12:54.242+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:12:54.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:12:54.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:13:25.137+0000] {processor.py:161} INFO - Started process (PID=38703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:25.141+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:13:25.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:13:25.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:25.173+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:13:25.168+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:13:25.174+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:25.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.114 seconds
[2024-05-01T05:13:56.095+0000] {processor.py:161} INFO - Started process (PID=38734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:56.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:13:56.101+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:13:56.100+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:56.125+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:13:56.120+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:13:56.126+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:13:56.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:14:27.193+0000] {processor.py:161} INFO - Started process (PID=38765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:27.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:14:27.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:14:27.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:27.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:14:27.220+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:14:27.227+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:27.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T05:14:58.215+0000] {processor.py:161} INFO - Started process (PID=38796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:58.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:14:58.221+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:14:58.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:58.245+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:14:58.241+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:14:58.246+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:14:58.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:15:29.185+0000] {processor.py:161} INFO - Started process (PID=38829) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:15:29.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:15:29.190+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:15:29.189+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:15:29.214+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:15:29.209+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:15:29.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:15:29.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:16:00.123+0000] {processor.py:161} INFO - Started process (PID=38860) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:00.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:16:00.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:16:00.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:00.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:16:00.150+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:16:00.157+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:00.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.104 seconds
[2024-05-01T05:16:31.137+0000] {processor.py:161} INFO - Started process (PID=38891) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:31.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:16:31.143+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:16:31.142+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:31.167+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:16:31.163+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:16:31.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:16:31.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:17:02.129+0000] {processor.py:161} INFO - Started process (PID=38922) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:02.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:17:02.135+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:17:02.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:02.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:17:02.154+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:17:02.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:02.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:17:33.129+0000] {processor.py:161} INFO - Started process (PID=38954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:33.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:17:33.135+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:17:33.134+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:33.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:17:33.154+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:17:33.160+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:17:33.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:18:03.950+0000] {processor.py:161} INFO - Started process (PID=38985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:03.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:18:03.957+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:18:03.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:03.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:18:03.979+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:18:03.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:04.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T05:18:35.019+0000] {processor.py:161} INFO - Started process (PID=39017) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:35.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:18:35.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:18:35.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:35.049+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:18:35.044+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:18:35.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:18:35.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:19:05.938+0000] {processor.py:161} INFO - Started process (PID=39048) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:05.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:19:05.944+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:19:05.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:05.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:19:05.963+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:19:05.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:06.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.110 seconds
[2024-05-01T05:19:36.760+0000] {processor.py:161} INFO - Started process (PID=39079) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:36.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:19:36.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:19:36.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:36.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:19:36.786+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:19:36.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:19:36.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.098 seconds
[2024-05-01T05:20:07.791+0000] {processor.py:161} INFO - Started process (PID=39115) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:07.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:20:07.796+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:20:07.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:07.820+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:20:07.815+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:20:07.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:07.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:20:38.802+0000] {processor.py:161} INFO - Started process (PID=39147) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:38.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:20:38.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:20:38.807+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:38.831+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:20:38.827+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:20:38.833+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:20:38.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:21:09.723+0000] {processor.py:161} INFO - Started process (PID=39178) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:09.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:21:09.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:21:09.729+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:09.765+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:21:09.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:21:09.766+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:09.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.109 seconds
[2024-05-01T05:21:40.617+0000] {processor.py:161} INFO - Started process (PID=39209) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:40.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:21:40.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:21:40.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:40.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:21:40.642+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:21:40.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:21:40.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.091 seconds
[2024-05-01T05:22:11.537+0000] {processor.py:161} INFO - Started process (PID=39241) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:11.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:22:11.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:22:11.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:11.567+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:22:11.563+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:22:11.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:11.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:22:42.470+0000] {processor.py:161} INFO - Started process (PID=39272) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:42.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:22:42.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:22:42.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:42.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:22:42.495+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:22:42.501+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:22:42.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:23:13.498+0000] {processor.py:161} INFO - Started process (PID=39303) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:13.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:23:13.535+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:23:13.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:13.563+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:23:13.558+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:23:13.565+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:13.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.128 seconds
[2024-05-01T05:23:44.447+0000] {processor.py:161} INFO - Started process (PID=39334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:44.450+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:23:44.453+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:23:44.452+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:44.477+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:23:44.472+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:23:44.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:23:44.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:24:15.351+0000] {processor.py:161} INFO - Started process (PID=39365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:15.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:24:15.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:24:15.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:15.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:24:15.376+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:24:15.382+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:15.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:24:46.271+0000] {processor.py:161} INFO - Started process (PID=39396) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:46.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:24:46.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:24:46.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:46.301+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:24:46.296+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:24:46.302+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:24:46.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:25:17.283+0000] {processor.py:161} INFO - Started process (PID=39427) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:17.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:25:17.289+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:25:17.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:17.314+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:25:17.309+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:25:17.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:17.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T05:25:48.205+0000] {processor.py:161} INFO - Started process (PID=39458) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:48.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:25:48.214+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:25:48.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:48.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:25:48.241+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:25:48.247+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:25:48.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T05:26:19.203+0000] {processor.py:161} INFO - Started process (PID=39489) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:19.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:26:19.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:26:19.209+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:19.235+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:26:19.230+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:26:19.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:19.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.111 seconds
[2024-05-01T05:26:49.973+0000] {processor.py:161} INFO - Started process (PID=39520) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:49.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:26:49.983+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:26:49.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:50.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:26:50.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:26:50.032+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:26:50.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.133 seconds
[2024-05-01T05:27:20.953+0000] {processor.py:161} INFO - Started process (PID=39551) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:20.957+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:27:20.959+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:27:20.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:20.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:27:20.979+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:27:20.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:21.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:27:51.907+0000] {processor.py:161} INFO - Started process (PID=39582) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:51.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:27:51.913+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:27:51.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:51.937+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:27:51.932+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:27:51.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:27:51.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.095 seconds
[2024-05-01T05:28:22.839+0000] {processor.py:161} INFO - Started process (PID=39613) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:22.843+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:28:22.846+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:28:22.845+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:22.870+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:28:22.866+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:28:22.872+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:22.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T05:28:53.781+0000] {processor.py:161} INFO - Started process (PID=39644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:53.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:28:53.787+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:28:53.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:53.811+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:28:53.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:28:53.813+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:28:53.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.154 seconds
[2024-05-01T05:29:24.780+0000] {processor.py:161} INFO - Started process (PID=39675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:24.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:29:24.789+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:29:24.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:24.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:29:24.817+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:29:24.825+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:24.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.115 seconds
[2024-05-01T05:29:55.770+0000] {processor.py:161} INFO - Started process (PID=39706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:55.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:29:55.775+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:29:55.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:55.799+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:29:55.794+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:29:55.800+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:29:55.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.093 seconds
[2024-05-01T05:30:26.863+0000] {processor.py:161} INFO - Started process (PID=39737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:26.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:30:26.869+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:30:26.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:26.893+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:30:26.888+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:30:26.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:26.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.092 seconds
[2024-05-01T05:30:57.597+0000] {processor.py:161} INFO - Started process (PID=39768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:57.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:30:57.604+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:30:57.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:57.628+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:30:57.623+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 178, in <module>
    load_data_to_bq = _load_data_to_bq(file_path=f"/opt/airflow/dags/data_to_load.csv", dataset_id="ds525_capstaone_db", table_id="aqi_data_test")
  File "/opt/airflow/dags/get_and_load.py", line 117, in _load_data_to_bq
    load_task = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_data_to_bq). Invalid arguments were:
**kwargs: {'bigquery_conn_id': 'my_bqr_conn'}
[2024-05-01T05:30:57.629+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:30:57.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.097 seconds
[2024-05-01T05:31:19.268+0000] {processor.py:161} INFO - Started process (PID=39799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:19.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:31:19.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:19.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:19.315+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:19.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:19.718+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:31:19.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:19.753+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:31:19.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.566 seconds
[2024-05-01T05:31:50.142+0000] {processor.py:161} INFO - Started process (PID=39830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:50.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:31:50.149+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:50.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:50.184+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:31:50.255+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:50.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:31:50.294+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:31:50.293+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:31:50.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T05:32:20.701+0000] {processor.py:161} INFO - Started process (PID=39867) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:20.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:32:20.708+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:20.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:20.744+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:20.813+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:20.813+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:32:20.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:20.851+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:32:20.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:32:51.767+0000] {processor.py:161} INFO - Started process (PID=39904) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:51.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:32:51.773+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:51.772+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:51.807+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:32:51.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:51.875+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:32:51.914+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:32:51.914+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:32:51.970+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T05:33:22.856+0000] {processor.py:161} INFO - Started process (PID=39935) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:22.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:33:22.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:22.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:22.904+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:22.973+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:22.973+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:33:23.011+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:23.011+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:33:23.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T05:33:53.459+0000] {processor.py:161} INFO - Started process (PID=39966) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:53.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:33:53.466+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:53.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:53.501+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:33:53.571+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:53.570+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:33:53.610+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:33:53.610+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:33:53.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:34:22.466+0000] {processor.py:161} INFO - Started process (PID=39997) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:22.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:34:22.481+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:22.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:22.521+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:22.593+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:22.593+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:34:22.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:22.632+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:34:22.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T05:34:53.505+0000] {processor.py:161} INFO - Started process (PID=40040) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:53.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:34:53.511+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:53.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:53.544+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:34:53.613+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:53.612+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:34:53.650+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:34:53.649+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:34:53.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.211 seconds
[2024-05-01T05:35:24.541+0000] {processor.py:161} INFO - Started process (PID=40071) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:24.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:35:24.547+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:24.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:24.581+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:24.650+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:24.649+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:35:24.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:24.687+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:35:24.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T05:35:55.477+0000] {processor.py:161} INFO - Started process (PID=40102) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:55.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:35:55.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:55.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:55.519+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:35:55.600+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:55.599+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:35:55.660+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:35:55.659+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:35:55.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.268 seconds
[2024-05-01T05:36:26.532+0000] {processor.py:161} INFO - Started process (PID=40133) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:26.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:36:26.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:26.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:26.574+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:26.644+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:26.643+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:36:26.682+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:26.681+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:36:26.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T05:36:57.573+0000] {processor.py:161} INFO - Started process (PID=40164) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:57.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:36:57.580+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:57.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:57.613+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:36:57.682+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:57.681+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:36:57.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:36:57.719+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:36:57.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T05:37:28.544+0000] {processor.py:161} INFO - Started process (PID=40195) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:28.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:37:28.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:28.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:28.590+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:28.661+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:28.661+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:37:28.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:28.699+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:37:28.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T05:37:59.613+0000] {processor.py:161} INFO - Started process (PID=40226) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:59.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:37:59.620+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:59.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:59.654+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:37:59.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:59.723+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:37:59.763+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:37:59.762+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:37:59.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T05:38:03.691+0000] {processor.py:161} INFO - Started process (PID=40231) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:03.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:38:03.697+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:03.696+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:03.737+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:04.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:04.136+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:38:04.171+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:04.170+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:38:04.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.556 seconds
[2024-05-01T05:38:34.367+0000] {processor.py:161} INFO - Started process (PID=40271) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:34.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:38:34.377+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:34.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:34.433+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:38:34.562+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:34.560+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:38:34.644+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:38:34.643+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:38:34.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.408 seconds
[2024-05-01T05:39:05.402+0000] {processor.py:161} INFO - Started process (PID=40307) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:05.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:39:05.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:05.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:05.443+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:05.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:05.512+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:39:05.550+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:05.549+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:39:05.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T05:39:36.380+0000] {processor.py:161} INFO - Started process (PID=40338) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:36.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:39:36.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:36.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:36.420+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:39:36.504+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:36.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:39:36.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:39:36.545+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:39:36.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T05:40:05.232+0000] {processor.py:161} INFO - Started process (PID=40369) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:05.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:40:05.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:05.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:05.280+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:05.362+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:05.361+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:40:05.405+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:05.404+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:40:05.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T05:40:36.382+0000] {processor.py:161} INFO - Started process (PID=40400) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:36.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:40:36.389+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:36.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:36.424+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:40:36.495+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:36.495+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:40:36.536+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:40:36.535+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:40:36.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T05:41:02.929+0000] {processor.py:161} INFO - Started process (PID=40421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:02.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:41:02.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:02.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:02.975+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:03.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:03.336+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:41:03.369+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:03.368+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:41:03.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.512 seconds
[2024-05-01T05:41:33.745+0000] {processor.py:161} INFO - Started process (PID=40464) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:33.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:41:33.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:33.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:33.786+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:41:33.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:33.858+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:41:33.896+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:41:33.895+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:41:33.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T05:42:04.331+0000] {processor.py:161} INFO - Started process (PID=40497) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:04.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:42:04.338+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:04.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:04.373+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:04.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:04.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:42:04.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:04.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:42:04.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T05:42:34.850+0000] {processor.py:161} INFO - Started process (PID=40528) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:34.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:42:34.857+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:34.856+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:34.897+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:42:34.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:34.980+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:42:35.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:42:35.018+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:42:35.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T05:43:05.432+0000] {processor.py:161} INFO - Started process (PID=40559) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:05.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:43:05.437+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:05.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:05.471+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:05.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:05.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:43:05.579+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:05.578+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:43:05.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T05:43:35.809+0000] {processor.py:161} INFO - Started process (PID=40590) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:35.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:43:35.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:35.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:35.871+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:43:35.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:35.970+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:43:36.022+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:43:36.021+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:43:36.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.295 seconds
[2024-05-01T05:44:06.717+0000] {processor.py:161} INFO - Started process (PID=40621) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:06.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:44:06.723+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:06.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:06.757+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:06.838+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:06.837+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:44:06.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:06.876+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:44:06.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T05:44:37.749+0000] {processor.py:161} INFO - Started process (PID=40652) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:37.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:44:37.756+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:37.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:37.790+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:44:37.862+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:37.861+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:44:37.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:44:37.901+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:44:37.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T05:45:08.276+0000] {processor.py:161} INFO - Started process (PID=40683) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:08.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:45:08.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:08.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:08.322+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:08.400+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:08.400+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:45:08.438+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:08.438+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:45:08.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T05:45:38.603+0000] {processor.py:161} INFO - Started process (PID=40714) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:38.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:45:38.610+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:38.609+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:38.644+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:45:38.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:38.724+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:45:38.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:45:38.765+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:45:38.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T05:46:09.699+0000] {processor.py:161} INFO - Started process (PID=40745) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:09.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:46:09.704+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:09.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:09.741+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:09.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:09.807+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:46:09.846+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:09.845+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:46:09.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.263 seconds
[2024-05-01T05:46:40.659+0000] {processor.py:161} INFO - Started process (PID=40776) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:40.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:46:40.665+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:40.664+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:40.701+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:46:40.781+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:40.780+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:46:40.838+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:46:40.837+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:46:40.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.257 seconds
[2024-05-01T05:47:11.052+0000] {processor.py:161} INFO - Started process (PID=40807) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:11.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:47:11.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:11.057+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:11.092+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:11.180+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:11.180+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:47:11.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:11.230+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:47:11.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T05:47:41.420+0000] {processor.py:161} INFO - Started process (PID=40838) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:41.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:47:41.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:41.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:41.461+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:47:41.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:41.540+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:47:41.588+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:47:41.587+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:47:41.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T05:48:12.559+0000] {processor.py:161} INFO - Started process (PID=40869) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:12.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:48:12.564+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:12.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:12.598+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:12.666+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:12.666+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:48:12.704+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:12.704+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:48:12.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.210 seconds
[2024-05-01T05:48:43.624+0000] {processor.py:161} INFO - Started process (PID=40900) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:43.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:48:43.635+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:43.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:43.683+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:48:43.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:43.753+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:48:43.793+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:48:43.792+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:48:43.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T05:49:14.834+0000] {processor.py:161} INFO - Started process (PID=40931) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:14.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:49:14.840+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:14.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:14.875+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:14.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:14.946+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:49:14.989+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:14.988+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:49:15.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:49:45.823+0000] {processor.py:161} INFO - Started process (PID=40962) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:45.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:49:45.830+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:45.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:45.863+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:49:45.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:45.932+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:49:45.972+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:49:45.971+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:49:46.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T05:50:16.652+0000] {processor.py:161} INFO - Started process (PID=40993) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:16.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:50:16.659+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:16.658+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:16.694+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:16.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:16.766+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:50:16.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:16.806+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:50:16.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T05:50:47.924+0000] {processor.py:161} INFO - Started process (PID=41030) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:47.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:50:47.930+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:47.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:47.969+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:50:48.042+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:48.041+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:50:48.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:50:48.085+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:50:48.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T05:51:18.956+0000] {processor.py:161} INFO - Started process (PID=41061) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:18.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:51:18.962+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:18.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:18.997+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:19.069+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:19.068+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:51:19.112+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:19.111+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:51:19.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T05:51:50.018+0000] {processor.py:161} INFO - Started process (PID=41093) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:50.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:51:50.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:50.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:50.062+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:51:50.133+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:50.132+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:51:50.172+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:51:50.171+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:51:50.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T05:52:21.038+0000] {processor.py:161} INFO - Started process (PID=41125) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:21.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:52:21.044+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:21.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:21.079+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:21.150+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:21.149+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:52:21.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:21.188+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:52:21.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T05:52:52.016+0000] {processor.py:161} INFO - Started process (PID=41156) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:52.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:52:52.022+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:52.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:52.057+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:52:52.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:52.126+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:52:52.167+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:52:52.166+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:52:52.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:53:23.028+0000] {processor.py:161} INFO - Started process (PID=41187) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:23.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:53:23.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:23.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:23.069+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:23.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:23.140+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:53:23.182+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:23.182+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:53:23.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T05:53:54.052+0000] {processor.py:161} INFO - Started process (PID=41219) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:54.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:53:54.060+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:54.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:54.096+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:53:54.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:54.168+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:53:54.207+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:53:54.207+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:53:54.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T05:54:25.069+0000] {processor.py:161} INFO - Started process (PID=41250) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:25.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:54:25.074+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:25.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:25.109+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:25.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:25.183+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:54:25.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:25.229+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:54:25.288+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T05:54:56.102+0000] {processor.py:161} INFO - Started process (PID=41281) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:56.105+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:54:56.108+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:56.107+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:56.143+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:54:56.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:56.212+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:54:56.252+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:54:56.251+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:54:56.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:55:27.246+0000] {processor.py:161} INFO - Started process (PID=41313) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:27.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:55:27.253+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:27.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:27.288+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:27.370+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:27.369+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:55:27.422+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:27.421+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:55:27.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.248 seconds
[2024-05-01T05:55:30.311+0000] {processor.py:161} INFO - Started process (PID=41318) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:30.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:55:30.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:30.317+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:30.364+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:30.800+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:30.799+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:55:30.840+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:30.839+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:55:30.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.616 seconds
[2024-05-01T05:55:48.194+0000] {processor.py:161} INFO - Started process (PID=41333) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:48.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:55:48.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:48.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:48.240+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:55:48.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:48.274+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:55:48.314+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:55:48.314+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:55:48.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.194 seconds
[2024-05-01T05:56:18.552+0000] {processor.py:161} INFO - Started process (PID=41375) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:18.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:56:18.559+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:18.558+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:18.604+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:19.017+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:19.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:56:19.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:19.057+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:56:19.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.595 seconds
[2024-05-01T05:56:49.354+0000] {processor.py:161} INFO - Started process (PID=41406) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:49.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:56:49.360+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:49.358+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:49.395+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:56:49.467+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:49.467+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:56:49.516+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:56:49.515+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:56:49.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T05:57:17.287+0000] {processor.py:161} INFO - Started process (PID=41437) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:17.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:57:17.293+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:17.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:17.335+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:17.686+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:17.686+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:57:17.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:17.719+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:57:17.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.504 seconds
[2024-05-01T05:57:47.911+0000] {processor.py:161} INFO - Started process (PID=41480) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:47.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:57:47.916+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:47.915+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:47.950+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:57:48.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:48.019+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:57:48.057+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:57:48.056+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:57:48.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T05:58:18.886+0000] {processor.py:161} INFO - Started process (PID=41511) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:18.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:58:18.893+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:18.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:18.931+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:19.001+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:19.001+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:58:19.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:19.039+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:58:19.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T05:58:49.909+0000] {processor.py:161} INFO - Started process (PID=41542) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:49.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:58:49.974+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:49.973+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:50.008+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:58:50.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:50.077+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:58:50.120+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:58:50.119+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:58:50.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.286 seconds
[2024-05-01T05:59:20.870+0000] {processor.py:161} INFO - Started process (PID=41580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:20.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:59:20.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:20.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:20.912+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:20.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:20.991+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:59:21.031+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:21.030+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:59:21.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T05:59:51.838+0000] {processor.py:161} INFO - Started process (PID=41611) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:51.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T05:59:51.844+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:51.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:51.878+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T05:59:51.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:51.947+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T05:59:51.985+0000] {logging_mixin.py:188} INFO - [2024-05-01T05:59:51.984+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T05:59:52.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T06:00:22.789+0000] {processor.py:161} INFO - Started process (PID=41642) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:22.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:00:22.796+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:22.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:22.832+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:22.904+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:22.903+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:00:22.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:22.941+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:00:22.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T06:00:53.687+0000] {processor.py:161} INFO - Started process (PID=41673) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:53.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:00:53.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:53.693+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:53.730+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:00:53.805+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:53.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:00:53.843+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:00:53.842+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:00:53.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T06:01:24.825+0000] {processor.py:161} INFO - Started process (PID=41704) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:24.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:01:24.839+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:24.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:24.884+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:24.954+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:24.953+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:01:24.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:24.991+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:01:25.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T06:01:55.122+0000] {processor.py:161} INFO - Started process (PID=41735) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:55.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:01:55.128+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:55.127+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:55.163+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:01:55.233+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:55.233+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:01:55.274+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:01:55.273+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:01:55.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T06:02:25.650+0000] {processor.py:161} INFO - Started process (PID=41766) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:25.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:02:25.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:25.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:25.692+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:25.762+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:25.762+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:02:25.800+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:25.799+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:02:25.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:02:56.198+0000] {processor.py:161} INFO - Started process (PID=41797) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:56.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:02:56.204+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:56.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:56.239+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:02:56.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:56.310+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:02:56.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:02:56.347+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:02:56.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T06:03:26.524+0000] {processor.py:161} INFO - Started process (PID=41828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:26.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:03:26.530+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:26.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:26.565+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:26.635+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:26.634+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:03:26.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:26.674+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:03:26.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:03:57.592+0000] {processor.py:161} INFO - Started process (PID=41859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:57.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:03:57.598+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:57.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:57.633+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:03:57.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:57.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:03:57.740+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:03:57.740+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:03:57.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:04:28.321+0000] {processor.py:161} INFO - Started process (PID=41890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:28.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:04:28.329+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:28.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:28.363+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:28.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:28.435+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:04:28.473+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:28.473+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:04:28.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T06:04:59.393+0000] {processor.py:161} INFO - Started process (PID=41921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:59.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:04:59.400+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:59.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:59.434+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:04:59.504+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:59.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:04:59.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:04:59.541+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:04:59.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:05:30.427+0000] {processor.py:161} INFO - Started process (PID=41952) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:05:30.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:05:30.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:05:30.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:05:30.469+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:05:30.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:05:30.539+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:05:30.577+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:05:30.576+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:05:30.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:06:01.444+0000] {processor.py:161} INFO - Started process (PID=41983) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:01.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:06:01.457+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:01.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:01.496+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:01.567+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:01.566+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:06:01.607+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:01.606+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:06:01.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T06:06:32.379+0000] {processor.py:161} INFO - Started process (PID=42014) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:32.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:06:32.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:32.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:32.420+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:06:32.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:32.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:06:32.528+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:06:32.527+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:06:32.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:07:03.358+0000] {processor.py:161} INFO - Started process (PID=42045) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:03.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:07:03.365+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:03.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:03.400+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:03.470+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:03.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:07:03.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:03.507+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:07:03.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:07:34.427+0000] {processor.py:161} INFO - Started process (PID=42076) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:34.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:07:34.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:34.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:34.468+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:07:34.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:34.538+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:07:34.576+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:07:34.575+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:07:34.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:08:05.421+0000] {processor.py:161} INFO - Started process (PID=42107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:05.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:08:05.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:05.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:05.462+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:05.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:05.531+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:08:05.570+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:05.569+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:08:05.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:08:36.407+0000] {processor.py:161} INFO - Started process (PID=42139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:36.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:08:36.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:36.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:36.447+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:08:36.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:36.518+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:08:36.559+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:08:36.558+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:08:36.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T06:09:07.420+0000] {processor.py:161} INFO - Started process (PID=42170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:07.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:09:07.425+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:07.424+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:07.460+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:07.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:07.531+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:09:07.570+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:07.569+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:09:07.626+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:09:38.561+0000] {processor.py:161} INFO - Started process (PID=42201) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:38.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:09:38.570+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:38.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:38.619+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:09:38.692+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:38.691+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:09:38.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:09:38.730+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:09:38.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T06:10:09.557+0000] {processor.py:161} INFO - Started process (PID=42232) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:09.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:10:09.564+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:09.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:09.603+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:09.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:09.674+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:10:09.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:09.712+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:10:09.770+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T06:10:40.646+0000] {processor.py:161} INFO - Started process (PID=42263) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:40.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:10:40.653+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:40.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:40.687+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:10:40.758+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:40.757+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:10:40.799+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:10:40.798+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:10:40.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.253 seconds
[2024-05-01T06:11:11.719+0000] {processor.py:161} INFO - Started process (PID=42294) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:11.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:11:11.727+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:11.726+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:11.769+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:11.857+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:11.857+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:11:11.897+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:11.897+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:11:11.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.250 seconds
[2024-05-01T06:11:42.721+0000] {processor.py:161} INFO - Started process (PID=42325) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:42.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:11:42.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:42.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:42.763+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:11:42.832+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:42.831+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:11:42.870+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:11:42.869+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:11:42.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:12:13.718+0000] {processor.py:161} INFO - Started process (PID=42356) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:13.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:12:13.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:13.723+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:13.759+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:13.827+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:13.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:12:13.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:13.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:12:13.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T06:12:44.691+0000] {processor.py:161} INFO - Started process (PID=42387) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:44.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:12:44.697+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:44.696+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:44.732+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:12:44.801+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:44.800+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:12:44.838+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:12:44.838+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:12:44.893+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.212 seconds
[2024-05-01T06:13:15.644+0000] {processor.py:161} INFO - Started process (PID=42418) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:15.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:13:15.650+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:15.649+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:15.686+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:15.756+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:15.755+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:13:15.793+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:15.793+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:13:15.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:13:46.725+0000] {processor.py:161} INFO - Started process (PID=42449) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:46.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:13:46.731+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:46.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:46.765+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:13:46.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:46.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:13:46.887+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:13:46.886+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:13:46.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T06:14:17.838+0000] {processor.py:161} INFO - Started process (PID=42480) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:17.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:14:17.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:17.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:17.880+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:17.949+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:17.949+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:14:17.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:17.986+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:14:18.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:14:48.810+0000] {processor.py:161} INFO - Started process (PID=42511) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:48.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:14:48.817+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:48.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:48.852+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:14:48.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:48.921+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:14:48.959+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:14:48.958+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:14:49.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:15:19.868+0000] {processor.py:161} INFO - Started process (PID=42544) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:19.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:15:19.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:19.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:19.908+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:19.979+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:19.979+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:15:20.018+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:20.017+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:15:20.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:15:50.910+0000] {processor.py:161} INFO - Started process (PID=42575) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:50.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:15:50.916+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:50.915+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:50.951+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:15:51.020+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:51.019+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:15:51.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:15:51.057+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:15:51.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:16:21.956+0000] {processor.py:161} INFO - Started process (PID=42606) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:21.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:16:21.962+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:21.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:21.997+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:22.066+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:22.066+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:16:22.107+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:22.106+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:16:22.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:16:52.962+0000] {processor.py:161} INFO - Started process (PID=42637) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:52.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:16:52.969+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:52.968+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:53.003+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:16:53.082+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:53.081+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:16:53.122+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:16:53.121+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:16:53.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T06:17:23.647+0000] {processor.py:161} INFO - Started process (PID=42668) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:23.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:17:23.653+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:23.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:23.688+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:23.759+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:23.758+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:17:23.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:23.796+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:17:23.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:17:54.698+0000] {processor.py:161} INFO - Started process (PID=42699) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:54.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:17:54.705+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:54.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:54.739+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:17:54.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:54.809+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:17:54.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:17:54.849+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:17:54.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:18:25.683+0000] {processor.py:161} INFO - Started process (PID=42730) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:25.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:18:25.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:25.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:25.723+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:25.798+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:25.797+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:18:25.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:25.848+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:18:25.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T06:18:56.708+0000] {processor.py:161} INFO - Started process (PID=42761) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:56.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:18:56.716+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:56.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:56.770+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:18:56.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:56.859+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:18:56.898+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:18:56.897+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:18:56.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.263 seconds
[2024-05-01T06:19:27.838+0000] {processor.py:161} INFO - Started process (PID=42798) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:27.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:19:27.843+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:27.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:27.880+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:27.952+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:27.951+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:19:27.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:27.989+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:19:28.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:19:58.325+0000] {processor.py:161} INFO - Started process (PID=42829) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:58.329+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:19:58.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:58.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:58.369+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:19:58.438+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:58.438+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:19:58.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:19:58.475+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:19:58.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:20:29.278+0000] {processor.py:161} INFO - Started process (PID=42860) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:20:29.282+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:20:29.285+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:20:29.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:20:29.320+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:20:29.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:20:29.393+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:20:29.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:20:29.433+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:20:29.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T06:21:00.468+0000] {processor.py:161} INFO - Started process (PID=42891) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:00.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:21:00.474+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:00.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:00.509+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:00.577+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:00.576+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:21:00.614+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:00.614+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:21:00.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.212 seconds
[2024-05-01T06:21:31.026+0000] {processor.py:161} INFO - Started process (PID=42922) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:31.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:21:31.033+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:31.032+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:31.067+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:21:31.136+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:31.135+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:21:31.173+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:21:31.172+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:21:31.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:22:02.190+0000] {processor.py:161} INFO - Started process (PID=42953) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:02.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:22:02.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:02.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:02.245+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:02.317+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:02.317+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:22:02.355+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:02.355+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:22:02.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T06:22:32.759+0000] {processor.py:161} INFO - Started process (PID=42984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:32.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:22:32.765+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:32.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:32.799+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:22:32.868+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:32.868+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:22:32.906+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:22:32.905+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:22:33.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.268 seconds
[2024-05-01T06:23:03.790+0000] {processor.py:161} INFO - Started process (PID=43015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:03.794+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:23:03.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:03.796+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:03.833+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:03.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:03.901+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:23:03.942+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:03.942+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:23:03.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T06:23:34.602+0000] {processor.py:161} INFO - Started process (PID=43046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:34.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:23:34.609+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:34.608+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:34.647+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:23:34.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:34.727+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:23:34.768+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:23:34.767+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:23:34.825+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T06:24:05.700+0000] {processor.py:161} INFO - Started process (PID=43077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:05.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:24:05.706+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:05.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:05.741+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:05.809+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:05.808+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:24:05.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:05.846+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:24:05.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:24:36.614+0000] {processor.py:161} INFO - Started process (PID=43108) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:36.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:24:36.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:36.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:36.656+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:24:36.727+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:36.726+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:24:36.765+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:24:36.764+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:24:36.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:25:07.544+0000] {processor.py:161} INFO - Started process (PID=43139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:07.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:25:07.552+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:07.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:07.588+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:07.693+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:07.692+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:25:07.756+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:07.756+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:25:07.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.284 seconds
[2024-05-01T06:25:38.520+0000] {processor.py:161} INFO - Started process (PID=43170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:38.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:25:38.527+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:38.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:38.563+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:25:38.699+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:38.698+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:25:38.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:25:38.743+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:25:38.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.293 seconds
[2024-05-01T06:26:09.072+0000] {processor.py:161} INFO - Started process (PID=43201) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:09.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:26:09.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:09.078+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:09.114+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:09.184+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:09.183+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:26:09.222+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:09.221+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:26:09.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:26:39.624+0000] {processor.py:161} INFO - Started process (PID=43233) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:39.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:26:39.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:39.631+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:39.680+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:26:39.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:39.752+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:26:39.791+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:26:39.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:26:39.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T06:27:10.544+0000] {processor.py:161} INFO - Started process (PID=43264) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:10.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:27:10.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:10.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:10.590+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:10.659+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:10.658+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:27:10.699+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:10.698+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:27:10.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T06:27:41.447+0000] {processor.py:161} INFO - Started process (PID=43295) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:41.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:27:41.453+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:41.452+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:41.488+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:27:41.557+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:41.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:27:41.596+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:27:41.596+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:27:41.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.277 seconds
[2024-05-01T06:28:12.364+0000] {processor.py:161} INFO - Started process (PID=43326) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:12.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:28:12.370+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:12.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:12.404+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:12.474+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:12.473+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:28:12.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:12.528+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:28:12.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T06:28:43.368+0000] {processor.py:161} INFO - Started process (PID=43357) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:43.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:28:43.376+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:43.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:43.414+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:28:43.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:43.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:28:43.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:28:43.528+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:28:43.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T06:29:14.396+0000] {processor.py:161} INFO - Started process (PID=43388) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:14.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:29:14.407+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:14.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:14.441+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:14.511+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:14.510+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:29:14.554+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:14.553+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:29:14.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T06:29:45.349+0000] {processor.py:161} INFO - Started process (PID=43419) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:45.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:29:45.355+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:45.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:45.389+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:29:45.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:45.458+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:29:45.496+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:29:45.496+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:29:45.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T06:30:16.388+0000] {processor.py:161} INFO - Started process (PID=43453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:16.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:30:16.400+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:16.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:16.444+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:16.517+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:16.517+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:30:16.557+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:16.557+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:30:16.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T06:30:46.964+0000] {processor.py:161} INFO - Started process (PID=43484) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:46.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:30:46.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:46.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:47.004+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:30:47.073+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:47.072+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:30:47.111+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:30:47.110+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:30:47.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.211 seconds
[2024-05-01T06:31:17.918+0000] {processor.py:161} INFO - Started process (PID=43515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:17.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:31:17.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:17.923+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:17.959+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:18.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:18.027+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:31:18.065+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:18.064+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:31:18.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:31:48.835+0000] {processor.py:161} INFO - Started process (PID=43546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:48.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:31:48.842+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:48.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:48.877+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:31:48.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:48.946+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:31:48.985+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:31:48.984+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:31:49.040+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:32:19.801+0000] {processor.py:161} INFO - Started process (PID=43577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:19.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:32:19.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:19.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:19.841+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:19.911+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:19.910+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:32:19.949+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:19.948+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:32:20.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T06:32:50.725+0000] {processor.py:161} INFO - Started process (PID=43608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:50.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:32:50.732+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:50.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:50.766+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:32:50.835+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:50.834+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:32:50.873+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:32:50.872+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:32:50.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:33:21.655+0000] {processor.py:161} INFO - Started process (PID=43640) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:21.658+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:33:21.661+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:21.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:21.700+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:21.774+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:21.773+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:33:21.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:21.811+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:33:21.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T06:33:52.615+0000] {processor.py:161} INFO - Started process (PID=43671) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:52.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:33:52.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:52.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:52.655+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:33:52.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:52.723+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:33:52.761+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:33:52.761+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:33:52.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:34:23.454+0000] {processor.py:161} INFO - Started process (PID=43702) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:23.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:34:23.460+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:23.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:23.494+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:23.565+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:23.564+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:34:23.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:23.602+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:34:23.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:34:54.450+0000] {processor.py:161} INFO - Started process (PID=43733) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:54.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:34:54.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:54.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:54.490+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:34:54.569+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:54.568+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:34:54.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:34:54.623+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:34:54.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.253 seconds
[2024-05-01T06:35:25.207+0000] {processor.py:161} INFO - Started process (PID=43764) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:25.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:35:25.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:25.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:25.247+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:25.319+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:25.318+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:35:25.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:25.356+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:35:25.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:35:56.337+0000] {processor.py:161} INFO - Started process (PID=43795) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:56.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:35:56.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:56.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:56.381+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:35:56.450+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:56.449+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:35:56.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:35:56.487+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:35:56.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:36:27.290+0000] {processor.py:161} INFO - Started process (PID=43827) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:27.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:36:27.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:27.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:27.336+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:27.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:27.405+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:36:27.443+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:27.442+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:36:27.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:36:58.228+0000] {processor.py:161} INFO - Started process (PID=43858) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:58.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:36:58.235+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:58.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:58.274+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:36:58.352+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:58.352+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:36:58.390+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:36:58.389+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:36:58.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T06:37:29.226+0000] {processor.py:161} INFO - Started process (PID=43889) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:37:29.231+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:37:29.235+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:37:29.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:37:29.269+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:37:29.339+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:37:29.339+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:37:29.378+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:37:29.377+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:37:29.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T06:38:00.194+0000] {processor.py:161} INFO - Started process (PID=43920) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:00.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:38:00.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:00.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:00.236+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:00.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:00.307+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:38:00.346+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:00.346+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:38:00.402+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:38:31.115+0000] {processor.py:161} INFO - Started process (PID=43951) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:31.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:38:31.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:31.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:31.158+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:38:31.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:31.226+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:38:31.265+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:38:31.264+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:38:31.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:39:01.708+0000] {processor.py:161} INFO - Started process (PID=43982) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:01.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:39:01.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:01.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:01.750+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:01.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:01.822+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:39:01.860+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:01.860+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:39:01.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T06:39:32.702+0000] {processor.py:161} INFO - Started process (PID=44013) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:32.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:39:32.710+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:32.709+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:32.756+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:39:32.841+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:32.840+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:39:32.882+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:39:32.881+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:39:32.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T06:40:03.699+0000] {processor.py:161} INFO - Started process (PID=44050) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:03.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:40:03.704+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:03.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:03.739+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:03.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:03.807+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:40:03.854+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:03.853+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:40:03.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T06:40:34.682+0000] {processor.py:161} INFO - Started process (PID=44081) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:34.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:40:34.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:34.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:34.723+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:40:34.796+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:34.796+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:40:34.841+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:40:34.840+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:40:35.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.656 seconds
[2024-05-01T06:41:05.461+0000] {processor.py:161} INFO - Started process (PID=44112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:05.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:41:05.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:05.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:05.503+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:05.577+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:05.576+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:41:05.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:05.632+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:41:05.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T06:41:36.337+0000] {processor.py:161} INFO - Started process (PID=44143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:36.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:41:36.344+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:36.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:36.378+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:41:36.449+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:36.448+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:41:36.487+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:41:36.486+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:41:36.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T06:42:07.296+0000] {processor.py:161} INFO - Started process (PID=44175) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:07.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:42:07.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:07.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:07.337+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:07.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:07.407+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:42:07.446+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:07.445+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:42:07.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T06:42:38.051+0000] {processor.py:161} INFO - Started process (PID=44206) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:38.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:42:38.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:38.057+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:38.092+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:42:38.164+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:38.163+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:42:38.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:42:38.201+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:42:38.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T06:43:08.904+0000] {processor.py:161} INFO - Started process (PID=44237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:08.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:43:08.910+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:08.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:08.945+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:09.017+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:09.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:43:09.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:09.055+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:43:09.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T06:43:40.176+0000] {processor.py:161} INFO - Started process (PID=44269) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:40.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:43:40.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:40.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:40.217+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:43:40.288+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:40.287+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:43:40.326+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:43:40.325+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:43:40.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T06:44:11.460+0000] {processor.py:161} INFO - Started process (PID=44300) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:11.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:44:11.471+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:11.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:11.506+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:11.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:11.575+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:44:11.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:11.612+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:44:11.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:44:42.615+0000] {processor.py:161} INFO - Started process (PID=44331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:42.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:44:42.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:42.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:42.655+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:44:42.724+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:42.723+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:44:42.762+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:44:42.761+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:44:42.817+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.212 seconds
[2024-05-01T06:45:13.528+0000] {processor.py:161} INFO - Started process (PID=44362) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:13.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:45:13.535+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:13.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:13.570+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:13.640+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:13.639+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:45:13.678+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:13.678+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:45:14.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.707 seconds
[2024-05-01T06:45:44.614+0000] {processor.py:161} INFO - Started process (PID=44393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:44.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:45:44.620+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:44.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:44.656+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:45:44.725+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:44.724+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:45:44.763+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:45:44.762+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:45:44.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:46:15.579+0000] {processor.py:161} INFO - Started process (PID=44424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:15.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:46:15.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:15.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:15.619+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:15.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:15.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:46:15.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:15.725+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:46:15.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.211 seconds
[2024-05-01T06:46:46.521+0000] {processor.py:161} INFO - Started process (PID=44455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:46.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:46:46.528+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:46.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:46.567+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:46:46.638+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:46.638+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:46:46.679+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:46:46.678+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:46:47.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.646 seconds
[2024-05-01T06:47:17.346+0000] {processor.py:161} INFO - Started process (PID=44486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:17.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:47:17.353+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:17.352+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:17.389+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:17.886+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:17.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:47:17.919+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:17.918+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:47:17.972+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T06:47:48.390+0000] {processor.py:161} INFO - Started process (PID=44517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:48.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:47:48.397+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:48.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:48.432+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:47:48.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:48.502+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:47:48.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:47:48.540+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:47:48.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T06:48:18.859+0000] {processor.py:161} INFO - Started process (PID=44549) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:18.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:48:18.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:18.864+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:18.900+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:18.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:18.970+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:48:19.011+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:19.011+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:48:19.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.697 seconds
[2024-05-01T06:48:49.833+0000] {processor.py:161} INFO - Started process (PID=44580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:49.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:48:49.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:49.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:49.883+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:48:50.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:50.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:48:50.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:48:50.418+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:48:50.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.659 seconds
[2024-05-01T06:49:20.574+0000] {processor.py:161} INFO - Started process (PID=44611) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:20.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:49:20.580+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:20.579+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:20.614+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:20.683+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:20.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:49:20.721+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:20.720+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:49:20.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T06:49:51.564+0000] {processor.py:161} INFO - Started process (PID=44642) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:51.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:49:51.570+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:51.569+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:51.605+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:49:51.675+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:51.674+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:49:51.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:49:51.714+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:49:52.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.646 seconds
[2024-05-01T06:50:22.663+0000] {processor.py:161} INFO - Started process (PID=44673) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:22.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:50:22.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:22.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:22.705+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:22.775+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:22.774+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:50:22.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:22.812+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:50:22.868+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:50:53.636+0000] {processor.py:161} INFO - Started process (PID=44704) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:53.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:50:53.643+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:53.642+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:53.678+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:50:53.747+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:53.746+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:50:53.785+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:50:53.784+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:50:53.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:51:24.282+0000] {processor.py:161} INFO - Started process (PID=44735) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:24.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:51:24.289+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:24.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:24.323+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:24.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:24.394+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:51:24.867+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:24.866+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:51:24.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.647 seconds
[2024-05-01T06:51:55.277+0000] {processor.py:161} INFO - Started process (PID=44765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:55.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:51:55.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:55.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:55.317+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:51:55.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:55.822+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:51:55.855+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:51:55.854+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:51:55.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.641 seconds
[2024-05-01T06:52:26.049+0000] {processor.py:161} INFO - Started process (PID=44796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:26.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:52:26.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:26.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:26.090+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:26.161+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:26.161+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:52:26.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:26.198+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:52:26.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T06:52:56.404+0000] {processor.py:161} INFO - Started process (PID=44827) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:56.408+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:52:56.411+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:56.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:56.446+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:52:56.516+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:56.515+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:52:56.983+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:52:56.982+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:52:57.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.641 seconds
[2024-05-01T06:53:28.067+0000] {processor.py:161} INFO - Started process (PID=44858) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:28.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:53:28.074+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:28.073+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:28.108+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:28.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:28.611+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:53:28.645+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:28.645+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:53:28.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T06:53:59.716+0000] {processor.py:161} INFO - Started process (PID=44889) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:59.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:53:59.723+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:59.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:59.759+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:53:59.828+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:59.828+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:53:59.866+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:53:59.865+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:53:59.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T06:54:30.284+0000] {processor.py:161} INFO - Started process (PID=44920) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:54:30.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:54:30.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:54:30.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:54:30.329+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:54:30.402+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:54:30.401+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:54:30.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:54:30.865+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:54:30.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.644 seconds
[2024-05-01T06:55:01.299+0000] {processor.py:161} INFO - Started process (PID=44951) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:01.302+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:55:01.305+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:01.304+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:01.340+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:01.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:01.874+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:55:01.907+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:01.906+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:55:01.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.669 seconds
[2024-05-01T06:55:33.058+0000] {processor.py:161} INFO - Started process (PID=44982) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:33.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:55:33.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:33.067+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:33.119+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:55:33.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:33.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:55:33.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:55:33.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:55:33.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T06:56:03.617+0000] {processor.py:161} INFO - Started process (PID=45013) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:03.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:56:03.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:03.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:03.664+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:03.736+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:03.735+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:56:04.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:04.198+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:56:04.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.645 seconds
[2024-05-01T06:56:34.668+0000] {processor.py:161} INFO - Started process (PID=45044) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:34.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:56:34.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:34.673+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:34.709+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:56:35.211+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:35.210+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:56:35.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:56:35.243+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:56:35.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.640 seconds
[2024-05-01T06:57:06.054+0000] {processor.py:161} INFO - Started process (PID=45075) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:06.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:57:06.060+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:06.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:06.094+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:06.166+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:06.165+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:57:06.205+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:06.205+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:57:06.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:57:36.663+0000] {processor.py:161} INFO - Started process (PID=45107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:36.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:57:36.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:36.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:36.711+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:57:36.782+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:36.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:57:37.272+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:57:37.271+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:57:37.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.679 seconds
[2024-05-01T06:58:07.853+0000] {processor.py:161} INFO - Started process (PID=45138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:07.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:58:07.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:07.858+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:07.896+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:08.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:08.398+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:58:08.432+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:08.431+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:58:08.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T06:58:38.921+0000] {processor.py:161} INFO - Started process (PID=45169) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:38.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:58:38.928+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:38.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:38.963+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:58:39.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:39.033+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:58:39.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:58:39.071+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:58:39.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T06:59:09.815+0000] {processor.py:161} INFO - Started process (PID=45207) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:09.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:59:09.821+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:09.820+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:09.856+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:09.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:09.928+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:59:09.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:09.969+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:59:10.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T06:59:40.768+0000] {processor.py:161} INFO - Started process (PID=45238) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:40.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T06:59:40.781+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:40.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:40.849+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T06:59:40.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:40.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T06:59:40.963+0000] {logging_mixin.py:188} INFO - [2024-05-01T06:59:40.962+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T06:59:41.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.274 seconds
[2024-05-01T07:00:11.797+0000] {processor.py:161} INFO - Started process (PID=45269) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:11.801+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:00:11.804+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:11.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:11.838+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:11.912+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:11.911+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:00:11.949+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:11.948+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:00:12.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:00:42.896+0000] {processor.py:161} INFO - Started process (PID=45300) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:42.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:00:42.903+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:42.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:42.937+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:00:43.009+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:43.008+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:00:43.049+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:00:43.048+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:00:43.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:01:13.934+0000] {processor.py:161} INFO - Started process (PID=45331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:13.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:01:13.940+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:13.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:13.976+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:14.047+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:14.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:01:14.084+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:14.083+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:01:14.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:01:44.869+0000] {processor.py:161} INFO - Started process (PID=45362) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:44.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:01:44.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:44.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:44.911+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:01:44.982+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:44.981+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:01:45.020+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:01:45.019+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:01:45.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:02:15.992+0000] {processor.py:161} INFO - Started process (PID=45393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:15.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:02:16.000+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:15.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:16.035+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:16.104+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:16.103+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:02:16.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:16.143+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:02:16.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T07:02:46.944+0000] {processor.py:161} INFO - Started process (PID=45424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:46.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:02:46.950+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:46.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:46.984+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:02:47.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:47.054+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:02:47.093+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:02:47.092+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:02:47.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T07:03:17.821+0000] {processor.py:161} INFO - Started process (PID=45455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:17.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:03:17.827+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:17.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:17.862+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:17.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:17.932+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:03:17.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:17.970+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:03:18.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:03:48.731+0000] {processor.py:161} INFO - Started process (PID=45486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:48.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:03:48.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:48.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:48.773+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:03:48.844+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:48.843+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:03:48.884+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:03:48.884+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:03:48.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:04:19.677+0000] {processor.py:161} INFO - Started process (PID=45517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:19.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:04:19.684+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:19.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:19.719+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:19.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:19.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:04:19.851+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:19.850+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:04:19.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.257 seconds
[2024-05-01T07:04:50.817+0000] {processor.py:161} INFO - Started process (PID=45548) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:50.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:04:50.824+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:50.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:50.859+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:04:50.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:50.932+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:04:50.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:04:50.971+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:04:51.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:05:21.896+0000] {processor.py:161} INFO - Started process (PID=45579) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:21.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:05:21.910+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:21.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:21.972+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:22.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:22.050+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:05:22.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:22.090+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:05:22.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
[2024-05-01T07:05:52.881+0000] {processor.py:161} INFO - Started process (PID=45610) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:52.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:05:52.887+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:52.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:52.922+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:05:52.994+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:52.993+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:05:53.033+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:05:53.033+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:05:53.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T07:06:23.898+0000] {processor.py:161} INFO - Started process (PID=45641) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:23.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:06:23.904+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:23.903+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:23.938+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:24.018+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:24.017+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:06:24.069+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:24.068+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:06:24.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.252 seconds
[2024-05-01T07:06:54.212+0000] {processor.py:161} INFO - Started process (PID=45672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:54.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:06:54.219+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:54.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:54.254+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:06:54.326+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:54.326+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:06:54.377+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:06:54.376+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:06:54.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T07:07:24.663+0000] {processor.py:161} INFO - Started process (PID=45703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:24.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:07:24.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:24.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:24.710+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:24.809+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:24.808+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:07:24.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:24.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:07:24.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T07:07:55.269+0000] {processor.py:161} INFO - Started process (PID=45734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:55.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:07:55.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:55.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:55.310+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:07:55.382+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:55.381+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:07:55.420+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:07:55.419+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:07:55.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:08:25.715+0000] {processor.py:161} INFO - Started process (PID=45765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:25.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:08:25.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:25.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:25.755+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:25.834+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:25.833+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:08:25.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:25.880+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:08:25.936+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T07:08:56.187+0000] {processor.py:161} INFO - Started process (PID=45796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:56.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:08:56.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:56.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:56.228+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:08:56.300+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:56.299+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:08:56.338+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:08:56.337+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:08:56.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T07:09:26.668+0000] {processor.py:161} INFO - Started process (PID=45828) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:26.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:09:26.682+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:26.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:26.722+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:26.805+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:26.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:09:26.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:26.849+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:09:26.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.320 seconds
[2024-05-01T07:09:57.193+0000] {processor.py:161} INFO - Started process (PID=45859) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:57.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:09:57.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:57.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:57.233+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:09:57.307+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:57.306+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:09:57.344+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:09:57.344+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:09:57.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:10:27.605+0000] {processor.py:161} INFO - Started process (PID=45890) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:27.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:10:27.611+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:27.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:27.646+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:27.717+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:27.717+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:10:27.755+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:27.754+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:10:27.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:10:58.018+0000] {processor.py:161} INFO - Started process (PID=45921) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:58.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:10:58.024+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:58.023+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:58.059+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:10:58.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:58.129+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:10:58.168+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:10:58.167+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:10:58.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:11:28.484+0000] {processor.py:161} INFO - Started process (PID=45952) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:28.487+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:11:28.490+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:28.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:28.524+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:28.597+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:28.596+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:11:28.635+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:28.634+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:11:28.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:11:58.946+0000] {processor.py:161} INFO - Started process (PID=45983) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:58.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:11:58.952+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:58.951+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:58.987+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:11:59.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:59.057+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:11:59.096+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:11:59.095+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:11:59.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:12:29.398+0000] {processor.py:161} INFO - Started process (PID=46014) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:12:29.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:12:29.405+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:12:29.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:12:29.439+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:12:29.511+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:12:29.510+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:12:29.548+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:12:29.548+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:12:29.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:12:59.894+0000] {processor.py:161} INFO - Started process (PID=46045) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:12:59.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:12:59.901+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:12:59.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:12:59.935+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:13:00.009+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:13:00.008+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:13:00.046+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:13:00.045+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:13:00.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T07:13:30.368+0000] {processor.py:161} INFO - Started process (PID=46075) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:13:30.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:13:30.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:13:30.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:13:30.409+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:13:30.480+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:13:30.479+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:13:30.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:13:30.517+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:13:30.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:14:00.826+0000] {processor.py:161} INFO - Started process (PID=46107) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:00.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:14:00.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:00.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:00.868+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:00.939+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:00.939+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:14:00.977+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:00.976+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:14:01.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T07:14:31.390+0000] {processor.py:161} INFO - Started process (PID=46138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:31.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:14:31.402+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:31.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:31.476+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:14:31.554+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:31.553+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:14:31.592+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:14:31.591+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:14:31.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.273 seconds
[2024-05-01T07:15:01.947+0000] {processor.py:161} INFO - Started process (PID=46172) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:01.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:15:01.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:01.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:02.005+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:02.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:02.130+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:15:02.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:02.185+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:15:02.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.347 seconds
[2024-05-01T07:15:33.325+0000] {processor.py:161} INFO - Started process (PID=46204) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:33.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:15:33.331+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:33.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:33.366+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:15:33.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:33.433+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:15:33.472+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:15:33.471+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:15:33.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:16:04.198+0000] {processor.py:161} INFO - Started process (PID=46235) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:04.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:16:04.205+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:04.204+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:04.240+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:04.314+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:04.314+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:16:04.352+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:04.352+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:16:04.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:16:35.112+0000] {processor.py:161} INFO - Started process (PID=46266) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:35.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:16:35.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:35.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:35.153+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:16:35.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:35.224+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:16:35.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:16:35.262+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:16:35.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:17:06.206+0000] {processor.py:161} INFO - Started process (PID=46297) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:06.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:17:06.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:06.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:06.248+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:06.321+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:06.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:17:06.363+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:06.362+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:17:06.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T07:17:37.263+0000] {processor.py:161} INFO - Started process (PID=46328) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:37.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:17:37.269+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:37.268+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:37.304+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:17:37.377+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:37.376+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:17:37.414+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:17:37.414+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:17:37.471+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:18:08.220+0000] {processor.py:161} INFO - Started process (PID=46359) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:08.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:18:08.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:08.226+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:08.261+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:08.332+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:08.331+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:18:08.370+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:08.369+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:18:08.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:18:39.258+0000] {processor.py:161} INFO - Started process (PID=46390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:39.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:18:39.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:39.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:39.298+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:18:39.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:39.372+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:18:39.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:18:39.433+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:18:39.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.258 seconds
[2024-05-01T07:19:10.256+0000] {processor.py:161} INFO - Started process (PID=46421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:10.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:19:10.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:10.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:10.304+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:10.402+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:10.402+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:19:10.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:10.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:19:10.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.266 seconds
[2024-05-01T07:19:41.321+0000] {processor.py:161} INFO - Started process (PID=46452) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:41.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:19:41.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:41.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:41.361+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:19:41.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:41.433+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:19:41.471+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:19:41.470+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:19:41.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:20:12.318+0000] {processor.py:161} INFO - Started process (PID=46483) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:12.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:20:12.325+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:12.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:12.360+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:12.431+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:12.430+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:20:12.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:12.468+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:20:12.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:20:43.438+0000] {processor.py:161} INFO - Started process (PID=46513) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:43.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:20:43.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:43.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:43.479+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:20:43.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:43.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:20:43.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:20:43.588+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:20:43.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:21:14.320+0000] {processor.py:161} INFO - Started process (PID=46545) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:14.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:21:14.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:14.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:14.362+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:14.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:14.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:21:14.471+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:14.470+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:21:14.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:21:45.468+0000] {processor.py:161} INFO - Started process (PID=46576) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:45.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:21:45.475+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:45.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:45.518+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:21:45.587+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:45.587+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:21:45.625+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:21:45.624+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:21:45.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T07:22:16.446+0000] {processor.py:161} INFO - Started process (PID=46608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:16.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:22:16.452+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:16.451+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:16.487+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:16.572+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:16.571+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:22:16.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:16.620+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:22:16.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.263 seconds
[2024-05-01T07:22:47.541+0000] {processor.py:161} INFO - Started process (PID=46645) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:47.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:22:47.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:47.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:47.584+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:22:47.662+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:47.661+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:22:47.707+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:22:47.706+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:22:47.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T07:23:18.518+0000] {processor.py:161} INFO - Started process (PID=46676) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:18.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:23:18.524+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:18.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:18.559+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:18.629+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:18.629+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:23:18.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:18.667+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:23:18.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T07:23:48.838+0000] {processor.py:161} INFO - Started process (PID=46707) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:48.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:23:48.844+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:48.843+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:48.879+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:23:48.951+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:48.950+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:23:48.989+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:23:48.988+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:23:49.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T07:24:19.270+0000] {processor.py:161} INFO - Started process (PID=46739) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:19.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:24:19.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:19.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:19.313+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:19.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:19.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:24:19.424+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:19.423+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:24:19.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T07:24:49.695+0000] {processor.py:161} INFO - Started process (PID=46770) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:49.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:24:49.701+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:49.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:49.736+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:24:49.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:49.807+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:24:49.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:24:49.844+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:24:49.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:25:20.124+0000] {processor.py:161} INFO - Started process (PID=46801) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:20.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:25:20.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:20.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:20.165+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:20.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:20.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:25:20.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:20.277+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:25:20.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:25:50.737+0000] {processor.py:161} INFO - Started process (PID=46832) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:50.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:25:50.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:50.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:50.779+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:25:50.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:50.850+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:25:50.888+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:25:50.888+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:25:50.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:26:21.629+0000] {processor.py:161} INFO - Started process (PID=46863) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:21.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:26:21.635+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:21.634+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:21.671+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:21.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:21.752+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:26:21.791+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:21.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:26:21.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T07:26:52.796+0000] {processor.py:161} INFO - Started process (PID=46894) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:52.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:26:52.803+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:52.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:52.837+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:26:52.907+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:52.906+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:26:52.945+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:26:52.944+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:26:53.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:27:23.668+0000] {processor.py:161} INFO - Started process (PID=46925) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:23.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:27:23.675+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:23.674+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:23.709+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:23.782+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:23.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:27:23.821+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:23.820+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:27:23.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:27:54.590+0000] {processor.py:161} INFO - Started process (PID=46956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:54.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:27:54.596+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:54.595+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:54.631+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:27:54.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:54.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:27:54.741+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:27:54.740+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:27:54.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:28:25.453+0000] {processor.py:161} INFO - Started process (PID=46987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:25.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:28:25.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:25.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:25.494+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:25.566+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:25.565+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:28:25.603+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:25.603+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:28:25.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:28:56.345+0000] {processor.py:161} INFO - Started process (PID=47018) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:56.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:28:56.352+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:56.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:56.386+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:28:56.458+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:56.457+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:28:56.496+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:28:56.495+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:28:56.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:29:27.244+0000] {processor.py:161} INFO - Started process (PID=47049) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:27.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:29:27.251+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:27.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:27.286+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:27.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:27.356+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:29:27.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:27.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:29:27.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T07:29:58.340+0000] {processor.py:161} INFO - Started process (PID=47080) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:58.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:29:58.347+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:58.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:58.382+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:29:58.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:58.454+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:29:58.493+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:29:58.492+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:29:58.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:30:29.369+0000] {processor.py:161} INFO - Started process (PID=47111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:30:29.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:30:29.376+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:30:29.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:30:29.412+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:30:29.485+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:30:29.484+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:30:29.523+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:30:29.522+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:30:29.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T07:31:00.379+0000] {processor.py:161} INFO - Started process (PID=47142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:00.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:31:00.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:00.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:00.420+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:00.491+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:00.491+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:31:00.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:00.529+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:31:00.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:31:31.487+0000] {processor.py:161} INFO - Started process (PID=47174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:31.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:31:31.493+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:31.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:31.528+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:31:31.599+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:31.598+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:31:31.637+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:31:31.636+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:31:31.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:32:02.395+0000] {processor.py:161} INFO - Started process (PID=47205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:02.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:32:02.404+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:02.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:02.455+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:02.535+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:02.534+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:32:02.577+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:02.577+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:32:02.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T07:32:33.538+0000] {processor.py:161} INFO - Started process (PID=47236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:33.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:32:33.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:33.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:33.581+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:32:33.650+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:33.649+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:32:33.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:32:33.687+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:32:33.747+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T07:33:04.530+0000] {processor.py:161} INFO - Started process (PID=47267) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:04.534+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:33:04.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:04.536+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:04.572+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:04.653+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:04.652+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:33:04.695+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:04.695+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:33:04.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T07:33:35.538+0000] {processor.py:161} INFO - Started process (PID=47298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:35.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:33:35.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:35.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:35.580+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:33:35.653+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:35.652+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:33:35.691+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:33:35.690+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:33:35.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T07:34:06.598+0000] {processor.py:161} INFO - Started process (PID=47329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:06.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:34:06.606+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:06.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:06.641+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:06.714+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:06.713+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:34:06.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:06.750+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:34:06.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T07:34:37.647+0000] {processor.py:161} INFO - Started process (PID=47360) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:37.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:34:37.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:37.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:37.689+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:34:37.762+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:37.761+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:34:37.803+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:34:37.802+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:34:37.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T07:35:08.691+0000] {processor.py:161} INFO - Started process (PID=47391) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:08.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:35:08.698+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:08.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:08.736+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:08.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:08.818+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:35:08.856+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:08.856+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:35:08.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T07:35:39.706+0000] {processor.py:161} INFO - Started process (PID=47422) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:39.710+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:35:39.713+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:39.712+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:39.747+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:35:39.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:39.817+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:35:39.856+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:35:39.855+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:35:39.917+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:36:10.870+0000] {processor.py:161} INFO - Started process (PID=47453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:10.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:36:10.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:10.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:10.912+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:10.983+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:10.982+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:36:11.021+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:11.020+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:36:11.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:36:41.769+0000] {processor.py:161} INFO - Started process (PID=47484) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:41.772+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:36:41.775+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:41.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:41.810+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:36:41.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:41.880+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:36:41.919+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:36:41.918+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:36:41.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:37:12.985+0000] {processor.py:161} INFO - Started process (PID=47515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:12.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:37:12.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:12.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:13.026+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:13.096+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:13.095+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:37:13.134+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:13.133+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:37:13.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:37:43.918+0000] {processor.py:161} INFO - Started process (PID=47546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:43.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:37:43.925+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:43.924+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:43.960+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:37:44.032+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:44.031+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:37:44.069+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:37:44.069+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:37:44.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:38:15.013+0000] {processor.py:161} INFO - Started process (PID=47577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:15.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:38:15.018+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:15.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:15.055+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:15.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:15.124+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:38:15.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:15.161+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:38:15.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T07:38:45.990+0000] {processor.py:161} INFO - Started process (PID=47608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:45.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:38:45.998+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:45.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:46.032+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:38:46.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:46.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:38:46.158+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:38:46.157+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:38:46.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T07:39:17.040+0000] {processor.py:161} INFO - Started process (PID=47639) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:17.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:39:17.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:17.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:17.104+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:17.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:17.198+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:39:17.245+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:17.244+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:39:17.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.277 seconds
[2024-05-01T07:39:48.076+0000] {processor.py:161} INFO - Started process (PID=47671) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:48.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:39:48.080+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:48.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:48.115+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:39:48.190+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:48.189+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:39:48.236+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:39:48.235+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:39:48.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T07:40:19.122+0000] {processor.py:161} INFO - Started process (PID=47702) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:19.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:40:19.128+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:19.127+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:19.163+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:19.236+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:19.235+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:40:19.273+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:19.272+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:40:19.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:40:50.109+0000] {processor.py:161} INFO - Started process (PID=47733) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:50.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:40:50.115+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:50.114+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:50.151+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:40:50.223+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:50.222+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:40:50.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:40:50.260+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:40:50.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T07:41:21.017+0000] {processor.py:161} INFO - Started process (PID=47764) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:21.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:41:21.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:21.023+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:21.064+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:21.163+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:21.162+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:41:21.209+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:21.208+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:41:21.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.262 seconds
[2024-05-01T07:41:52.145+0000] {processor.py:161} INFO - Started process (PID=47795) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:52.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:41:52.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:52.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:52.201+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:41:52.287+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:52.286+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:41:52.325+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:41:52.324+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:41:52.382+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T07:42:23.094+0000] {processor.py:161} INFO - Started process (PID=47826) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:23.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:42:23.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:23.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:23.135+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:23.218+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:23.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:42:23.270+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:23.269+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:42:23.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.281 seconds
[2024-05-01T07:42:54.275+0000] {processor.py:161} INFO - Started process (PID=47864) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:54.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:42:54.281+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:54.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:54.315+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:42:54.389+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:54.388+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:42:54.430+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:42:54.429+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:42:54.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T07:43:25.286+0000] {processor.py:161} INFO - Started process (PID=47896) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:25.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:43:25.293+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:25.292+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:25.331+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:25.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:25.411+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:43:25.450+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:25.449+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:43:25.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T07:43:56.303+0000] {processor.py:161} INFO - Started process (PID=47927) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:56.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:43:56.309+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:56.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:56.344+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:43:56.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:56.418+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:43:56.456+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:43:56.456+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:43:56.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:44:27.488+0000] {processor.py:161} INFO - Started process (PID=47958) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:27.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:44:27.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:27.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:27.529+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:27.600+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:27.599+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:44:27.638+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:27.637+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:44:27.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T07:44:58.417+0000] {processor.py:161} INFO - Started process (PID=47989) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:58.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:44:58.423+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:58.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:58.458+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:44:58.529+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:58.528+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:44:58.567+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:44:58.566+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:44:58.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:45:29.515+0000] {processor.py:161} INFO - Started process (PID=48020) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:45:29.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:45:29.522+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:45:29.521+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:45:29.556+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:45:29.630+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:45:29.630+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:45:29.680+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:45:29.679+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:45:29.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T07:46:00.512+0000] {processor.py:161} INFO - Started process (PID=48051) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:00.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:46:00.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:00.517+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:00.553+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:00.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:00.623+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:46:00.662+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:00.661+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:46:00.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T07:46:31.671+0000] {processor.py:161} INFO - Started process (PID=48082) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:31.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:46:31.677+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:31.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:31.712+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:46:31.786+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:31.785+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:46:31.827+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:46:31.826+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:46:31.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T07:47:02.615+0000] {processor.py:161} INFO - Started process (PID=48113) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:02.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:47:02.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:02.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:02.656+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:02.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:02.727+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:47:02.765+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:02.765+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:47:02.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:47:33.540+0000] {processor.py:161} INFO - Started process (PID=48144) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:33.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:47:33.546+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:33.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:33.581+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:47:33.652+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:33.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:47:33.690+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:47:33.689+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:47:33.755+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T07:48:04.716+0000] {processor.py:161} INFO - Started process (PID=48175) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:04.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:48:04.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:04.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:04.757+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:04.825+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:04.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:48:04.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:04.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:48:04.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T07:48:35.642+0000] {processor.py:161} INFO - Started process (PID=48206) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:35.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:48:35.649+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:35.648+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:35.684+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:48:35.757+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:35.756+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:48:35.795+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:48:35.795+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:48:35.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:49:06.628+0000] {processor.py:161} INFO - Started process (PID=48237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:06.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:49:06.634+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:06.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:06.670+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:06.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:06.750+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:49:06.789+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:06.788+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:49:06.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T07:49:37.730+0000] {processor.py:161} INFO - Started process (PID=48268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:37.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:49:37.737+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:37.736+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:37.773+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:49:37.841+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:37.841+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:49:37.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:49:37.881+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:49:37.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:50:08.692+0000] {processor.py:161} INFO - Started process (PID=48299) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:08.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:50:08.705+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:08.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:08.739+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:08.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:08.818+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:50:08.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:08.873+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:50:08.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.274 seconds
[2024-05-01T07:50:39.600+0000] {processor.py:161} INFO - Started process (PID=48330) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:39.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:50:39.606+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:39.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:39.641+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:50:39.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:39.711+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:50:39.749+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:50:39.749+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:50:39.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:51:10.565+0000] {processor.py:161} INFO - Started process (PID=48361) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:10.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:51:10.572+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:10.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:10.607+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:10.679+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:10.678+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:51:10.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:10.719+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:51:10.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T07:51:41.651+0000] {processor.py:161} INFO - Started process (PID=48392) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:41.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:51:41.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:41.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:41.691+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:51:41.763+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:41.763+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:51:41.802+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:51:41.802+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:51:41.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:52:12.708+0000] {processor.py:161} INFO - Started process (PID=48423) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:12.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:52:12.715+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:12.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:12.751+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:12.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:12.822+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:52:12.860+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:12.860+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:52:12.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:52:43.688+0000] {processor.py:161} INFO - Started process (PID=48453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:43.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:52:43.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:43.693+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:43.728+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:52:43.799+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:43.798+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:52:43.840+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:52:43.839+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:52:43.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T07:53:14.698+0000] {processor.py:161} INFO - Started process (PID=48484) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:14.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:53:14.705+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:14.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:14.740+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:14.813+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:14.812+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:53:14.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:14.849+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:53:14.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:53:45.736+0000] {processor.py:161} INFO - Started process (PID=48515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:45.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:53:45.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:45.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:45.778+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:53:45.851+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:45.851+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:53:45.889+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:53:45.889+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:53:45.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:54:16.714+0000] {processor.py:161} INFO - Started process (PID=48546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:16.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:54:16.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:16.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:16.755+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:16.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:16.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:54:16.867+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:16.866+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:54:16.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T07:54:47.797+0000] {processor.py:161} INFO - Started process (PID=48577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:47.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:54:47.806+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:47.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:47.844+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:54:47.914+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:47.913+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:54:47.952+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:54:47.951+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:54:48.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T07:55:18.726+0000] {processor.py:161} INFO - Started process (PID=48608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:18.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:55:18.733+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:18.732+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:18.768+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:18.840+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:18.839+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:55:18.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:18.877+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:55:18.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T07:55:49.897+0000] {processor.py:161} INFO - Started process (PID=48639) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:49.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:55:49.909+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:49.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:49.944+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:55:50.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:50.013+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:55:50.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:55:50.053+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:55:50.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.247 seconds
[2024-05-01T07:56:20.811+0000] {processor.py:161} INFO - Started process (PID=48670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:20.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:56:20.817+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:20.816+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:20.851+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:20.923+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:20.922+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:56:20.961+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:20.960+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:56:21.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:56:51.922+0000] {processor.py:161} INFO - Started process (PID=48702) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:51.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:56:51.928+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:51.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:51.964+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:56:52.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:52.033+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:56:52.071+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:56:52.070+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:56:52.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T07:57:22.921+0000] {processor.py:161} INFO - Started process (PID=48733) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:22.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:57:22.927+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:22.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:22.962+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:23.035+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:23.034+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:57:23.084+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:23.083+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:57:23.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T07:57:54.012+0000] {processor.py:161} INFO - Started process (PID=48764) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:54.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:57:54.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:54.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:54.067+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:57:54.154+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:54.153+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:57:54.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:57:54.211+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:57:54.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.268 seconds
[2024-05-01T07:58:24.971+0000] {processor.py:161} INFO - Started process (PID=48795) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:24.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:58:24.977+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:24.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:25.011+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:25.082+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:25.082+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:58:25.120+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:25.120+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:58:25.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T07:58:55.892+0000] {processor.py:161} INFO - Started process (PID=48826) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:55.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:58:55.916+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:55.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:55.957+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:58:56.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:56.038+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:58:56.084+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:58:56.082+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:58:56.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.276 seconds
[2024-05-01T07:59:26.984+0000] {processor.py:161} INFO - Started process (PID=48857) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:26.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:59:26.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:26.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:27.025+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:27.096+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:27.096+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:59:27.136+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:27.135+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:59:27.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T07:59:58.069+0000] {processor.py:161} INFO - Started process (PID=48888) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:58.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T07:59:58.076+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:58.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:58.114+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T07:59:58.188+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:58.187+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T07:59:58.226+0000] {logging_mixin.py:188} INFO - [2024-05-01T07:59:58.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T07:59:58.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T08:00:29.133+0000] {processor.py:161} INFO - Started process (PID=48919) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:29.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:00:29.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:29.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:29.174+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:29.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:29.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:00:29.286+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:29.285+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:00:29.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T08:00:59.636+0000] {processor.py:161} INFO - Started process (PID=48956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:59.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:00:59.652+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:59.650+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:59.696+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:00:59.768+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:59.767+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:00:59.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:00:59.808+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:00:59.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T08:01:30.110+0000] {processor.py:161} INFO - Started process (PID=48987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:01:30.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:01:30.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:01:30.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:01:30.152+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:01:30.221+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:01:30.221+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:01:30.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:01:30.259+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:01:30.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:02:00.559+0000] {processor.py:161} INFO - Started process (PID=49019) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:00.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:02:00.567+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:00.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:00.604+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:00.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:00.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:02:00.713+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:00.713+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:02:00.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T08:02:30.993+0000] {processor.py:161} INFO - Started process (PID=49050) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:30.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:02:30.999+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:30.998+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:31.034+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:02:31.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:31.126+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:02:31.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:02:31.168+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:02:31.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T08:03:01.507+0000] {processor.py:161} INFO - Started process (PID=49081) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:01.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:03:01.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:01.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:01.563+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:01.641+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:01.640+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:03:01.679+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:01.678+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:03:01.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T08:03:31.954+0000] {processor.py:161} INFO - Started process (PID=49112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:31.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:03:31.961+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:31.960+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:31.995+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:03:32.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:32.076+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:03:32.120+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:03:32.119+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:03:32.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T08:04:02.476+0000] {processor.py:161} INFO - Started process (PID=49143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:02.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:04:02.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:02.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:02.528+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:02.604+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:02.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:04:02.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:02.646+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:04:02.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T08:04:32.943+0000] {processor.py:161} INFO - Started process (PID=49174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:32.947+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:04:32.950+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:32.949+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:32.984+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:04:33.070+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:33.068+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:04:33.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:04:33.116+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:04:33.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T08:05:03.430+0000] {processor.py:161} INFO - Started process (PID=49205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:03.433+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:05:03.436+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:03.435+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:03.470+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:03.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:03.538+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:05:03.578+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:03.578+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:05:03.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T08:05:33.843+0000] {processor.py:161} INFO - Started process (PID=49237) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:33.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:05:33.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:33.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:33.885+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:05:33.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:33.955+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:05:33.993+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:05:33.992+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:05:34.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:06:04.323+0000] {processor.py:161} INFO - Started process (PID=49268) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:04.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:06:04.330+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:04.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:04.366+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:04.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:04.435+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:06:04.473+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:04.472+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:06:04.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T08:06:35.230+0000] {processor.py:161} INFO - Started process (PID=49300) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:35.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:06:35.237+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:35.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:35.272+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:06:35.342+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:35.341+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:06:35.382+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:06:35.382+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:06:35.437+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:07:06.389+0000] {processor.py:161} INFO - Started process (PID=49331) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:06.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:07:06.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:06.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:06.433+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:06.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:06.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:07:06.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:06.541+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:07:06.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:07:37.290+0000] {processor.py:161} INFO - Started process (PID=49362) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:37.294+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:07:37.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:37.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:37.335+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:07:37.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:37.411+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:07:37.450+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:07:37.449+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:07:37.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T08:08:08.334+0000] {processor.py:161} INFO - Started process (PID=49393) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:08.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:08:08.340+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:08.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:08.375+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:08.449+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:08.449+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:08:08.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:08.488+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:08:08.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:08:39.274+0000] {processor.py:161} INFO - Started process (PID=49424) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:39.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:08:39.281+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:39.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:39.316+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:08:39.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:39.386+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:08:39.424+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:08:39.423+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:08:39.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:09:10.309+0000] {processor.py:161} INFO - Started process (PID=49455) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:10.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:09:10.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:10.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:10.355+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:10.444+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:10.443+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:09:10.499+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:10.498+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:09:10.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.267 seconds
[2024-05-01T08:09:41.363+0000] {processor.py:161} INFO - Started process (PID=49486) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:41.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:09:41.371+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:41.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:41.412+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:09:41.497+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:41.496+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:09:41.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:09:41.536+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:09:41.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T08:10:12.361+0000] {processor.py:161} INFO - Started process (PID=49517) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:12.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:10:12.368+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:12.367+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:12.404+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:12.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:12.476+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:10:12.515+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:12.514+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:10:12.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:10:43.453+0000] {processor.py:161} INFO - Started process (PID=49548) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:43.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:10:43.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:43.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:43.495+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:10:43.564+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:43.563+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:10:43.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:10:43.600+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:10:43.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:11:14.341+0000] {processor.py:161} INFO - Started process (PID=49580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:14.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:11:14.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:14.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:14.382+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:14.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:14.454+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:11:14.493+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:14.492+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:11:14.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:11:45.476+0000] {processor.py:161} INFO - Started process (PID=49612) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:45.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:11:45.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:45.482+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:45.518+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:11:45.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:45.588+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:11:45.626+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:11:45.625+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:11:45.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:12:16.428+0000] {processor.py:161} INFO - Started process (PID=49644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:16.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:12:16.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:16.434+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:16.470+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:16.544+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:16.544+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:12:16.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:16.581+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:12:16.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T08:12:47.541+0000] {processor.py:161} INFO - Started process (PID=49675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:47.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:12:47.547+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:47.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:47.583+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:12:47.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:47.653+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:12:47.691+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:12:47.691+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:12:47.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:13:18.441+0000] {processor.py:161} INFO - Started process (PID=49706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:18.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:13:18.448+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:18.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:18.487+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:18.557+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:18.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:13:18.595+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:18.594+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:13:18.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:13:49.496+0000] {processor.py:161} INFO - Started process (PID=49737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:49.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:13:49.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:49.502+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:49.539+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:13:49.608+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:49.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:13:49.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:13:49.646+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:13:49.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:14:20.420+0000] {processor.py:161} INFO - Started process (PID=49768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:20.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:14:20.428+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:20.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:20.463+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:20.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:20.537+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:14:20.576+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:20.575+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:14:20.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T08:14:51.525+0000] {processor.py:161} INFO - Started process (PID=49799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:51.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:14:51.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:51.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:51.567+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:14:51.643+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:51.642+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:14:51.681+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:14:51.680+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:14:51.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T08:15:22.470+0000] {processor.py:161} INFO - Started process (PID=49832) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:22.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:15:22.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:22.475+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:22.511+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:22.583+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:22.583+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:15:22.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:22.621+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:15:22.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T08:15:53.557+0000] {processor.py:161} INFO - Started process (PID=49863) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:53.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:15:53.565+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:53.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:53.600+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:15:53.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:53.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:15:53.708+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:15:53.707+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:15:53.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:16:24.432+0000] {processor.py:161} INFO - Started process (PID=49894) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:24.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:16:24.437+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:24.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:24.472+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:24.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:24.542+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:16:24.581+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:24.580+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:16:24.637+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:16:55.503+0000] {processor.py:161} INFO - Started process (PID=49925) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:55.506+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:16:55.509+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:55.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:55.547+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:16:55.618+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:55.618+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:16:55.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:16:55.655+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:16:55.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T08:17:26.495+0000] {processor.py:161} INFO - Started process (PID=49956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:26.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:17:26.501+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:26.500+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:26.536+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:26.610+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:26.610+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:17:26.649+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:26.648+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:17:26.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:17:57.615+0000] {processor.py:161} INFO - Started process (PID=49988) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:57.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:17:57.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:57.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:57.657+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:17:57.727+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:57.726+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:17:57.764+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:17:57.764+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:17:57.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T08:18:28.554+0000] {processor.py:161} INFO - Started process (PID=50019) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:28.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:18:28.561+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:28.559+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:28.595+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:28.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:28.666+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:18:28.705+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:28.704+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:18:28.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:18:59.713+0000] {processor.py:161} INFO - Started process (PID=50050) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:59.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:18:59.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:59.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:59.754+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:18:59.827+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:59.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:18:59.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:18:59.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:18:59.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:19:30.661+0000] {processor.py:161} INFO - Started process (PID=50081) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:19:30.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:19:30.667+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:19:30.666+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:19:30.702+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:19:30.773+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:19:30.772+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:19:30.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:19:30.811+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:19:30.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:20:01.720+0000] {processor.py:161} INFO - Started process (PID=50112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:01.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:20:01.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:01.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:01.761+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:01.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:01.832+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:20:01.872+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:01.871+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:20:01.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:20:32.712+0000] {processor.py:161} INFO - Started process (PID=50143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:32.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:20:32.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:32.718+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:32.765+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:20:32.842+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:32.842+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:20:32.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:20:32.880+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:20:32.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T08:21:03.754+0000] {processor.py:161} INFO - Started process (PID=50174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:03.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:21:03.761+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:03.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:03.799+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:03.884+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:03.883+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:21:03.925+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:03.924+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:21:03.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T08:21:34.781+0000] {processor.py:161} INFO - Started process (PID=50205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:34.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:21:34.788+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:34.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:34.823+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:21:34.898+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:34.897+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:21:34.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:21:34.935+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:21:34.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T08:22:05.751+0000] {processor.py:161} INFO - Started process (PID=50236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:05.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:22:05.757+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:05.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:05.792+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:05.872+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:05.871+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:22:05.912+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:05.912+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:22:05.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T08:22:36.755+0000] {processor.py:161} INFO - Started process (PID=50273) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:36.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:22:36.761+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:36.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:36.796+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:22:36.871+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:36.870+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:22:36.909+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:22:36.908+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:22:36.966+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:23:07.081+0000] {processor.py:161} INFO - Started process (PID=50303) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:07.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:23:07.087+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:07.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:07.122+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:07.193+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:07.193+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:23:07.231+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:07.231+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:23:07.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:23:37.499+0000] {processor.py:161} INFO - Started process (PID=50334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:37.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:23:37.505+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:37.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:37.540+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:23:37.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:37.611+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:23:37.691+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:23:37.689+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:23:37.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.278 seconds
[2024-05-01T08:24:08.016+0000] {processor.py:161} INFO - Started process (PID=50365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:08.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:24:08.021+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:08.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:08.056+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:08.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:08.127+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:24:08.165+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:08.164+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:24:08.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T08:24:38.615+0000] {processor.py:161} INFO - Started process (PID=50396) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:38.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:24:38.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:38.621+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:38.657+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:24:38.729+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:38.728+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:24:38.767+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:24:38.766+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:24:38.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:25:09.443+0000] {processor.py:161} INFO - Started process (PID=50427) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:09.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:25:09.449+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:09.448+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:09.484+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:09.554+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:09.553+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:25:09.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:09.590+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:25:09.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T08:25:40.348+0000] {processor.py:161} INFO - Started process (PID=50458) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:40.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:25:40.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:40.353+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:40.389+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:25:40.459+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:40.459+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:25:40.497+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:25:40.496+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:25:40.555+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:26:11.364+0000] {processor.py:161} INFO - Started process (PID=50489) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:11.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:26:11.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:11.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:11.426+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:11.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:11.499+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:26:11.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:11.537+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:26:11.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T08:26:42.381+0000] {processor.py:161} INFO - Started process (PID=50520) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:42.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:26:42.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:42.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:42.421+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:26:42.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:42.493+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:26:42.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:26:42.531+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:26:42.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:27:13.349+0000] {processor.py:161} INFO - Started process (PID=50552) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:13.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:27:13.356+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:13.355+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:13.391+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:13.463+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:13.462+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:27:13.501+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:13.500+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:27:13.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:27:44.329+0000] {processor.py:161} INFO - Started process (PID=50583) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:44.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:27:44.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:44.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:44.372+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:27:44.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:44.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:27:44.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:27:44.482+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:27:44.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T08:28:15.302+0000] {processor.py:161} INFO - Started process (PID=50614) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:15.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:28:15.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:15.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:15.343+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:15.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:15.415+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:28:15.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:15.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:28:15.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:28:46.278+0000] {processor.py:161} INFO - Started process (PID=50645) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:46.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:28:46.284+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:46.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:46.319+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:28:46.391+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:46.390+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:28:46.429+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:28:46.428+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:28:46.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:29:17.276+0000] {processor.py:161} INFO - Started process (PID=50676) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:17.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:29:17.282+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:17.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:17.317+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:17.389+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:17.389+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:29:17.427+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:17.426+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:29:17.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T08:29:48.388+0000] {processor.py:161} INFO - Started process (PID=50707) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:48.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:29:48.395+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:48.394+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:48.430+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:29:48.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:48.499+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:29:48.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:29:48.537+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:29:48.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:30:19.277+0000] {processor.py:161} INFO - Started process (PID=50738) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:19.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:30:19.284+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:19.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:19.319+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:19.390+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:19.390+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:30:19.429+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:19.429+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:30:19.486+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:30:50.374+0000] {processor.py:161} INFO - Started process (PID=50769) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:50.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:30:50.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:50.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:50.418+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:30:50.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:50.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:30:50.526+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:30:50.526+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:30:50.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T08:31:21.268+0000] {processor.py:161} INFO - Started process (PID=50800) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:21.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:31:21.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:21.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:21.310+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:21.384+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:21.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:31:21.422+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:21.421+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:31:21.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:31:52.373+0000] {processor.py:161} INFO - Started process (PID=50831) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:52.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:31:52.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:52.379+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:52.415+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:31:52.487+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:52.486+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:31:52.525+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:31:52.524+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:31:52.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:32:23.368+0000] {processor.py:161} INFO - Started process (PID=50862) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:23.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:32:23.376+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:23.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:23.414+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:23.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:23.488+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:32:23.528+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:23.527+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:32:23.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T08:32:54.437+0000] {processor.py:161} INFO - Started process (PID=50893) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:54.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:32:54.443+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:54.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:54.478+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:32:54.552+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:54.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:32:54.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:32:54.589+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:32:54.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:33:25.437+0000] {processor.py:161} INFO - Started process (PID=50924) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:25.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:33:25.443+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:25.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:25.478+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:25.550+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:25.549+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:33:25.588+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:25.587+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:33:25.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:33:56.498+0000] {processor.py:161} INFO - Started process (PID=50955) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:56.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:33:56.504+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:56.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:56.539+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:33:56.611+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:56.610+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:33:56.651+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:33:56.650+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:33:56.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T08:34:27.564+0000] {processor.py:161} INFO - Started process (PID=50986) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:27.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:34:27.571+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:27.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:27.607+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:27.680+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:27.679+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:34:27.718+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:27.717+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:34:27.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:34:58.514+0000] {processor.py:161} INFO - Started process (PID=51017) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:58.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:34:58.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:58.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:58.554+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:34:58.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:58.624+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:34:58.663+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:34:58.662+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:34:58.719+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:35:29.640+0000] {processor.py:161} INFO - Started process (PID=51049) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:35:29.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:35:29.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:35:29.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:35:29.689+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:35:29.767+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:35:29.766+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:35:29.805+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:35:29.804+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:35:29.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T08:36:00.583+0000] {processor.py:161} INFO - Started process (PID=51079) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:00.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:36:00.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:00.588+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:00.624+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:00.699+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:00.698+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:36:00.737+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:00.736+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:36:00.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:36:31.690+0000] {processor.py:161} INFO - Started process (PID=51110) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:31.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:36:31.696+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:31.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:31.731+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:36:31.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:31.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:36:31.871+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:36:31.870+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:36:31.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.254 seconds
[2024-05-01T08:37:02.647+0000] {processor.py:161} INFO - Started process (PID=51141) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:02.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:37:02.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:02.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:02.694+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:02.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:02.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:37:02.834+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:02.833+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:37:02.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.254 seconds
[2024-05-01T08:37:33.616+0000] {processor.py:161} INFO - Started process (PID=51172) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:33.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:37:33.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:33.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:33.656+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:37:33.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:33.728+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:37:33.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:37:33.765+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:37:33.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:38:04.496+0000] {processor.py:161} INFO - Started process (PID=51203) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:04.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:38:04.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:04.502+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:04.538+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:04.608+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:04.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:38:04.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:04.645+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:38:04.702+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:38:35.613+0000] {processor.py:161} INFO - Started process (PID=51234) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:35.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:38:35.619+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:35.618+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:35.653+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:38:35.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:35.721+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:38:35.761+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:38:35.761+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:38:35.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T08:39:06.635+0000] {processor.py:161} INFO - Started process (PID=51265) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:06.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:39:06.645+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:06.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:06.685+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:06.764+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:06.764+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:39:06.802+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:06.801+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:39:06.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T08:39:37.623+0000] {processor.py:161} INFO - Started process (PID=51296) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:37.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:39:37.630+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:37.629+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:37.672+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:39:37.768+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:37.766+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:39:37.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:39:37.823+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:39:37.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T08:40:08.823+0000] {processor.py:161} INFO - Started process (PID=51327) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:08.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:40:08.829+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:08.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:08.864+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:08.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:08.935+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:40:08.975+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:08.975+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:40:09.031+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:40:39.127+0000] {processor.py:161} INFO - Started process (PID=51359) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:39.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:40:39.132+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:39.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:39.167+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:40:39.237+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:39.237+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:40:39.275+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:40:39.274+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:40:39.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:41:09.571+0000] {processor.py:161} INFO - Started process (PID=51390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:09.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:41:09.577+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:09.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:09.612+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:09.683+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:09.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:41:09.721+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:09.721+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:41:09.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T08:41:40.042+0000] {processor.py:161} INFO - Started process (PID=51422) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:40.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:41:40.048+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:40.047+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:40.083+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:41:40.153+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:40.152+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:41:40.192+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:41:40.192+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:41:40.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T08:42:10.533+0000] {processor.py:161} INFO - Started process (PID=51453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:10.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:42:10.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:10.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:10.575+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:10.645+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:10.645+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:42:10.683+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:10.682+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:42:10.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:42:41.007+0000] {processor.py:161} INFO - Started process (PID=51484) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:41.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:42:41.014+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:41.013+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:41.049+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:42:41.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:41.130+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:42:41.173+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:42:41.173+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:42:41.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T08:43:11.476+0000] {processor.py:161} INFO - Started process (PID=51515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:11.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:43:11.482+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:11.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:11.517+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:11.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:11.588+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:43:11.628+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:11.627+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:43:11.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:43:41.923+0000] {processor.py:161} INFO - Started process (PID=51546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:41.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:43:41.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:41.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:41.963+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:43:42.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:42.033+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:43:42.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:43:42.071+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:43:42.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:44:12.350+0000] {processor.py:161} INFO - Started process (PID=51577) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:12.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:44:12.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:12.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:12.392+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:12.463+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:12.462+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:44:12.501+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:12.500+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:44:12.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:44:42.840+0000] {processor.py:161} INFO - Started process (PID=51608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:42.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:44:42.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:42.846+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:42.888+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:44:42.971+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:42.970+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:44:43.017+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:44:43.017+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:44:43.073+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T08:45:13.324+0000] {processor.py:161} INFO - Started process (PID=51639) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:13.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:45:13.330+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:13.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:13.365+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:13.436+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:13.435+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:45:13.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:13.491+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:45:13.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.262 seconds
[2024-05-01T08:45:43.892+0000] {processor.py:161} INFO - Started process (PID=51670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:43.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:45:43.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:43.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:43.950+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:45:44.046+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:44.045+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:45:44.095+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:45:44.094+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:45:44.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.315 seconds
[2024-05-01T08:46:15.118+0000] {processor.py:161} INFO - Started process (PID=51707) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:15.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:46:15.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:15.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:15.159+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:15.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:15.231+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:46:15.274+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:15.273+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:46:15.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:46:46.077+0000] {processor.py:161} INFO - Started process (PID=51739) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:46.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:46:46.083+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:46.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:46.122+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:46:46.199+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:46.199+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:46:46.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:46:46.238+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:46:46.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T08:47:17.165+0000] {processor.py:161} INFO - Started process (PID=51770) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:17.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:47:17.171+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:17.170+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:17.206+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:17.278+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:17.277+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:47:17.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:17.315+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:47:17.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:47:48.166+0000] {processor.py:161} INFO - Started process (PID=51801) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:48.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:47:48.171+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:48.170+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:48.206+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:47:48.279+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:48.278+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:47:48.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:47:48.318+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:47:48.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:48:19.147+0000] {processor.py:161} INFO - Started process (PID=51832) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:19.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:48:19.153+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:19.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:19.188+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:19.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:19.259+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:48:19.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:19.296+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:48:19.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:48:50.278+0000] {processor.py:161} INFO - Started process (PID=51863) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:50.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:48:50.284+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:50.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:50.318+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:48:50.387+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:50.386+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:48:50.426+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:48:50.426+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:48:50.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T08:49:21.307+0000] {processor.py:161} INFO - Started process (PID=51894) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:21.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:49:21.313+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:21.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:21.348+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:21.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:21.418+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:49:21.460+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:21.460+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:49:21.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:49:52.354+0000] {processor.py:161} INFO - Started process (PID=51925) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:52.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:49:52.362+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:52.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:52.401+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:49:52.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:52.476+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:49:52.514+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:49:52.514+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:49:52.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T08:50:23.437+0000] {processor.py:161} INFO - Started process (PID=51956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:23.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:50:23.444+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:23.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:23.479+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:23.552+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:23.551+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:50:23.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:23.588+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:50:23.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:50:54.430+0000] {processor.py:161} INFO - Started process (PID=51987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:54.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:50:54.436+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:54.435+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:54.471+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:50:54.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:54.543+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:50:54.583+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:50:54.582+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:50:54.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T08:51:25.532+0000] {processor.py:161} INFO - Started process (PID=52019) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:25.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:51:25.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:25.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:25.574+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:25.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:25.645+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:51:25.684+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:25.684+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:51:25.739+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T08:51:56.542+0000] {processor.py:161} INFO - Started process (PID=52050) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:56.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:51:56.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:56.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:56.584+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:51:56.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:56.655+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:51:56.693+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:51:56.693+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:51:56.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T08:52:27.510+0000] {processor.py:161} INFO - Started process (PID=52081) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:27.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:52:27.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:27.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:27.572+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:27.661+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:27.660+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:52:27.701+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:27.700+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:52:27.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.262 seconds
[2024-05-01T08:52:58.777+0000] {processor.py:161} INFO - Started process (PID=52111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:58.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:52:58.782+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:58.781+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:58.817+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:52:58.885+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:58.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:52:58.923+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:52:58.923+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:52:58.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.211 seconds
[2024-05-01T08:53:29.676+0000] {processor.py:161} INFO - Started process (PID=52142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:53:29.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:53:29.683+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:53:29.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:53:29.718+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:53:29.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:53:29.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:53:29.828+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:53:29.827+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:53:29.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:54:00.884+0000] {processor.py:161} INFO - Started process (PID=52173) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:00.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:54:00.890+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:00.889+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:00.936+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:01.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:01.013+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:54:01.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:01.052+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:54:01.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T08:54:31.779+0000] {processor.py:161} INFO - Started process (PID=52204) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:31.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:54:31.786+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:31.785+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:31.822+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:54:31.894+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:31.893+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:54:31.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:54:31.931+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:54:32.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.268 seconds
[2024-05-01T08:55:02.882+0000] {processor.py:161} INFO - Started process (PID=52235) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:02.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:55:02.888+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:02.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:02.927+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:02.998+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:02.997+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:55:03.035+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:03.034+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:55:03.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:55:33.950+0000] {processor.py:161} INFO - Started process (PID=52266) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:33.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:55:33.956+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:33.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:33.990+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:55:34.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:34.077+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:55:34.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:55:34.116+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:55:34.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T08:56:04.939+0000] {processor.py:161} INFO - Started process (PID=52297) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:04.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:56:04.946+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:04.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:04.981+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:05.052+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:05.052+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:56:05.091+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:05.090+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:56:05.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T08:56:35.988+0000] {processor.py:161} INFO - Started process (PID=52328) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:35.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:56:35.994+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:35.993+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:36.029+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:56:36.101+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:36.100+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:56:36.138+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:56:36.137+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:56:36.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T08:57:06.983+0000] {processor.py:161} INFO - Started process (PID=52359) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:06.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:57:06.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:06.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:07.025+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:07.097+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:07.096+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:57:07.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:07.140+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:57:07.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T08:57:38.095+0000] {processor.py:161} INFO - Started process (PID=52390) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:38.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:57:38.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:38.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:38.138+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:57:38.216+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:38.215+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:57:38.258+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:57:38.257+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:57:38.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T08:58:09.046+0000] {processor.py:161} INFO - Started process (PID=52421) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:09.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:58:09.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:09.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:09.087+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:09.158+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:09.158+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:58:09.196+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:09.195+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:58:09.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T08:58:40.178+0000] {processor.py:161} INFO - Started process (PID=52452) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:40.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:58:40.184+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:40.183+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:40.219+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:58:40.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:40.289+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:58:40.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:58:40.327+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:58:40.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T08:59:11.100+0000] {processor.py:161} INFO - Started process (PID=52483) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:11.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:59:11.106+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:11.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:11.148+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:11.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:11.225+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:59:11.264+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:11.263+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:59:11.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T08:59:42.249+0000] {processor.py:161} INFO - Started process (PID=52514) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:42.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T08:59:42.255+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:42.254+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:42.291+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T08:59:42.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:42.360+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T08:59:42.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T08:59:42.397+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T08:59:42.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:00:13.166+0000] {processor.py:161} INFO - Started process (PID=52545) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:13.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:00:13.173+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:13.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:13.208+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:13.282+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:13.281+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:00:13.320+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:13.319+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:00:13.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:00:44.410+0000] {processor.py:161} INFO - Started process (PID=52576) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:44.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:00:44.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:44.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:44.450+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:00:44.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:44.518+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:00:44.564+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:00:44.563+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:00:44.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.260 seconds
[2024-05-01T09:01:15.363+0000] {processor.py:161} INFO - Started process (PID=52608) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:15.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:01:15.378+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:15.376+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:15.426+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:15.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:15.508+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:01:15.553+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:15.552+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:01:15.625+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.274 seconds
[2024-05-01T09:01:45.999+0000] {processor.py:161} INFO - Started process (PID=52639) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:46.002+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:01:46.005+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:46.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:46.040+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:01:46.135+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:46.133+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:01:46.197+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:01:46.196+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:01:46.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.290 seconds
[2024-05-01T09:02:16.506+0000] {processor.py:161} INFO - Started process (PID=52670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:16.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:02:16.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:16.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:16.547+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:16.618+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:16.617+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:02:16.657+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:16.656+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:02:16.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:02:46.977+0000] {processor.py:161} INFO - Started process (PID=52701) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:46.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:02:46.983+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:46.982+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:47.018+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:02:47.091+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:47.090+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:02:47.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:02:47.128+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:02:47.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T09:03:17.428+0000] {processor.py:161} INFO - Started process (PID=52731) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:17.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:03:17.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:17.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:17.469+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:17.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:17.549+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:03:17.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:17.590+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:03:17.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T09:03:47.864+0000] {processor.py:161} INFO - Started process (PID=52762) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:47.867+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:03:47.869+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:47.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:47.904+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:03:47.976+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:47.975+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:03:48.013+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:03:48.013+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:03:48.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:04:18.340+0000] {processor.py:161} INFO - Started process (PID=52793) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:18.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:04:18.346+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:18.345+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:18.381+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:18.452+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:18.451+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:04:18.490+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:18.489+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:04:18.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T09:04:48.789+0000] {processor.py:161} INFO - Started process (PID=52824) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:48.793+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:04:48.795+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:48.794+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:48.830+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:04:48.905+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:48.905+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:04:48.943+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:04:48.942+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:04:48.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:05:19.226+0000] {processor.py:161} INFO - Started process (PID=52855) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:19.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:05:19.231+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:19.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:19.266+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:19.347+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:19.346+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:05:19.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:19.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:05:19.440+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T09:05:49.743+0000] {processor.py:161} INFO - Started process (PID=52886) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:49.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:05:49.750+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:49.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:49.784+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:05:49.855+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:49.854+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:05:49.892+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:05:49.892+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:05:49.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.266 seconds
[2024-05-01T09:06:20.262+0000] {processor.py:161} INFO - Started process (PID=52917) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:20.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:06:20.267+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:20.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:20.302+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:20.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:20.382+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:06:20.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:20.439+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:06:20.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.254 seconds
[2024-05-01T09:06:50.823+0000] {processor.py:161} INFO - Started process (PID=52954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:50.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:06:50.829+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:50.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:50.864+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:06:50.940+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:50.939+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:06:50.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:06:50.983+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:06:51.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T09:07:21.319+0000] {processor.py:161} INFO - Started process (PID=52985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:21.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:07:21.325+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:21.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:21.365+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:21.448+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:21.447+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:07:21.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:21.491+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:07:21.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.257 seconds
[2024-05-01T09:07:51.666+0000] {processor.py:161} INFO - Started process (PID=53016) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:51.670+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:07:51.673+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:51.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:51.708+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:07:51.783+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:51.782+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:07:51.821+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:07:51.820+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:07:51.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T09:08:22.663+0000] {processor.py:161} INFO - Started process (PID=53046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:22.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:08:22.669+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:22.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:22.705+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:22.778+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:22.778+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:08:22.817+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:22.816+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:08:22.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T09:08:53.746+0000] {processor.py:161} INFO - Started process (PID=53077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:53.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:08:53.755+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:53.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:53.805+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:08:53.879+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:53.878+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:08:53.919+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:08:53.918+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:08:53.977+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.247 seconds
[2024-05-01T09:09:24.761+0000] {processor.py:161} INFO - Started process (PID=53108) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:24.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:09:24.768+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:24.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:24.803+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:24.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:24.876+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:09:24.916+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:24.915+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:09:24.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T09:09:55.870+0000] {processor.py:161} INFO - Started process (PID=53139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:55.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:09:55.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:55.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:55.911+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:09:55.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:55.983+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:09:56.027+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:09:56.026+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:09:56.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T09:10:26.832+0000] {processor.py:161} INFO - Started process (PID=53170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:26.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:10:26.876+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:26.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:26.911+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:26.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:26.983+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:10:27.024+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:27.023+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:10:27.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.280 seconds
[2024-05-01T09:10:57.927+0000] {processor.py:161} INFO - Started process (PID=53201) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:57.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:10:57.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:57.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:57.968+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:10:58.040+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:58.040+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:10:58.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:10:58.078+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:10:58.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T09:11:28.988+0000] {processor.py:161} INFO - Started process (PID=53232) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:11:28.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:11:28.994+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:11:28.993+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:11:29.034+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:11:29.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:11:29.105+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:11:29.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:11:29.144+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:11:29.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:12:00.026+0000] {processor.py:161} INFO - Started process (PID=53262) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:00.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:12:00.032+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:00.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:00.067+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:00.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:00.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:12:00.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:00.177+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:12:00.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T09:12:30.343+0000] {processor.py:161} INFO - Started process (PID=53293) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:30.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:12:30.350+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:30.349+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:30.384+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:12:30.457+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:30.456+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:12:30.495+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:12:30.494+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:12:30.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:13:00.797+0000] {processor.py:161} INFO - Started process (PID=53325) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:00.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:13:00.803+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:00.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:00.838+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:00.909+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:00.909+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:13:00.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:00.946+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:13:01.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T09:13:31.324+0000] {processor.py:161} INFO - Started process (PID=53356) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:31.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:13:31.331+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:31.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:31.367+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:13:31.441+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:31.441+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:13:31.479+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:13:31.478+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:13:31.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:14:01.843+0000] {processor.py:161} INFO - Started process (PID=53399) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:01.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:14:01.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:01.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:01.884+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:01.956+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:01.955+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:14:01.994+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:01.994+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:14:02.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T09:14:32.360+0000] {processor.py:161} INFO - Started process (PID=53431) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:32.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:14:32.366+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:32.365+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:32.401+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:14:32.473+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:32.472+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:14:32.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:14:32.512+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:14:32.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:15:02.827+0000] {processor.py:161} INFO - Started process (PID=53464) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:02.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:15:02.837+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:02.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:02.898+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:02.973+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:02.972+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:15:03.011+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:03.010+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:15:03.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.267 seconds
[2024-05-01T09:15:33.438+0000] {processor.py:161} INFO - Started process (PID=53495) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:33.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:15:33.448+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:33.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:33.507+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:15:33.621+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:33.619+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:15:33.683+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:15:33.682+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:15:33.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.352 seconds
[2024-05-01T09:16:04.800+0000] {processor.py:161} INFO - Started process (PID=53526) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:04.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:16:04.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:04.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:04.843+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:04.913+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:04.912+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:16:04.951+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:04.950+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:16:05.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:16:35.725+0000] {processor.py:161} INFO - Started process (PID=53557) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:35.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:16:35.731+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:35.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:35.766+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:16:35.837+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:35.836+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:16:35.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:16:35.876+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:16:35.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:17:06.963+0000] {processor.py:161} INFO - Started process (PID=53588) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:06.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:17:06.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:06.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:07.005+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:07.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:07.076+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:17:07.116+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:07.115+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:17:07.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:17:37.858+0000] {processor.py:161} INFO - Started process (PID=53619) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:37.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:17:37.864+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:37.863+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:37.899+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:17:37.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:37.969+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:17:38.009+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:17:38.009+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:17:38.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T09:18:08.732+0000] {processor.py:161} INFO - Started process (PID=53650) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:08.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:18:08.739+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:08.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:08.775+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:08.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:08.851+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:18:08.913+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:08.912+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:18:08.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T09:18:39.769+0000] {processor.py:161} INFO - Started process (PID=53681) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:39.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:18:39.778+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:39.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:39.820+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:18:39.895+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:39.894+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:18:39.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:18:39.936+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:18:40.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T09:19:10.936+0000] {processor.py:161} INFO - Started process (PID=53712) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:10.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:19:10.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:10.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:10.978+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:11.047+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:11.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:19:11.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:11.085+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:19:11.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T09:19:41.825+0000] {processor.py:161} INFO - Started process (PID=53743) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:41.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:19:41.831+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:41.830+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:41.866+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:19:41.949+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:41.948+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:19:41.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:19:41.994+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:19:42.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T09:20:12.775+0000] {processor.py:161} INFO - Started process (PID=53774) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:12.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:20:12.782+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:12.781+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:12.818+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:12.893+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:12.892+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:20:12.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:12.932+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:20:12.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:20:43.964+0000] {processor.py:161} INFO - Started process (PID=53805) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:43.967+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:20:43.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:43.969+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:44.005+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:20:44.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:44.077+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:20:44.116+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:20:44.116+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:20:44.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:21:14.924+0000] {processor.py:161} INFO - Started process (PID=53836) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:14.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:21:14.931+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:14.930+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:14.966+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:15.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:15.036+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:21:15.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:15.076+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:21:15.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T09:21:46.163+0000] {processor.py:161} INFO - Started process (PID=53867) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:46.167+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:21:46.170+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:46.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:46.206+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:21:46.276+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:46.276+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:21:46.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:21:46.316+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:21:46.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T09:22:17.086+0000] {processor.py:161} INFO - Started process (PID=53898) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:17.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:22:17.092+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:17.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:17.127+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:17.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:17.199+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:22:17.238+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:17.237+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:22:17.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:22:48.018+0000] {processor.py:161} INFO - Started process (PID=53929) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:48.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:22:48.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:48.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:48.062+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:22:48.147+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:48.146+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:22:48.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:22:48.193+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:22:48.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T09:23:19.005+0000] {processor.py:161} INFO - Started process (PID=53960) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:19.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:23:19.011+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:19.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:19.046+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:19.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:19.117+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:23:19.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:19.155+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:23:19.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T09:23:50.124+0000] {processor.py:161} INFO - Started process (PID=53992) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:50.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:23:50.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:50.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:50.167+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:23:50.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:50.238+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:23:50.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:23:50.276+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:23:50.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T09:24:10.892+0000] {processor.py:161} INFO - Started process (PID=54018) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:10.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:24:10.901+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:10.899+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:10.950+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:11.041+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:11.040+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:24:11.088+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:11.087+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:24:11.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.290 seconds
[2024-05-01T09:24:41.959+0000] {processor.py:161} INFO - Started process (PID=54061) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:41.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:24:41.966+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:41.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:42.007+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:24:42.094+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:42.094+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:24:42.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:24:42.140+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:24:42.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.259 seconds
[2024-05-01T09:25:12.959+0000] {processor.py:161} INFO - Started process (PID=54092) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:12.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:25:12.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:12.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:13.014+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:13.119+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:13.119+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:25:13.164+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:13.163+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:25:13.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.289 seconds
[2024-05-01T09:25:43.948+0000] {processor.py:161} INFO - Started process (PID=54123) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:43.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:25:43.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:43.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:43.995+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:44.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:44.101+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:25:44.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:44.155+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:25:44.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.296 seconds
[2024-05-01T09:25:56.488+0000] {processor.py:161} INFO - Started process (PID=54138) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:56.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:25:56.493+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:56.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:56.533+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:25:56.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:56.611+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:25:56.680+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:25:56.679+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:25:56.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.284 seconds
[2024-05-01T09:26:27.056+0000] {processor.py:161} INFO - Started process (PID=54187) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:27.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:26:27.063+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:27.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:27.106+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:27.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:27.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:26:27.228+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:27.227+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:26:27.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T09:26:58.226+0000] {processor.py:161} INFO - Started process (PID=54218) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:58.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:26:58.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:58.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:58.267+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:26:58.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:58.353+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:26:58.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:26:58.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:26:58.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T09:27:29.181+0000] {processor.py:161} INFO - Started process (PID=54249) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:27:29.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:27:29.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:27:29.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:27:29.222+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:27:29.295+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:27:29.294+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:27:29.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:27:29.333+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:27:29.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:28:00.276+0000] {processor.py:161} INFO - Started process (PID=54280) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:00.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:28:00.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:00.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:00.324+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:00.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:00.408+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:28:00.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:00.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:28:00.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.258 seconds
[2024-05-01T09:28:31.329+0000] {processor.py:161} INFO - Started process (PID=54311) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:31.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:28:31.335+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:31.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:31.370+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:28:31.442+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:31.441+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:28:31.481+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:28:31.480+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:28:31.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:29:02.354+0000] {processor.py:161} INFO - Started process (PID=54342) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:02.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:29:02.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:02.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:02.395+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:02.523+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:02.522+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:29:02.561+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:02.561+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:29:02.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.289 seconds
[2024-05-01T09:29:33.351+0000] {processor.py:161} INFO - Started process (PID=54373) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:33.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:29:33.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:33.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:33.398+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:29:33.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:33.483+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:29:33.530+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:29:33.529+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:29:33.585+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T09:30:04.435+0000] {processor.py:161} INFO - Started process (PID=54406) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:04.439+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:30:04.442+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:04.441+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:04.488+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:04.588+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:04.587+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:30:04.637+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:04.636+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:30:04.708+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.286 seconds
[2024-05-01T09:30:12.844+0000] {processor.py:161} INFO - Started process (PID=54416) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:12.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:30:12.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:12.849+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:12.895+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:12.975+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:12.974+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:30:13.015+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:13.014+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:30:13.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T09:30:43.337+0000] {processor.py:161} INFO - Started process (PID=54459) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:43.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:30:43.344+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:43.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:43.379+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:30:43.450+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:43.450+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:30:43.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:30:43.488+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:30:43.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:31:14.275+0000] {processor.py:161} INFO - Started process (PID=54490) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:14.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:31:14.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:14.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:14.389+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:14.485+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:14.484+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:31:14.526+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:14.526+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:31:14.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.330 seconds
[2024-05-01T09:31:45.344+0000] {processor.py:161} INFO - Started process (PID=54522) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:45.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:31:45.351+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:45.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:45.385+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:31:45.458+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:45.457+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:31:45.497+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:31:45.496+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:31:45.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T09:32:16.403+0000] {processor.py:161} INFO - Started process (PID=54553) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:16.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:32:16.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:16.408+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:16.445+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:16.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:16.539+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:32:16.603+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:16.602+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:32:16.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T09:32:47.393+0000] {processor.py:161} INFO - Started process (PID=54585) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:47.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:32:47.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:47.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:47.434+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:32:47.508+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:47.508+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:32:47.553+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:32:47.552+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:32:47.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T09:33:18.584+0000] {processor.py:161} INFO - Started process (PID=54616) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:18.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:33:18.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:18.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:18.627+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:18.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:18.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:33:18.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:18.743+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:33:18.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:33:24.703+0000] {processor.py:161} INFO - Started process (PID=54621) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:24.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:33:24.711+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:24.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:24.772+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:24.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:24.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:33:24.890+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:24.889+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:33:24.952+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T09:33:55.293+0000] {processor.py:161} INFO - Started process (PID=54664) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:55.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:33:55.301+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:55.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:55.336+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:33:55.409+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:55.408+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:33:55.448+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:33:55.448+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:33:55.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T09:34:25.852+0000] {processor.py:161} INFO - Started process (PID=54695) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:25.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:34:25.860+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:25.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:25.895+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:25.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:25.967+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:34:26.009+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:26.009+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:34:26.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T09:34:56.395+0000] {processor.py:161} INFO - Started process (PID=54726) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:56.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:34:56.403+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:56.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:56.442+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:34:56.564+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:56.562+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:34:56.604+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:34:56.603+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:34:56.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.280 seconds
[2024-05-01T09:35:26.978+0000] {processor.py:161} INFO - Started process (PID=54757) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:26.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:35:26.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:26.983+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:27.019+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:27.091+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:27.090+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:35:27.130+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:27.129+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:35:27.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T09:35:57.512+0000] {processor.py:161} INFO - Started process (PID=54788) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:57.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:35:57.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:57.517+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:57.553+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:35:57.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:57.623+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:35:57.665+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:35:57.664+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:35:57.722+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T09:36:28.029+0000] {processor.py:161} INFO - Started process (PID=54819) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:28.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:36:28.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:28.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:28.071+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:28.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:28.143+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:36:28.181+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:28.181+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:36:28.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T09:36:58.562+0000] {processor.py:161} INFO - Started process (PID=54849) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:58.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:36:58.568+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:58.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:58.603+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:36:58.676+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:58.675+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:36:58.714+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:36:58.714+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:36:58.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T09:37:29.064+0000] {processor.py:161} INFO - Started process (PID=54880) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:29.068+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:37:29.071+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:29.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:29.117+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:29.188+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:29.187+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:37:29.228+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:29.227+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:37:29.286+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T09:37:59.658+0000] {processor.py:161} INFO - Started process (PID=54911) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:59.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:37:59.669+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:59.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:59.709+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:37:59.785+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:59.785+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:37:59.824+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:37:59.824+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:37:59.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T09:38:30.261+0000] {processor.py:161} INFO - Started process (PID=54951) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:38:30.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:38:30.267+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:38:30.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:38:30.302+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:38:30.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:38:30.702+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:38:30.749+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:38:30.748+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:38:30.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.598 seconds
[2024-05-01T09:39:01.199+0000] {processor.py:161} INFO - Started process (PID=54994) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:01.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:39:01.206+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:01.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:01.278+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:01.414+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:01.414+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:39:01.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:01.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:39:01.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.367 seconds
[2024-05-01T09:39:31.908+0000] {processor.py:161} INFO - Started process (PID=55026) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:31.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:39:31.915+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:31.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:31.949+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:39:32.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:32.023+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:39:32.067+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:39:32.066+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:39:32.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T09:40:02.801+0000] {processor.py:161} INFO - Started process (PID=55057) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:02.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:40:02.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:02.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:02.857+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:02.931+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:02.931+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:40:02.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:02.969+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:40:03.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T09:40:03.886+0000] {processor.py:161} INFO - Started process (PID=55062) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:03.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:40:03.892+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:03.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:03.937+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:04.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:04.344+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:40:04.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:04.380+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:40:04.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.580 seconds
[2024-05-01T09:40:35.282+0000] {processor.py:161} INFO - Started process (PID=55106) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:35.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:40:35.293+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:35.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:35.385+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:40:35.515+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:35.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:40:35.580+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:40:35.579+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:40:35.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.421 seconds
[2024-05-01T09:41:05.993+0000] {processor.py:161} INFO - Started process (PID=55139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:05.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:41:06.004+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:06.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:06.052+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:06.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:06.136+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:41:06.184+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:06.183+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:41:06.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.277 seconds
[2024-05-01T09:41:34.534+0000] {processor.py:161} INFO - Started process (PID=55170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:34.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:41:34.542+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:34.541+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:34.599+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:41:34.948+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:34.947+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:41:34.988+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:41:34.988+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:41:35.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.542 seconds
[2024-05-01T09:42:02.761+0000] {processor.py:161} INFO - Started process (PID=55201) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:02.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:42:02.767+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:02.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:02.808+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:02.843+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:02.843+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:42:02.884+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:02.884+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:42:02.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.198 seconds
[2024-05-01T09:42:33.924+0000] {processor.py:161} INFO - Started process (PID=55262) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:33.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:42:33.930+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:33.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:33.965+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:42:34.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:34.033+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:42:34.073+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:42:34.072+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:42:34.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:43:04.887+0000] {processor.py:161} INFO - Started process (PID=55293) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:04.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:43:04.893+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:04.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:04.928+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:05.284+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:05.283+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:43:05.323+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:05.322+0000] {dag.py:3069} INFO - Creating ORM DAG for load_data_to_bq
[2024-05-01T09:43:05.325+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:05.324+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:43:05.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.504 seconds
[2024-05-01T09:43:35.704+0000] {processor.py:161} INFO - Started process (PID=55324) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:35.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:43:35.710+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:35.709+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:35.754+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:43:35.831+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:35.830+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:43:35.869+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:43:35.869+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:43:35.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T09:44:06.304+0000] {processor.py:161} INFO - Started process (PID=55355) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:06.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:44:06.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:06.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:06.345+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:06.417+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:06.416+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:44:06.456+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:06.455+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:44:06.516+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T09:44:36.825+0000] {processor.py:161} INFO - Started process (PID=55386) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:36.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:44:36.832+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:36.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:36.866+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:44:36.938+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:36.937+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:44:36.976+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:44:36.975+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:44:37.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:45:07.362+0000] {processor.py:161} INFO - Started process (PID=55417) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:07.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:45:07.371+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:07.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:07.422+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:07.504+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:07.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:45:07.542+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:07.541+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:45:07.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.252 seconds
[2024-05-01T09:45:37.896+0000] {processor.py:161} INFO - Started process (PID=55448) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:37.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:45:37.903+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:37.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:37.940+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:38.016+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:38.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:45:38.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:38.056+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:45:38.116+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T09:45:48.623+0000] {processor.py:161} INFO - Started process (PID=55463) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:48.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:45:48.629+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:48.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:48.676+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:45:48.747+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:48.746+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:45:48.785+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:45:48.784+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:45:48.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T09:46:18.979+0000] {processor.py:161} INFO - Started process (PID=55500) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:18.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:46:18.988+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:18.987+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:19.029+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:19.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:19.117+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:46:19.161+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:19.160+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:46:19.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.266 seconds
[2024-05-01T09:46:49.913+0000] {processor.py:161} INFO - Started process (PID=55540) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:49.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:46:49.919+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:49.918+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:49.954+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:46:50.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:50.027+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:46:50.074+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:46:50.073+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:46:50.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T09:47:20.845+0000] {processor.py:161} INFO - Started process (PID=55572) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:20.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:47:20.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:20.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:20.887+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:20.959+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:20.958+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:47:20.997+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:20.997+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:47:21.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T09:47:51.817+0000] {processor.py:161} INFO - Started process (PID=55603) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:51.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:47:51.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:51.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:51.858+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:47:51.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:51.931+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:47:51.972+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:47:51.971+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:47:52.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T09:48:22.956+0000] {processor.py:161} INFO - Started process (PID=55634) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:22.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:48:22.962+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:22.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:22.997+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:23.069+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:23.068+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:48:23.109+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:23.108+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:48:23.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:48:53.971+0000] {processor.py:161} INFO - Started process (PID=55665) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:53.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:48:53.977+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:53.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:54.013+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:54.088+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:54.086+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:48:54.148+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:54.147+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:48:54.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T09:48:58.155+0000] {processor.py:161} INFO - Started process (PID=55670) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:58.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:48:58.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:58.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:58.204+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:48:58.274+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:58.273+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:48:58.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:48:58.317+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:48:58.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.239 seconds
[2024-05-01T09:49:28.802+0000] {processor.py:161} INFO - Started process (PID=55715) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:28.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:49:28.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:28.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:28.858+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:28.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:28.968+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:49:29.032+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:29.031+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:49:29.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.341 seconds
[2024-05-01T09:49:59.247+0000] {processor.py:161} INFO - Started process (PID=55747) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:59.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:49:59.252+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:59.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:59.287+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:49:59.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:59.356+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:49:59.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:49:59.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:49:59.452+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T09:50:29.765+0000] {processor.py:161} INFO - Started process (PID=55779) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:50:29.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:50:29.772+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:50:29.771+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:50:29.812+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:50:29.885+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:50:29.884+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:50:29.923+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:50:29.923+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:50:29.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T09:51:00.239+0000] {processor.py:161} INFO - Started process (PID=55810) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:00.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:51:00.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:00.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:00.287+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:00.358+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:00.357+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:51:00.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:00.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:51:00.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:51:30.662+0000] {processor.py:161} INFO - Started process (PID=55841) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:30.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:51:30.668+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:30.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:30.703+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:51:30.773+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:30.772+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:51:30.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:51:30.810+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:51:30.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T09:52:01.170+0000] {processor.py:161} INFO - Started process (PID=55872) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:01.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:52:01.177+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:01.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:01.212+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:01.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:01.282+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:52:01.321+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:01.320+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:52:01.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:52:31.637+0000] {processor.py:161} INFO - Started process (PID=55903) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:31.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:52:31.681+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:31.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:31.716+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:52:31.788+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:31.788+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:52:31.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:52:31.825+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:52:31.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T09:53:02.162+0000] {processor.py:161} INFO - Started process (PID=55934) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:02.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:53:02.167+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:02.166+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:02.202+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:02.274+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:02.273+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:53:02.313+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:02.312+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:53:02.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T09:53:32.586+0000] {processor.py:161} INFO - Started process (PID=55965) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:32.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:53:32.593+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:32.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:32.628+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:53:32.697+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:32.696+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:53:32.737+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:53:32.736+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:53:32.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T09:54:03.034+0000] {processor.py:161} INFO - Started process (PID=55996) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:03.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:54:03.045+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:03.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:03.097+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:03.166+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:03.165+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:54:03.204+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:03.204+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:54:03.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T09:54:33.483+0000] {processor.py:161} INFO - Started process (PID=56027) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:33.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:54:33.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:33.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:33.522+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:54:33.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:33.590+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:54:33.628+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:54:33.628+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:54:33.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T09:55:04.010+0000] {processor.py:161} INFO - Started process (PID=56059) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:04.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:55:04.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:04.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:04.073+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:04.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:04.145+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:55:04.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:04.182+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:55:04.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T09:55:34.490+0000] {processor.py:161} INFO - Started process (PID=56090) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:34.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:55:34.496+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:34.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:34.530+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:55:34.609+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:34.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:55:34.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:55:34.650+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:55:34.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T09:56:04.915+0000] {processor.py:161} INFO - Started process (PID=56121) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:04.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:56:04.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:04.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:04.955+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:05.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:05.024+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:56:05.065+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:05.064+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:56:05.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T09:56:35.337+0000] {processor.py:161} INFO - Started process (PID=56153) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:35.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:56:35.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:35.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:35.377+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:56:35.447+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:35.446+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:56:35.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:56:35.484+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:56:35.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T09:57:05.756+0000] {processor.py:161} INFO - Started process (PID=56184) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:05.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:57:05.762+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:05.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:05.797+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:05.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:05.865+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:57:05.903+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:05.903+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:57:05.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T09:57:36.237+0000] {processor.py:161} INFO - Started process (PID=56215) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:36.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:57:36.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:36.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:36.281+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:57:36.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:36.353+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:57:36.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:57:36.392+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:57:36.449+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T09:58:06.671+0000] {processor.py:161} INFO - Started process (PID=56246) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:06.674+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:58:06.677+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:06.676+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:06.712+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:06.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:06.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:58:06.832+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:06.831+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:58:06.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T09:58:37.261+0000] {processor.py:161} INFO - Started process (PID=56277) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:37.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:58:37.271+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:37.269+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:37.317+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:58:37.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:37.398+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:58:37.443+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:58:37.442+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:58:37.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.300 seconds
[2024-05-01T09:59:07.772+0000] {processor.py:161} INFO - Started process (PID=56315) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:07.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:59:07.778+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:07.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:07.813+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:07.885+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:07.884+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:59:07.923+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:07.922+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:59:07.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T09:59:38.269+0000] {processor.py:161} INFO - Started process (PID=56346) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:38.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T09:59:38.276+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:38.275+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:38.310+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T09:59:38.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:38.379+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T09:59:38.418+0000] {logging_mixin.py:188} INFO - [2024-05-01T09:59:38.417+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T09:59:38.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T10:00:08.717+0000] {processor.py:161} INFO - Started process (PID=56377) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:08.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:00:08.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:08.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:08.756+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:08.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:08.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:00:08.866+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:08.865+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:00:08.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T10:00:37.822+0000] {processor.py:161} INFO - Started process (PID=56402) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:37.826+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:00:37.829+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:37.828+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:37.870+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:00:37.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:37.954+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:00:38.002+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:00:38.001+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:00:38.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
[2024-05-01T10:01:08.794+0000] {processor.py:161} INFO - Started process (PID=56454) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:08.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:01:08.801+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:08.800+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:08.836+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:08.908+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:08.907+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:01:08.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:08.946+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:01:09.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T10:01:39.714+0000] {processor.py:161} INFO - Started process (PID=56487) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:39.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:01:39.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:39.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:39.755+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:01:39.827+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:39.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:01:39.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:01:39.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:01:39.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T10:02:10.656+0000] {processor.py:161} INFO - Started process (PID=56518) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:10.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:02:10.663+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:10.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:10.698+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:10.769+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:10.768+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:02:10.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:10.807+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:02:10.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T10:02:41.758+0000] {processor.py:161} INFO - Started process (PID=56550) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:41.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:02:41.764+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:41.763+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:41.799+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:02:41.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:41.876+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:02:41.922+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:02:41.922+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:02:41.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T10:03:12.758+0000] {processor.py:161} INFO - Started process (PID=56582) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:12.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:03:12.764+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:12.763+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:12.801+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:12.883+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:12.882+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:03:12.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:12.920+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:03:12.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T10:03:43.890+0000] {processor.py:161} INFO - Started process (PID=56613) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:43.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:03:43.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:43.899+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:43.950+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:03:44.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:44.026+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:03:44.064+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:03:44.064+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:03:44.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.289 seconds
[2024-05-01T10:04:14.861+0000] {processor.py:161} INFO - Started process (PID=56644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:14.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:04:14.867+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:14.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:14.904+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:14.973+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:14.973+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:04:15.012+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:15.011+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:04:15.070+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T10:04:45.807+0000] {processor.py:161} INFO - Started process (PID=56675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:45.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:04:45.815+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:45.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:45.849+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:04:45.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:45.921+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:04:45.960+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:04:45.960+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:04:46.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:05:16.096+0000] {processor.py:161} INFO - Started process (PID=56706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:16.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:05:16.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:16.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:16.136+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:16.209+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:16.208+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:05:16.250+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:16.250+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:05:16.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:05:46.620+0000] {processor.py:161} INFO - Started process (PID=56737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:46.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:05:46.628+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:46.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:46.663+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:05:46.735+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:46.734+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:05:46.778+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:05:46.778+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:05:46.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T10:06:17.077+0000] {processor.py:161} INFO - Started process (PID=56768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:17.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:06:17.082+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:17.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:17.117+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:17.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:17.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:06:17.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:17.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:06:17.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:06:47.715+0000] {processor.py:161} INFO - Started process (PID=56799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:47.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:06:47.725+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:47.723+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:47.783+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:06:47.895+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:47.894+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:06:47.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:06:47.954+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:06:48.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.345 seconds
[2024-05-01T10:07:18.618+0000] {processor.py:161} INFO - Started process (PID=56830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:18.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:07:18.623+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:18.622+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:18.662+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:18.733+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:18.732+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:07:18.785+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:18.783+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:07:18.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T10:07:49.632+0000] {processor.py:161} INFO - Started process (PID=56861) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:49.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:07:49.638+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:49.637+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:49.673+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:07:49.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:49.743+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:07:49.784+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:07:49.783+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:07:49.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:08:20.112+0000] {processor.py:161} INFO - Started process (PID=56892) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:20.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:08:20.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:20.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:20.153+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:20.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:20.224+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:08:20.703+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:20.703+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:08:20.757+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.655 seconds
[2024-05-01T10:08:51.488+0000] {processor.py:161} INFO - Started process (PID=56923) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:51.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:08:51.495+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:51.494+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:51.531+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:08:51.606+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:51.605+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:08:51.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:08:51.646+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:08:51.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T10:09:22.401+0000] {processor.py:161} INFO - Started process (PID=56955) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:22.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:09:22.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:22.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:22.444+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:22.517+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:22.516+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:09:22.561+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:22.560+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:09:22.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T10:09:31.037+0000] {processor.py:161} INFO - Started process (PID=56965) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:31.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:09:31.043+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:31.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:31.087+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:09:31.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:31.858+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:09:31.894+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:09:31.893+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:09:31.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.932 seconds
[2024-05-01T10:10:02.737+0000] {processor.py:161} INFO - Started process (PID=57011) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:02.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:10:02.744+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:02.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:02.779+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:03.276+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:03.275+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:10:03.309+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:03.308+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:10:03.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.635 seconds
[2024-05-01T10:10:33.504+0000] {processor.py:161} INFO - Started process (PID=57042) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:33.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:10:33.510+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:33.509+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:33.545+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:10:33.615+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:33.615+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:10:33.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:10:33.654+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:10:33.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T10:11:04.259+0000] {processor.py:161} INFO - Started process (PID=57073) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:04.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:11:04.266+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:04.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:04.301+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:04.373+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:04.373+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:11:04.852+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:04.851+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:11:04.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.657 seconds
[2024-05-01T10:11:35.353+0000] {processor.py:161} INFO - Started process (PID=57104) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:35.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:11:35.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:35.359+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:35.396+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:11:35.467+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:35.466+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:11:35.506+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:11:35.505+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:11:35.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:12:06.583+0000] {processor.py:161} INFO - Started process (PID=57135) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:06.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:12:06.593+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:06.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:06.627+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:06.698+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:06.698+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:12:06.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:06.737+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:12:06.799+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T10:12:37.181+0000] {processor.py:161} INFO - Started process (PID=57166) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:37.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:12:37.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:37.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:37.233+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:12:37.313+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:37.312+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:12:37.780+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:12:37.779+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:12:37.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.662 seconds
[2024-05-01T10:13:08.395+0000] {processor.py:161} INFO - Started process (PID=57197) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:08.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:13:08.401+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:08.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:08.436+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:08.935+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:08.934+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:13:08.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:08.967+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:13:09.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.635 seconds
[2024-05-01T10:13:39.583+0000] {processor.py:161} INFO - Started process (PID=57228) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:39.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:13:39.588+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:39.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:39.622+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:13:39.691+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:39.690+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:13:39.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:13:39.729+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:13:39.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T10:14:10.207+0000] {processor.py:161} INFO - Started process (PID=57259) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:10.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:14:10.214+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:10.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:10.260+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:10.347+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:10.346+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:14:10.809+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:10.808+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:14:10.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.663 seconds
[2024-05-01T10:14:41.366+0000] {processor.py:161} INFO - Started process (PID=57290) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:41.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:14:41.373+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:41.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:41.408+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:14:41.963+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:41.962+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:14:42.000+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:14:41.999+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:14:42.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.696 seconds
[2024-05-01T10:15:12.896+0000] {processor.py:161} INFO - Started process (PID=57325) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:12.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:15:12.905+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:12.903+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:12.959+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:13.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:13.074+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:15:13.159+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:13.158+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:15:13.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.369 seconds
[2024-05-01T10:15:30.137+0000] {processor.py:161} INFO - Started process (PID=57354) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:30.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:15:30.146+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:30.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:30.200+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:15:30.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:30.282+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:15:30.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:15:30.333+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:15:30.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.766 seconds
[2024-05-01T10:16:01.164+0000] {processor.py:161} INFO - Started process (PID=57397) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:01.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:16:01.171+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:01.170+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:01.206+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:01.710+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:01.709+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:16:01.743+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:01.743+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:16:01.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T10:16:32.759+0000] {processor.py:161} INFO - Started process (PID=57428) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:32.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:16:32.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:32.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:32.800+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:32.870+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:32.869+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:16:32.908+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:32.907+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:16:32.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T10:16:46.976+0000] {processor.py:161} INFO - Started process (PID=57449) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:46.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:16:46.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:46.983+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:47.032+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:16:47.116+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:47.115+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:16:47.176+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:16:47.175+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:16:47.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.713 seconds
[2024-05-01T10:17:17.889+0000] {processor.py:161} INFO - Started process (PID=57493) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:17.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:17:17.897+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:17.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:17.940+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:18.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:18.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:17:18.468+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:18.467+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:17:18.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.644 seconds
[2024-05-01T10:17:49.030+0000] {processor.py:161} INFO - Started process (PID=57526) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:49.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:17:49.038+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:49.037+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:49.078+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:17:49.149+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:49.148+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:17:49.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:17:49.187+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:17:49.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T10:18:13.866+0000] {processor.py:161} INFO - Started process (PID=57546) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:13.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:18:13.872+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:13.871+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:13.913+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:14.311+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:14.310+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:18:14.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:14.343+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:18:14.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.550 seconds
[2024-05-01T10:18:45.214+0000] {processor.py:161} INFO - Started process (PID=57598) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:45.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:18:45.221+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:45.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:45.256+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:18:45.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:45.326+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:18:45.366+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:18:45.365+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:18:45.424+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T10:19:15.683+0000] {processor.py:161} INFO - Started process (PID=57629) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:15.686+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:19:15.689+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:15.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:15.728+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:15.801+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:15.801+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:19:15.843+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:15.842+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:19:15.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T10:19:46.188+0000] {processor.py:161} INFO - Started process (PID=57660) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:46.191+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:19:46.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:46.193+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:46.229+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:19:46.302+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:46.300+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:19:46.342+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:19:46.341+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:19:46.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:20:16.756+0000] {processor.py:161} INFO - Started process (PID=57691) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:16.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:20:16.763+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:16.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:16.837+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:16.925+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:16.925+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:20:16.963+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:16.963+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:20:17.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.278 seconds
[2024-05-01T10:20:47.716+0000] {processor.py:161} INFO - Started process (PID=57722) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:47.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:20:47.726+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:47.724+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:47.774+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:20:47.864+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:47.863+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:20:47.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:20:47.901+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:20:47.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.259 seconds
[2024-05-01T10:21:19.004+0000] {processor.py:161} INFO - Started process (PID=57753) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:19.007+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:21:19.010+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:19.009+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:19.045+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:19.114+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:19.114+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:21:19.153+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:19.152+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:21:19.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T10:21:49.307+0000] {processor.py:161} INFO - Started process (PID=57784) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:49.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:21:49.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:49.313+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:49.369+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:21:49.446+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:49.445+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:21:49.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:21:49.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:21:49.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T10:22:19.751+0000] {processor.py:161} INFO - Started process (PID=57815) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:19.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:22:19.757+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:19.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:19.794+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:19.867+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:19.866+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:22:19.905+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:19.905+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:22:19.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T10:22:50.311+0000] {processor.py:161} INFO - Started process (PID=57847) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:50.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:22:50.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:50.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:50.363+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:50.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:50.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:22:50.473+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:50.473+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:22:50.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T10:22:54.568+0000] {processor.py:161} INFO - Started process (PID=57852) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:54.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:22:54.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:54.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:54.631+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:22:54.733+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:54.732+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:22:54.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:22:54.793+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:22:54.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.321 seconds
[2024-05-01T10:23:25.081+0000] {processor.py:161} INFO - Started process (PID=57898) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:25.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:23:25.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:25.089+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:25.136+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:25.247+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:25.245+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:23:25.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:25.302+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:23:25.381+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.317 seconds
[2024-05-01T10:23:56.115+0000] {processor.py:161} INFO - Started process (PID=57929) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:56.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:23:56.122+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:56.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:56.162+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:56.248+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:56.248+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:23:56.296+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:56.295+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:23:56.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T10:23:58.505+0000] {processor.py:161} INFO - Started process (PID=57939) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:58.508+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:23:58.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:58.510+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:58.565+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:23:58.648+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:58.647+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:23:58.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:23:58.694+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:23:58.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.284 seconds
[2024-05-01T10:24:28.894+0000] {processor.py:161} INFO - Started process (PID=57985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:28.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:24:28.899+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:24:28.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:28.933+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:29.006+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:24:29.005+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:24:29.044+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:24:29.044+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:24:29.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T10:24:59.873+0000] {processor.py:161} INFO - Started process (PID=58016) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:59.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:24:59.880+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:24:59.879+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:59.916+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:24:59.988+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:24:59.987+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:25:00.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:25:00.027+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:25:00.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T10:25:30.714+0000] {processor.py:161} INFO - Started process (PID=58047) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:25:30.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:25:30.721+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:25:30.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:25:30.758+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:25:30.828+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:25:30.827+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:25:30.866+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:25:30.865+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:25:30.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T10:26:01.692+0000] {processor.py:161} INFO - Started process (PID=58078) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:01.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:26:01.698+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:01.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:01.733+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:01.804+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:01.803+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:26:01.855+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:01.855+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:26:01.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T10:26:32.743+0000] {processor.py:161} INFO - Started process (PID=58109) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:32.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:26:32.750+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:32.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:32.785+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:26:32.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:32.858+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:26:32.899+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:26:32.898+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:26:32.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T10:27:03.090+0000] {processor.py:161} INFO - Started process (PID=58140) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:03.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:27:03.097+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:03.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:03.132+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:03.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:03.209+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:27:03.253+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:03.252+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:27:03.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T10:27:15.813+0000] {processor.py:161} INFO - Started process (PID=58150) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:15.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:27:15.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:15.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:15.860+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:15.930+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:15.929+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:27:15.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:15.983+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:27:16.050+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.248 seconds
[2024-05-01T10:27:46.338+0000] {processor.py:161} INFO - Started process (PID=58196) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:46.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:27:46.346+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:46.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:46.386+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:27:46.462+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:46.462+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:27:46.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:27:46.499+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:27:46.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T10:28:16.832+0000] {processor.py:161} INFO - Started process (PID=58228) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:16.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:28:16.838+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:16.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:16.872+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:16.945+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:16.945+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:28:16.984+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:16.984+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:28:17.042+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T10:28:47.310+0000] {processor.py:161} INFO - Started process (PID=58259) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:47.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:28:47.317+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:47.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:47.360+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:28:47.451+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:47.450+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:28:47.489+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:28:47.488+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:28:47.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T10:29:17.746+0000] {processor.py:161} INFO - Started process (PID=58290) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:17.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:29:17.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:17.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:17.786+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:17.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:17.857+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:29:17.901+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:17.900+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:29:17.998+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.264 seconds
[2024-05-01T10:29:48.258+0000] {processor.py:161} INFO - Started process (PID=58327) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:48.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:29:48.265+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:48.264+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:48.300+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:29:48.375+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:48.374+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:29:48.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:29:48.412+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:29:48.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T10:30:18.754+0000] {processor.py:161} INFO - Started process (PID=58358) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:18.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:30:18.764+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:18.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:18.808+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:18.901+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:18.900+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:30:18.940+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:18.939+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:30:18.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T10:30:49.216+0000] {processor.py:161} INFO - Started process (PID=58389) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:49.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:30:49.222+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:49.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:49.258+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:30:49.329+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:49.329+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:30:49.371+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:30:49.370+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:30:49.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:31:20.241+0000] {processor.py:161} INFO - Started process (PID=58419) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:20.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:31:20.247+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:20.246+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:20.282+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:20.355+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:20.354+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:31:20.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:20.398+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:31:20.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T10:31:51.338+0000] {processor.py:161} INFO - Started process (PID=58450) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:51.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:31:51.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:51.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:51.379+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:31:51.448+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:51.447+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:31:51.487+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:31:51.486+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:31:51.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T10:32:22.291+0000] {processor.py:161} INFO - Started process (PID=58481) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:22.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:32:22.296+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:22.295+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:22.331+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:22.403+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:22.403+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:32:22.444+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:22.444+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:32:22.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T10:32:53.134+0000] {processor.py:161} INFO - Started process (PID=58512) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:53.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:32:53.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:53.140+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:53.176+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:32:53.247+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:53.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:32:53.286+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:32:53.285+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:32:53.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T10:33:24.028+0000] {processor.py:161} INFO - Started process (PID=58543) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:24.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:33:24.035+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:24.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:24.071+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:24.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:24.143+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:33:24.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:24.182+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:33:24.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T10:33:54.981+0000] {processor.py:161} INFO - Started process (PID=58574) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:54.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:33:54.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:54.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:55.026+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:33:55.125+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:55.124+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:33:55.176+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:33:55.175+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:33:55.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.276 seconds
[2024-05-01T10:34:26.141+0000] {processor.py:161} INFO - Started process (PID=58605) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:26.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:34:26.147+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:26.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:26.184+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:26.257+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:26.256+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:34:26.294+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:26.294+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:34:26.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T10:34:57.065+0000] {processor.py:161} INFO - Started process (PID=58636) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:57.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:34:57.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:57.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:57.107+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:34:57.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:57.177+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:34:57.218+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:34:57.217+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:34:57.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T10:35:28.032+0000] {processor.py:161} INFO - Started process (PID=58667) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:28.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:35:28.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:28.038+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:28.075+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:28.148+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:28.147+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:35:28.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:28.188+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:35:28.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T10:35:58.621+0000] {processor.py:161} INFO - Started process (PID=58698) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:58.625+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:35:58.628+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:58.627+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:58.663+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:35:58.737+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:58.736+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:35:58.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:35:58.776+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:35:58.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T10:36:29.093+0000] {processor.py:161} INFO - Started process (PID=58729) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:29.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:36:29.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:29.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:29.134+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:29.208+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:29.207+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:36:29.255+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:29.254+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:36:29.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T10:36:59.641+0000] {processor.py:161} INFO - Started process (PID=58760) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:59.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:36:59.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:59.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:59.682+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:36:59.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:59.753+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:36:59.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:36:59.793+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:36:59.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T10:37:30.238+0000] {processor.py:161} INFO - Started process (PID=58791) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:30.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:37:30.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:30.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:30.280+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:30.356+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:30.356+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:37:30.396+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:30.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:37:30.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T10:37:53.342+0000] {processor.py:161} INFO - Started process (PID=58817) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:53.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:37:53.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:53.347+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:53.379+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:53.375+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/get_and_load.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/get_and_load.py", line 205, in <module>
    load_data_to_bq = PythonOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 185, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
TypeError: __init__() missing 1 required positional argument: 'task_id'
[2024-05-01T10:37:53.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:53.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.103 seconds
[2024-05-01T10:37:59.410+0000] {processor.py:161} INFO - Started process (PID=58822) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:59.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:37:59.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:59.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:59.459+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:37:59.537+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:59.536+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:37:59.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:37:59.585+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:37:59.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T10:38:29.759+0000] {processor.py:161} INFO - Started process (PID=58853) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:29.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:38:29.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:29.765+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:29.801+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:29.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:29.876+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:38:29.919+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:29.918+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:38:29.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T10:38:50.140+0000] {processor.py:161} INFO - Started process (PID=58878) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:50.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:38:50.146+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:50.145+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:50.188+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:38:50.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:50.259+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:38:50.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:38:50.307+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:38:50.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.247 seconds
[2024-05-01T10:39:20.500+0000] {processor.py:161} INFO - Started process (PID=58924) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:20.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:39:20.506+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:20.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:20.541+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:20.614+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:20.613+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:39:20.654+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:20.653+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:39:20.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:39:51.386+0000] {processor.py:161} INFO - Started process (PID=58962) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:51.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:39:51.392+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:51.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:51.430+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:39:51.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:51.499+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:39:51.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:39:51.540+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:39:51.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T10:40:22.396+0000] {processor.py:161} INFO - Started process (PID=58993) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:22.400+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:40:22.403+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:22.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:22.443+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:22.521+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:22.520+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:40:22.559+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:22.558+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:40:22.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T10:40:53.491+0000] {processor.py:161} INFO - Started process (PID=59024) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:53.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:40:53.497+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:53.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:53.532+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:40:53.604+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:53.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:40:53.651+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:40:53.650+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:40:53.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T10:41:24.545+0000] {processor.py:161} INFO - Started process (PID=59055) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:24.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:41:24.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:24.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:24.586+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:24.657+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:24.657+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:41:24.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:24.699+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:41:24.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T10:41:55.567+0000] {processor.py:161} INFO - Started process (PID=59086) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:55.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:41:55.573+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:55.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:55.608+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:41:55.681+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:55.680+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:41:55.719+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:41:55.718+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:41:55.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T10:42:26.596+0000] {processor.py:161} INFO - Started process (PID=59117) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:26.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:42:26.607+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:26.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:26.656+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:26.745+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:26.745+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:42:26.794+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:26.794+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:42:26.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.273 seconds
[2024-05-01T10:42:57.728+0000] {processor.py:161} INFO - Started process (PID=59148) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:57.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:42:57.735+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:57.734+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:57.770+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:42:57.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:57.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:42:57.896+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:42:57.895+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:42:57.951+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T10:43:28.732+0000] {processor.py:161} INFO - Started process (PID=59179) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:28.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:43:28.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:28.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:28.773+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:28.845+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:28.844+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:43:28.883+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:28.882+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:43:28.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T10:43:59.821+0000] {processor.py:161} INFO - Started process (PID=59210) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:59.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:43:59.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:59.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:59.862+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:43:59.945+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:59.945+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:43:59.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:43:59.987+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:44:00.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T10:44:30.775+0000] {processor.py:161} INFO - Started process (PID=59241) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:44:30.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:44:30.781+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:44:30.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:44:30.816+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:44:30.888+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:44:30.887+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:44:30.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:44:30.928+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:44:30.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T10:45:01.900+0000] {processor.py:161} INFO - Started process (PID=59272) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:01.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:45:01.907+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:01.906+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:01.943+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:02.017+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:02.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:45:02.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:02.055+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:45:02.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T10:45:32.872+0000] {processor.py:161} INFO - Started process (PID=59303) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:32.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:45:32.878+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:32.877+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:32.913+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:45:32.985+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:32.984+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:45:33.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:45:33.027+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:45:33.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T10:46:04.029+0000] {processor.py:161} INFO - Started process (PID=59334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:04.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:46:04.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:04.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:04.074+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:04.145+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:04.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:46:04.184+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:04.184+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:46:04.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:46:35.057+0000] {processor.py:161} INFO - Started process (PID=59365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:35.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:46:35.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:35.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:35.137+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:46:35.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:35.209+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:46:35.248+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:46:35.247+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:46:35.303+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.257 seconds
[2024-05-01T10:47:06.057+0000] {processor.py:161} INFO - Started process (PID=59396) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:06.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:47:06.064+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:06.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:06.099+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:06.234+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:06.233+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:47:06.279+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:06.278+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:47:06.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.296 seconds
[2024-05-01T10:47:37.139+0000] {processor.py:161} INFO - Started process (PID=59427) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:37.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:47:37.146+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:37.145+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:37.182+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:47:37.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:37.262+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:47:37.305+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:47:37.304+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:47:37.364+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T10:48:07.489+0000] {processor.py:161} INFO - Started process (PID=59458) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:07.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:48:07.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:07.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:07.548+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:07.632+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:07.631+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:48:07.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:07.670+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:48:07.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.253 seconds
[2024-05-01T10:48:37.982+0000] {processor.py:161} INFO - Started process (PID=59489) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:37.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:48:37.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:37.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:38.028+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:48:38.103+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:38.102+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:48:38.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:48:38.140+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:48:38.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T10:49:08.420+0000] {processor.py:161} INFO - Started process (PID=59520) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:08.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:49:08.428+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:08.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:08.469+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:08.559+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:08.556+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:49:08.634+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:08.633+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:49:08.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.288 seconds
[2024-05-01T10:49:38.927+0000] {processor.py:161} INFO - Started process (PID=59551) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:38.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:49:38.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:38.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:38.967+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:39.038+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:39.037+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:49:39.076+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:39.076+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:49:39.133+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T10:49:50.617+0000] {processor.py:161} INFO - Started process (PID=59561) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:50.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:49:50.624+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:50.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:50.666+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:49:50.749+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:50.749+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:49:50.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:49:50.789+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:49:50.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T10:50:21.008+0000] {processor.py:161} INFO - Started process (PID=59606) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:21.011+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:50:21.014+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:21.013+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:21.055+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:21.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:21.140+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:50:21.192+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:21.191+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:50:21.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T10:50:51.584+0000] {processor.py:161} INFO - Started process (PID=59638) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:51.588+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:50:51.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:51.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:51.628+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:50:51.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:51.700+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:50:51.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:50:51.738+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:50:51.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T10:51:22.060+0000] {processor.py:161} INFO - Started process (PID=59669) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:22.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:51:22.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:22.067+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:22.105+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:22.177+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:22.176+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:51:22.215+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:22.214+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:51:22.278+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T10:51:52.517+0000] {processor.py:161} INFO - Started process (PID=59700) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:52.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:51:52.523+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:52.522+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:52.560+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:51:52.632+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:52.631+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:51:52.676+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:51:52.676+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:51:52.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T10:52:23.030+0000] {processor.py:161} INFO - Started process (PID=59730) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:23.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:52:23.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:23.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:23.076+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:23.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:23.151+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:52:23.190+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:23.189+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:52:23.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T10:52:53.908+0000] {processor.py:161} INFO - Started process (PID=59756) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:53.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:52:53.915+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:53.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:53.967+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:52:54.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:54.076+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:52:54.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:52:54.186+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:52:54.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.371 seconds
[2024-05-01T10:53:24.563+0000] {processor.py:161} INFO - Started process (PID=59787) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:24.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:53:24.576+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:24.574+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:24.618+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:24.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:24.719+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:53:24.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:24.765+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:53:24.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.294 seconds
[2024-05-01T10:53:55.575+0000] {processor.py:161} INFO - Started process (PID=59818) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:55.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:53:55.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:55.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:55.630+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:53:55.742+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:55.741+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:53:55.786+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:53:55.786+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:53:55.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.293 seconds
[2024-05-01T10:54:26.528+0000] {processor.py:161} INFO - Started process (PID=59854) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:26.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:54:26.535+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:26.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:26.575+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:26.661+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:26.661+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:54:26.708+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:26.708+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:54:26.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.263 seconds
[2024-05-01T10:54:57.468+0000] {processor.py:161} INFO - Started process (PID=59885) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:57.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:54:57.475+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:57.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:57.515+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:54:57.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:57.602+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:54:57.648+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:54:57.648+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:54:57.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.287 seconds
[2024-05-01T10:55:28.457+0000] {processor.py:161} INFO - Started process (PID=59916) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:28.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:55:28.465+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:28.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:28.508+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:28.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:28.602+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:55:28.648+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:28.647+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:55:28.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T10:55:59.454+0000] {processor.py:161} INFO - Started process (PID=59947) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:59.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:55:59.460+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:59.459+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:59.500+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:55:59.589+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:59.588+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:55:59.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:55:59.632+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:55:59.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.264 seconds
[2024-05-01T10:56:30.409+0000] {processor.py:161} INFO - Started process (PID=59978) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:56:30.413+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:56:30.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:56:30.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:56:30.456+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:56:30.543+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:56:30.542+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:56:30.588+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:56:30.587+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:56:30.670+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
[2024-05-01T10:57:01.387+0000] {processor.py:161} INFO - Started process (PID=60009) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:01.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:57:01.394+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:01.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:01.435+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:01.524+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:01.523+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:57:01.569+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:01.568+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:57:01.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.264 seconds
[2024-05-01T10:57:32.307+0000] {processor.py:161} INFO - Started process (PID=60040) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:32.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:57:32.314+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:32.313+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:32.354+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:32.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:32.444+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:57:32.490+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:32.489+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:57:32.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T10:57:38.823+0000] {processor.py:161} INFO - Started process (PID=60060) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:38.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:57:38.834+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:38.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:38.890+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:57:38.962+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:38.961+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:57:39.004+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:57:39.004+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:57:39.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T10:58:09.149+0000] {processor.py:161} INFO - Started process (PID=60106) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:09.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:58:09.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:09.153+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:09.189+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:09.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:09.260+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:58:09.299+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:09.298+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:58:09.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T10:58:40.033+0000] {processor.py:161} INFO - Started process (PID=60137) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:40.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:58:40.041+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:40.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:40.076+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:58:40.147+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:40.146+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:58:40.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:58:40.186+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:58:40.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T10:59:11.152+0000] {processor.py:161} INFO - Started process (PID=60168) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:11.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:59:11.158+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:11.157+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:11.193+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:11.265+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:11.264+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:59:11.319+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:11.318+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:59:11.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T10:59:42.146+0000] {processor.py:161} INFO - Started process (PID=60199) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:42.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T10:59:42.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:42.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:42.187+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T10:59:42.259+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:42.258+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T10:59:42.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T10:59:42.296+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T10:59:42.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T11:00:13.257+0000] {processor.py:161} INFO - Started process (PID=60230) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:13.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:00:13.264+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:13.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:13.300+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:13.373+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:13.372+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:00:13.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:13.415+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:00:13.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T11:00:20.363+0000] {processor.py:161} INFO - Started process (PID=60235) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:20.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:00:20.371+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:20.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:20.420+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:20.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:20.502+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:00:20.550+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:20.549+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:00:20.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.279 seconds
[2024-05-01T11:00:51.016+0000] {processor.py:161} INFO - Started process (PID=60281) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:51.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:00:51.022+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:51.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:51.057+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:00:51.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:51.130+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:00:51.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:00:51.168+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:00:51.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:01:22.085+0000] {processor.py:161} INFO - Started process (PID=60312) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:22.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:01:22.094+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:22.093+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:22.131+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:22.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:22.212+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:01:22.252+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:22.252+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:01:22.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.248 seconds
[2024-05-01T11:01:52.980+0000] {processor.py:161} INFO - Started process (PID=60344) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:52.984+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:01:52.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:52.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:53.022+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:01:53.093+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:53.092+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:01:53.131+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:01:53.130+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:01:53.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.239 seconds
[2024-05-01T11:02:23.876+0000] {processor.py:161} INFO - Started process (PID=60375) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:23.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:02:23.883+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:23.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:23.918+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:23.992+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:23.991+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:02:24.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:24.055+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:02:24.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.265 seconds
[2024-05-01T11:02:55.084+0000] {processor.py:161} INFO - Started process (PID=60406) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:55.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:02:55.090+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:55.089+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:55.128+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:02:55.206+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:55.206+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:02:55.245+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:02:55.244+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:02:55.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T11:03:26.118+0000] {processor.py:161} INFO - Started process (PID=60437) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:26.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:03:26.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:26.123+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:26.159+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:26.232+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:26.231+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:03:26.271+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:26.270+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:03:26.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:03:57.174+0000] {processor.py:161} INFO - Started process (PID=60468) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:57.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:03:57.181+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:57.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:57.217+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:03:57.293+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:57.292+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:03:57.333+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:03:57.333+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:03:57.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T11:04:28.217+0000] {processor.py:161} INFO - Started process (PID=60500) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:28.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:04:28.222+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:28.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:28.257+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:28.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:28.335+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:04:28.373+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:28.373+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:04:28.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T11:04:58.716+0000] {processor.py:161} INFO - Started process (PID=60531) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:58.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:04:58.723+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:58.722+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:58.758+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:58.830+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:58.830+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:04:58.868+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:58.868+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:04:58.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T11:04:59.746+0000] {processor.py:161} INFO - Started process (PID=60542) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:59.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:04:59.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:59.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:59.802+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:04:59.878+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:59.877+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:04:59.924+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:04:59.923+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:05:00.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T11:05:30.187+0000] {processor.py:161} INFO - Started process (PID=60588) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:05:30.190+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:05:30.193+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:05:30.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:05:30.232+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:05:30.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:05:30.302+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:05:30.341+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:05:30.340+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:05:30.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:06:00.635+0000] {processor.py:161} INFO - Started process (PID=60618) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:00.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:06:00.642+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:00.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:00.677+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:00.748+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:00.748+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:06:00.787+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:00.786+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:06:00.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:06:31.029+0000] {processor.py:161} INFO - Started process (PID=60649) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:31.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:06:31.042+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:31.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:31.078+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:06:31.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:31.151+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:06:31.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:06:31.189+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:06:31.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T11:07:01.472+0000] {processor.py:161} INFO - Started process (PID=60680) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:01.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:07:01.479+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:01.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:01.513+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:01.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:01.585+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:07:01.625+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:01.625+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:07:01.683+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:07:31.927+0000] {processor.py:161} INFO - Started process (PID=60711) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:31.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:07:31.933+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:31.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:31.968+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:07:32.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:32.038+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:07:32.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:07:32.076+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:07:32.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:08:02.401+0000] {processor.py:161} INFO - Started process (PID=60743) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:02.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:08:02.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:02.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:02.441+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:02.514+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:02.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:08:02.552+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:02.551+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:08:02.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T11:08:32.950+0000] {processor.py:161} INFO - Started process (PID=60774) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:32.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:08:32.958+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:32.957+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:32.993+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:08:33.073+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:33.073+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:08:33.123+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:08:33.122+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:08:33.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T11:09:03.446+0000] {processor.py:161} INFO - Started process (PID=60805) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:03.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:09:03.451+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:03.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:03.486+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:03.558+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:03.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:09:03.596+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:03.595+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:09:03.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T11:09:34.120+0000] {processor.py:161} INFO - Started process (PID=60836) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:34.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:09:34.134+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:34.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:34.178+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:09:34.252+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:34.251+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:09:34.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:09:34.291+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:09:34.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T11:10:05.238+0000] {processor.py:161} INFO - Started process (PID=60867) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:05.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:10:05.245+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:05.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:05.279+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:05.349+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:05.348+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:10:05.387+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:05.387+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:10:05.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.214 seconds
[2024-05-01T11:10:36.271+0000] {processor.py:161} INFO - Started process (PID=60898) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:36.275+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:10:36.278+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:36.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:36.316+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:10:36.392+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:36.391+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:10:36.429+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:10:36.429+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:10:36.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T11:11:07.239+0000] {processor.py:161} INFO - Started process (PID=60929) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:07.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:11:07.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:07.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:07.278+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:07.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:07.347+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:11:07.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:07.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:11:07.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.213 seconds
[2024-05-01T11:11:38.257+0000] {processor.py:161} INFO - Started process (PID=60960) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:38.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:11:38.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:38.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:38.298+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:11:38.367+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:38.367+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:11:38.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:11:38.405+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:11:38.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T11:12:09.149+0000] {processor.py:161} INFO - Started process (PID=60991) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:09.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:12:09.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:09.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:09.219+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:09.318+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:09.317+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:12:09.360+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:09.359+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:12:09.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.281 seconds
[2024-05-01T11:12:18.583+0000] {processor.py:161} INFO - Started process (PID=61001) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:18.587+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:12:18.590+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:18.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:18.633+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:18.707+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:18.706+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:12:18.745+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:18.744+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:12:18.809+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T11:12:49.512+0000] {processor.py:161} INFO - Started process (PID=61032) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:49.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:12:49.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:49.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:49.554+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:12:49.626+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:49.626+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:12:49.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:12:49.670+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:12:49.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T11:13:20.611+0000] {processor.py:161} INFO - Started process (PID=61078) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:20.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:13:20.617+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:20.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:20.653+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:20.728+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:20.727+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:13:20.766+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:20.765+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:13:20.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T11:13:50.938+0000] {processor.py:161} INFO - Started process (PID=61109) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:50.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:13:50.945+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:50.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:50.984+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:13:51.062+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:51.061+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:13:51.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:13:51.099+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:13:51.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T11:14:21.520+0000] {processor.py:161} INFO - Started process (PID=61140) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:21.524+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:14:21.527+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:21.526+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:21.565+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:21.639+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:21.638+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:14:21.677+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:21.676+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:14:21.733+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T11:14:52.051+0000] {processor.py:161} INFO - Started process (PID=61171) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:52.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:14:52.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:52.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:52.096+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:14:52.196+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:52.195+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:14:52.255+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:14:52.254+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:14:52.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.284 seconds
[2024-05-01T11:15:22.684+0000] {processor.py:161} INFO - Started process (PID=61204) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:22.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:15:22.691+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:22.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:22.734+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:22.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:22.818+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:15:22.865+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:22.864+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:15:22.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.262 seconds
[2024-05-01T11:15:53.024+0000] {processor.py:161} INFO - Started process (PID=61235) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:53.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:15:53.030+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:53.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:53.064+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:15:53.135+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:53.135+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:15:53.173+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:15:53.172+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:15:53.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:16:23.973+0000] {processor.py:161} INFO - Started process (PID=61267) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:23.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:16:23.980+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:23.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:24.015+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:24.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:24.085+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:16:24.124+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:24.124+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:16:24.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:16:54.940+0000] {processor.py:161} INFO - Started process (PID=61298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:54.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:16:54.946+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:54.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:54.982+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:16:55.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:55.054+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:16:55.093+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:16:55.092+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:16:55.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:17:16.775+0000] {processor.py:161} INFO - Started process (PID=61323) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:16.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:17:16.781+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:16.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:16.823+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:16.890+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:16.890+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:17:16.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:16.928+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:17:16.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T11:17:47.934+0000] {processor.py:161} INFO - Started process (PID=61369) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:47.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:17:47.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:47.940+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:47.983+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:17:48.075+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:48.074+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:17:48.121+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:17:48.120+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:17:48.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.272 seconds
[2024-05-01T11:18:18.545+0000] {processor.py:161} INFO - Started process (PID=61400) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:18.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:18:18.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:18.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:18.585+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:18.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:18.655+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:18:18.694+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:18.694+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:18:18.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.215 seconds
[2024-05-01T11:18:24.196+0000] {processor.py:161} INFO - Started process (PID=61410) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:24.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:18:24.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:24.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:24.248+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:24.332+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:24.331+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:18:24.394+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:24.393+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:18:24.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.317 seconds
[2024-05-01T11:18:54.724+0000] {processor.py:161} INFO - Started process (PID=61456) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:54.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:18:54.731+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:54.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:54.790+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:18:54.880+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:54.878+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:18:54.922+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:18:54.921+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:18:54.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.267 seconds
[2024-05-01T11:19:25.684+0000] {processor.py:161} INFO - Started process (PID=61487) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:25.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:19:25.690+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:25.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:25.725+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:25.797+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:25.795+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:19:25.838+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:25.837+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:19:25.895+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T11:19:55.975+0000] {processor.py:161} INFO - Started process (PID=61518) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:55.979+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:19:55.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:55.980+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:56.017+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:19:56.088+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:56.087+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:19:56.127+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:19:56.127+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:19:56.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:20:26.917+0000] {processor.py:161} INFO - Started process (PID=61549) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:26.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:20:26.923+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:26.922+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:26.958+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:27.029+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:27.028+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:20:27.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:27.067+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:20:27.127+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:20:57.895+0000] {processor.py:161} INFO - Started process (PID=61580) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:57.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:20:57.903+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:57.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:57.952+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:20:58.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:58.025+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:20:58.064+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:20:58.063+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:20:58.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T11:21:11.314+0000] {processor.py:161} INFO - Started process (PID=61596) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:11.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:21:11.320+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:11.319+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:11.362+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:11.433+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:11.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:21:11.486+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:11.485+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:21:11.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.276 seconds
[2024-05-01T11:21:41.669+0000] {processor.py:161} INFO - Started process (PID=61636) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:41.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:21:41.676+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:41.675+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:41.717+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:21:41.805+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:41.804+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:21:41.859+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:21:41.858+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:21:41.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.278 seconds
[2024-05-01T11:22:12.074+0000] {processor.py:161} INFO - Started process (PID=61673) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:12.077+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:22:12.080+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:12.079+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:12.115+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:12.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:12.186+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:22:12.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:12.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:22:12.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:22:43.110+0000] {processor.py:161} INFO - Started process (PID=61704) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:43.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:22:43.118+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:43.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:43.158+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:22:43.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:43.229+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:22:43.269+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:22:43.269+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:22:43.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T11:23:13.513+0000] {processor.py:161} INFO - Started process (PID=61734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:13.516+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:23:13.519+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:13.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:13.554+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:13.625+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:13.624+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:23:13.665+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:13.664+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:23:13.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:23:44.027+0000] {processor.py:161} INFO - Started process (PID=61765) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:44.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:23:44.034+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:44.033+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:44.069+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:23:44.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:44.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:23:44.180+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:23:44.179+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:23:44.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:24:14.551+0000] {processor.py:161} INFO - Started process (PID=61796) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:14.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:24:14.556+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:14.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:14.592+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:14.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:14.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:24:14.714+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:14.713+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:24:14.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T11:24:45.061+0000] {processor.py:161} INFO - Started process (PID=61827) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:45.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:24:45.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:45.067+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:45.105+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:24:45.181+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:45.180+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:24:45.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:24:45.224+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:24:45.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T11:25:15.578+0000] {processor.py:161} INFO - Started process (PID=61858) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:15.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:25:15.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:15.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:15.630+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:15.711+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:15.710+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:25:15.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:15.750+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:25:15.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T11:25:45.927+0000] {processor.py:161} INFO - Started process (PID=61889) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:45.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:25:45.938+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:45.936+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:45.974+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:25:46.046+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:46.046+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:25:46.085+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:25:46.084+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:25:46.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T11:26:16.342+0000] {processor.py:161} INFO - Started process (PID=61934) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:16.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:26:16.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:16.352+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:16.397+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:16.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:16.491+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:26:16.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:16.539+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:26:16.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.281 seconds
[2024-05-01T11:26:46.938+0000] {processor.py:161} INFO - Started process (PID=61966) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:46.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:26:46.945+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:46.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:46.980+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:47.054+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:47.053+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:26:47.094+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:47.093+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:26:47.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T11:26:57.378+0000] {processor.py:161} INFO - Started process (PID=61981) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:57.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:26:57.384+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:57.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:57.429+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:57.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:57.513+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:26:57.555+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:57.554+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:26:57.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.253 seconds
[2024-05-01T11:26:58.406+0000] {processor.py:161} INFO - Started process (PID=61986) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:58.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:26:58.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:58.410+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:58.454+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:58.525+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:58.525+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:26:58.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:58.573+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:26:58.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.273 seconds
[2024-05-01T11:26:59.724+0000] {processor.py:161} INFO - Started process (PID=61991) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:59.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:26:59.730+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:59.729+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:59.772+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:26:59.841+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:59.841+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:26:59.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:26:59.880+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:26:59.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T11:27:30.182+0000] {processor.py:161} INFO - Started process (PID=62023) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:27:30.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:27:30.188+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:27:30.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:27:30.224+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:27:30.297+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:27:30.296+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:27:30.335+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:27:30.335+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:27:30.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T11:28:00.776+0000] {processor.py:161} INFO - Started process (PID=62063) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:00.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:28:00.783+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:00.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:00.829+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:00.920+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:00.919+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:28:00.979+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:00.977+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:28:01.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.287 seconds
[2024-05-01T11:28:31.738+0000] {processor.py:161} INFO - Started process (PID=62100) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:31.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:28:31.748+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:31.746+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:31.794+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:31.864+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:31.863+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:28:31.902+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:31.901+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:28:31.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T11:28:39.206+0000] {processor.py:161} INFO - Started process (PID=62116) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:39.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:28:39.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:39.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:39.265+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:28:39.355+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:39.354+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:28:39.399+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:28:39.398+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:28:39.463+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.268 seconds
[2024-05-01T11:29:10.190+0000] {processor.py:161} INFO - Started process (PID=62147) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:10.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:29:10.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:10.199+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:10.269+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:10.379+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:10.378+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:29:10.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:10.439+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:29:10.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.353 seconds
[2024-05-01T11:29:41.472+0000] {processor.py:161} INFO - Started process (PID=62178) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:41.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:29:41.482+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:41.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:41.530+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:29:41.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:41.600+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:29:41.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:29:41.645+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:29:41.709+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.254 seconds
[2024-05-01T11:30:11.982+0000] {processor.py:161} INFO - Started process (PID=62209) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:11.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:30:11.989+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:11.988+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:12.024+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:12.099+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:12.098+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:30:12.138+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:12.138+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:30:12.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.224 seconds
[2024-05-01T11:30:42.407+0000] {processor.py:161} INFO - Started process (PID=62240) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:42.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:30:42.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:42.412+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:42.448+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:30:42.518+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:42.518+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:30:42.556+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:30:42.556+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:30:42.613+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T11:31:06.190+0000] {processor.py:161} INFO - Started process (PID=62260) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:06.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:31:06.197+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:06.196+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:06.239+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:06.320+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:06.320+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:31:06.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:06.360+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:31:06.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T11:31:36.605+0000] {processor.py:161} INFO - Started process (PID=62302) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:36.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:31:36.612+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:36.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:36.651+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:31:36.735+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:36.734+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:31:36.778+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:31:36.777+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:31:36.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.251 seconds
[2024-05-01T11:32:07.132+0000] {processor.py:161} INFO - Started process (PID=62337) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:07.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:32:07.139+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:07.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:07.174+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:07.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:07.245+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:32:07.284+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:07.284+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:32:07.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:32:37.655+0000] {processor.py:161} INFO - Started process (PID=62368) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:37.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:32:37.662+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:37.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:37.697+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:32:37.768+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:37.767+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:32:37.808+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:32:37.807+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:32:37.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:33:08.131+0000] {processor.py:161} INFO - Started process (PID=62399) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:08.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:33:08.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:08.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:08.172+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:08.244+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:08.244+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:33:08.283+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:08.283+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:33:08.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:33:38.595+0000] {processor.py:161} INFO - Started process (PID=62430) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:38.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:33:38.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:38.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:38.636+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:33:38.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:38.711+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:33:38.783+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:33:38.782+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:33:38.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T11:34:09.075+0000] {processor.py:161} INFO - Started process (PID=62467) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:09.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:34:09.082+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:09.081+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:09.131+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:09.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:09.212+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:34:09.254+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:09.253+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:34:09.316+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T11:34:39.618+0000] {processor.py:161} INFO - Started process (PID=62499) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:39.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:34:39.625+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:39.624+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:39.661+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:34:39.733+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:39.732+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:34:39.771+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:34:39.771+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:34:39.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:35:10.091+0000] {processor.py:161} INFO - Started process (PID=62529) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:10.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:35:10.099+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:10.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:10.135+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:10.205+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:10.204+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:35:10.243+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:10.243+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:35:10.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:35:40.537+0000] {processor.py:161} INFO - Started process (PID=62560) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:40.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:35:40.544+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:40.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:40.578+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:35:40.648+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:40.647+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:35:40.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:35:40.687+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:35:40.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:36:11.008+0000] {processor.py:161} INFO - Started process (PID=62591) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:11.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:36:11.015+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:11.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:11.053+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:11.129+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:11.128+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:36:11.169+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:11.168+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:36:11.226+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T11:36:41.475+0000] {processor.py:161} INFO - Started process (PID=62622) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:41.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:36:41.481+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:41.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:41.517+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:36:41.609+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:41.608+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:36:41.655+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:36:41.654+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:36:41.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.250 seconds
[2024-05-01T11:37:11.968+0000] {processor.py:161} INFO - Started process (PID=62654) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:11.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:37:11.978+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:11.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:12.019+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:12.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:12.102+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:37:12.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:12.154+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:37:12.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.332 seconds
[2024-05-01T11:37:42.557+0000] {processor.py:161} INFO - Started process (PID=62685) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:42.561+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:37:42.563+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:42.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:42.599+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:37:42.676+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:42.675+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:37:42.737+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:37:42.737+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:37:42.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.259 seconds
[2024-05-01T11:38:13.096+0000] {processor.py:161} INFO - Started process (PID=62715) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:13.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:38:13.102+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:13.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:13.137+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:13.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:13.208+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:38:13.248+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:13.247+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:38:13.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:38:43.595+0000] {processor.py:161} INFO - Started process (PID=62746) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:43.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:38:43.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:43.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:43.637+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:38:43.708+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:43.708+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:38:43.749+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:38:43.749+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:38:43.814+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T11:39:14.078+0000] {processor.py:161} INFO - Started process (PID=62777) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:14.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:39:14.083+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:14.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:14.119+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:14.189+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:14.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:39:14.251+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:14.250+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:39:14.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T11:39:44.609+0000] {processor.py:161} INFO - Started process (PID=62808) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:44.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:39:44.616+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:44.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:44.651+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:39:44.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:44.722+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:39:44.761+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:39:44.760+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:39:44.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:40:15.075+0000] {processor.py:161} INFO - Started process (PID=62839) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:15.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:40:15.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:15.080+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:15.116+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:15.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:15.186+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:40:15.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:15.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:40:15.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T11:40:45.546+0000] {processor.py:161} INFO - Started process (PID=62870) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:45.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:40:45.551+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:45.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:45.586+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:40:45.659+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:45.658+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:40:45.698+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:40:45.697+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:40:45.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T11:41:16.091+0000] {processor.py:161} INFO - Started process (PID=62900) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:16.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:41:16.097+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:16.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:16.132+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:16.202+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:16.202+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:41:16.241+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:16.240+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:41:16.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:41:46.518+0000] {processor.py:161} INFO - Started process (PID=62931) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:46.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:41:46.525+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:46.524+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:46.560+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:41:46.633+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:46.632+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:41:46.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:41:46.670+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:41:46.728+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:42:17.038+0000] {processor.py:161} INFO - Started process (PID=62962) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:17.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:42:17.045+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:17.044+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:17.081+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:17.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:17.152+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:42:17.191+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:17.190+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:42:17.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:42:47.527+0000] {processor.py:161} INFO - Started process (PID=62993) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:47.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:42:47.539+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:47.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:47.597+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:42:47.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:47.671+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:42:47.710+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:42:47.710+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:42:47.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.281 seconds
[2024-05-01T11:43:18.097+0000] {processor.py:161} INFO - Started process (PID=63024) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:18.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:43:18.104+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:18.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:18.139+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:18.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:18.212+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:43:18.250+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:18.250+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:43:18.308+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:43:25.493+0000] {processor.py:161} INFO - Started process (PID=63034) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:25.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:43:25.499+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:25.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:25.540+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:25.611+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:25.610+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:43:25.648+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:25.648+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:43:25.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T11:43:56.709+0000] {processor.py:161} INFO - Started process (PID=63065) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:56.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:43:56.716+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:56.715+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:56.751+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:43:56.820+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:56.819+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:43:56.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:43:56.858+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:43:56.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T11:44:27.156+0000] {processor.py:161} INFO - Started process (PID=63111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:27.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:44:27.164+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:27.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:27.215+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:27.307+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:27.306+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:44:27.353+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:27.352+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:44:27.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.274 seconds
[2024-05-01T11:44:57.639+0000] {processor.py:161} INFO - Started process (PID=63143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:57.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:44:57.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:57.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:57.681+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:44:57.752+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:57.751+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:44:57.791+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:44:57.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:44:57.848+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:45:28.105+0000] {processor.py:161} INFO - Started process (PID=63174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:28.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:45:28.111+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:28.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:28.147+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:28.221+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:28.220+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:45:28.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:28.262+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:45:28.322+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T11:45:58.533+0000] {processor.py:161} INFO - Started process (PID=63205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:58.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:45:58.541+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:58.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:58.576+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:45:58.646+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:58.646+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:45:58.686+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:45:58.685+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:45:58.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T11:46:20.043+0000] {processor.py:161} INFO - Started process (PID=63231) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:20.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:46:20.051+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:20.050+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:20.102+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:20.177+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:20.176+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:46:20.216+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:20.215+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:46:20.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T11:46:50.611+0000] {processor.py:161} INFO - Started process (PID=63263) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:50.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:46:50.617+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:50.616+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:50.654+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:46:50.757+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:50.755+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:46:50.819+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:46:50.818+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:46:50.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.285 seconds
[2024-05-01T11:47:21.136+0000] {processor.py:161} INFO - Started process (PID=63294) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:21.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:47:21.143+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:21.142+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:21.184+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:21.256+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:21.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:47:21.294+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:21.293+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:47:21.350+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T11:47:41.638+0000] {processor.py:161} INFO - Started process (PID=63309) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:41.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:47:41.643+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:41.642+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:41.685+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:47:41.757+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:41.756+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:47:41.795+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:47:41.795+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:47:41.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T11:48:12.204+0000] {processor.py:161} INFO - Started process (PID=63355) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:12.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:48:12.210+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:12.209+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:12.246+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:12.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:12.316+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:48:12.357+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:12.357+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:48:12.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:48:42.699+0000] {processor.py:161} INFO - Started process (PID=63386) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:42.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:48:42.705+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:42.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:42.741+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:48:42.818+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:42.817+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:48:42.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:48:42.857+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:48:42.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T11:49:13.214+0000] {processor.py:161} INFO - Started process (PID=63417) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:13.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:49:13.221+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:13.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:13.256+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:13.327+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:13.326+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:49:13.367+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:13.366+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:49:13.436+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T11:49:43.731+0000] {processor.py:161} INFO - Started process (PID=63448) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:43.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:49:43.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:43.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:43.773+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:49:43.847+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:43.846+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:49:43.888+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:49:43.887+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:49:43.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T11:50:14.374+0000] {processor.py:161} INFO - Started process (PID=63479) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:14.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:50:14.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:14.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:14.425+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:14.532+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:14.532+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:50:14.572+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:14.571+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:50:14.631+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.280 seconds
[2024-05-01T11:50:44.878+0000] {processor.py:161} INFO - Started process (PID=63515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:44.881+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:50:44.884+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:44.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:44.919+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:50:44.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:44.990+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:50:45.029+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:50:45.028+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:50:45.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T11:51:00.630+0000] {processor.py:161} INFO - Started process (PID=63530) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:00.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:51:00.636+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:00.635+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:00.678+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:00.750+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:00.750+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:51:00.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:00.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:51:00.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T11:51:31.233+0000] {processor.py:161} INFO - Started process (PID=63576) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:31.236+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:51:31.239+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:31.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:31.273+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:51:31.345+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:31.345+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:51:31.384+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:51:31.383+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:51:31.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:52:01.819+0000] {processor.py:161} INFO - Started process (PID=63607) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:01.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:52:01.826+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:01.825+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:01.861+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:01.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:01.931+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:52:01.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:01.970+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:52:02.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T11:52:32.374+0000] {processor.py:161} INFO - Started process (PID=63638) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:32.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:52:32.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:32.379+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:32.414+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:52:32.486+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:32.486+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:52:32.524+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:52:32.524+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:52:32.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T11:53:02.874+0000] {processor.py:161} INFO - Started process (PID=63669) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:02.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:53:02.881+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:02.880+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:02.915+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:02.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:02.987+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:53:03.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:03.025+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:53:03.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T11:53:33.354+0000] {processor.py:161} INFO - Started process (PID=63700) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:33.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:53:33.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:33.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:33.396+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:53:33.533+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:33.532+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:53:33.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:53:33.574+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:53:33.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.289 seconds
[2024-05-01T11:54:03.905+0000] {processor.py:161} INFO - Started process (PID=63731) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:03.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:54:03.911+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:03.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:03.946+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:04.016+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:04.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:54:04.055+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:04.054+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:54:04.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T11:54:34.363+0000] {processor.py:161} INFO - Started process (PID=63762) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:34.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:54:34.368+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:34.367+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:34.403+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:34.475+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:34.474+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:54:34.513+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:34.513+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:54:34.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.217 seconds
[2024-05-01T11:54:35.392+0000] {processor.py:161} INFO - Started process (PID=63767) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:35.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:54:35.397+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:35.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:35.438+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:35.509+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:35.508+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:54:35.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:35.548+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:54:35.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T11:54:46.063+0000] {processor.py:161} INFO - Started process (PID=63783) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:46.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:54:46.077+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:46.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:46.168+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:54:46.281+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:46.280+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:54:46.335+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:54:46.334+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:54:46.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.370 seconds
[2024-05-01T11:55:16.594+0000] {processor.py:161} INFO - Started process (PID=63829) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:16.598+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:55:16.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:16.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:16.646+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:16.731+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:16.730+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:55:16.776+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:16.775+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:55:16.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.266 seconds
[2024-05-01T11:55:46.929+0000] {processor.py:161} INFO - Started process (PID=63860) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:46.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:55:46.936+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:46.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:46.970+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:55:47.043+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:47.043+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:55:47.084+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:55:47.083+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:55:47.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T11:56:17.362+0000] {processor.py:161} INFO - Started process (PID=63891) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:17.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:56:17.369+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:17.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:17.404+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:17.483+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:17.482+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:56:17.520+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:17.520+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:56:17.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T11:56:47.842+0000] {processor.py:161} INFO - Started process (PID=63922) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:47.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:56:47.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:47.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:47.883+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:56:48.010+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:48.009+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:56:48.052+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:56:48.051+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:56:48.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.278 seconds
[2024-05-01T11:57:18.577+0000] {processor.py:161} INFO - Started process (PID=63953) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:18.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:57:18.584+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:18.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:18.631+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:18.734+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:18.733+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:57:18.791+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:18.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:57:18.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.318 seconds
[2024-05-01T11:57:49.572+0000] {processor.py:161} INFO - Started process (PID=63984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:49.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:57:49.579+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:49.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:49.619+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:57:49.704+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:49.704+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:57:49.751+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:57:49.750+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:57:49.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.292 seconds
[2024-05-01T11:58:20.519+0000] {processor.py:161} INFO - Started process (PID=64015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:20.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:58:20.526+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:20.525+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:20.566+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:20.652+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:20.651+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:58:20.699+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:20.698+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:58:20.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T11:58:51.468+0000] {processor.py:161} INFO - Started process (PID=64046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:51.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:58:51.476+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:51.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:51.516+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:58:51.601+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:51.600+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:58:51.649+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:58:51.648+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:58:51.726+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T11:59:22.439+0000] {processor.py:161} INFO - Started process (PID=64077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:22.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:59:22.446+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:22.445+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:22.486+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:22.571+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:22.571+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:59:22.616+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:22.615+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:59:22.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T11:59:53.472+0000] {processor.py:161} INFO - Started process (PID=64108) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:53.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T11:59:53.478+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:53.477+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:53.518+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T11:59:53.607+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:53.606+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T11:59:53.655+0000] {logging_mixin.py:188} INFO - [2024-05-01T11:59:53.655+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T11:59:53.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.266 seconds
[2024-05-01T12:00:24.401+0000] {processor.py:161} INFO - Started process (PID=64139) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:24.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:00:24.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:24.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:24.448+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:24.535+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:24.534+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:00:24.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:24.581+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:00:24.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.258 seconds
[2024-05-01T12:00:55.333+0000] {processor.py:161} INFO - Started process (PID=64170) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:55.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:00:55.340+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:55.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:55.380+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:00:55.464+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:55.464+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:00:55.509+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:00:55.509+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:00:55.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T12:01:26.283+0000] {processor.py:161} INFO - Started process (PID=64201) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:26.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:01:26.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:26.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:26.330+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:26.418+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:26.417+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:01:26.466+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:26.466+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:01:26.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
[2024-05-01T12:01:46.068+0000] {processor.py:161} INFO - Started process (PID=64221) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:46.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:01:46.073+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:46.072+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:46.115+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:01:46.185+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:46.184+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:01:46.223+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:01:46.222+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:01:46.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:02:17.100+0000] {processor.py:161} INFO - Started process (PID=64255) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:17.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:02:17.108+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:17.106+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:17.147+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:17.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:17.229+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:02:17.273+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:17.271+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:02:17.339+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.250 seconds
[2024-05-01T12:02:47.542+0000] {processor.py:161} INFO - Started process (PID=64298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:47.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:02:47.549+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:47.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:47.588+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:02:47.660+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:47.659+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:02:47.701+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:02:47.700+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:02:47.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:03:18.397+0000] {processor.py:161} INFO - Started process (PID=64329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:18.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:03:18.405+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:18.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:18.440+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:18.512+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:18.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:03:18.550+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:18.550+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:03:18.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T12:03:49.279+0000] {processor.py:161} INFO - Started process (PID=64366) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:49.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:03:49.286+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:49.285+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:49.321+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:03:49.393+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:49.392+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:03:49.432+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:03:49.432+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:03:49.490+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T12:04:20.154+0000] {processor.py:161} INFO - Started process (PID=64397) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:20.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:04:20.160+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:20.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:20.195+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:20.268+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:20.267+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:04:20.309+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:20.309+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:04:20.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T12:04:50.516+0000] {processor.py:161} INFO - Started process (PID=64428) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:50.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:04:50.521+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:50.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:50.555+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:04:50.626+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:50.626+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:04:50.664+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:04:50.664+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:04:50.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.216 seconds
[2024-05-01T12:05:21.045+0000] {processor.py:161} INFO - Started process (PID=64460) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:21.048+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:05:21.050+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:21.049+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:21.085+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:21.155+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:21.155+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:05:21.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:21.193+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:05:21.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T12:05:37.109+0000] {processor.py:161} INFO - Started process (PID=64475) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:37.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:05:37.116+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:37.115+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:37.168+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:05:37.290+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:37.289+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:05:37.340+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:05:37.339+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:05:37.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.337 seconds
[2024-05-01T12:06:07.816+0000] {processor.py:161} INFO - Started process (PID=64526) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:07.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:06:07.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:07.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:07.859+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:07.930+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:07.930+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:06:07.968+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:07.968+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:06:08.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T12:06:38.224+0000] {processor.py:161} INFO - Started process (PID=64557) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:38.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:06:38.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:38.229+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:38.266+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:06:38.336+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:38.335+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:06:38.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:06:38.373+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:06:38.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.218 seconds
[2024-05-01T12:07:08.712+0000] {processor.py:161} INFO - Started process (PID=64588) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:08.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:07:08.718+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:08.717+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:08.754+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:08.825+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:08.824+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:07:08.866+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:08.865+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:07:08.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T12:07:39.206+0000] {processor.py:161} INFO - Started process (PID=64619) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:39.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:07:39.214+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:39.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:39.251+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:39.324+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:39.323+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:07:39.361+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:39.361+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:07:39.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T12:07:47.907+0000] {processor.py:161} INFO - Started process (PID=64629) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:47.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:07:47.913+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:47.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:47.955+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:07:48.026+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:48.025+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:07:48.067+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:07:48.066+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:07:48.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T12:08:18.903+0000] {processor.py:161} INFO - Started process (PID=64675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:18.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:08:18.908+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:18.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:18.943+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:19.014+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:19.013+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:08:19.052+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:19.052+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:08:19.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.219 seconds
[2024-05-01T12:08:49.806+0000] {processor.py:161} INFO - Started process (PID=64706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:49.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:08:49.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:49.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:49.847+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:08:49.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:49.920+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:08:49.960+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:08:49.959+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:08:50.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.221 seconds
[2024-05-01T12:09:20.663+0000] {processor.py:161} INFO - Started process (PID=64737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:20.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:09:20.670+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:20.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:20.705+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:20.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:20.777+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:09:20.816+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:20.815+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:09:20.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.222 seconds
[2024-05-01T12:09:51.749+0000] {processor.py:161} INFO - Started process (PID=64774) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:51.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:09:51.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:51.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:51.789+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:09:51.861+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:51.860+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:09:51.900+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:09:51.899+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:09:51.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T12:10:20.706+0000] {processor.py:161} INFO - Started process (PID=64799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:20.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:10:20.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:20.711+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:20.753+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:21.094+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:21.093+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:10:21.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:21.155+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:10:21.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.578 seconds
[2024-05-01T12:10:51.562+0000] {processor.py:161} INFO - Started process (PID=64845) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:51.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:10:51.573+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:51.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:51.632+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:10:51.771+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:51.770+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:10:51.832+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:10:51.831+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:10:51.929+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.399 seconds
[2024-05-01T12:11:20.870+0000] {processor.py:161} INFO - Started process (PID=64876) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:20.874+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:11:20.877+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:20.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:20.922+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:20.995+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:20.994+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:11:21.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:21.035+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:11:21.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T12:11:51.913+0000] {processor.py:161} INFO - Started process (PID=64907) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:51.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:11:51.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:51.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:51.962+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:11:52.056+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:52.055+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:11:52.095+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:11:52.094+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:11:52.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.261 seconds
[2024-05-01T12:12:15.547+0000] {processor.py:161} INFO - Started process (PID=64929) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:15.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:12:15.554+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:15.552+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:15.596+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:15.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:15.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:12:15.712+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:15.712+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:12:15.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T12:12:16.919+0000] {processor.py:161} INFO - Started process (PID=64939) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:16.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:12:16.928+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:16.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:16.982+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:17.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:17.052+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:12:17.092+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:17.091+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:12:17.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T12:12:47.488+0000] {processor.py:161} INFO - Started process (PID=64984) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:47.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:12:47.494+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:47.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:47.529+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:12:47.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:47.601+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:12:47.640+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:12:47.639+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:12:47.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T12:13:18.458+0000] {processor.py:161} INFO - Started process (PID=65015) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:18.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:13:18.464+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:18.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:18.514+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:18.605+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:18.604+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:13:18.647+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:18.646+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:13:18.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.259 seconds
[2024-05-01T12:13:48.805+0000] {processor.py:161} INFO - Started process (PID=65046) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:48.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:13:48.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:48.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:48.847+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:13:48.938+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:48.938+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:13:48.989+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:13:48.988+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:13:49.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T12:14:19.249+0000] {processor.py:161} INFO - Started process (PID=65077) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:19.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:14:19.259+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:19.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:19.317+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:19.404+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:19.404+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:14:19.443+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:19.442+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:14:19.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.276 seconds
[2024-05-01T12:14:49.804+0000] {processor.py:161} INFO - Started process (PID=65108) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:49.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:14:49.810+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:49.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:49.844+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:14:49.916+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:49.915+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:14:49.957+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:14:49.956+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:14:50.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.220 seconds
[2024-05-01T12:15:20.312+0000] {processor.py:161} INFO - Started process (PID=65142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:20.316+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:15:20.319+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:20.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:20.354+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:20.425+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:20.425+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:15:20.464+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:20.463+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:15:20.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T12:15:50.861+0000] {processor.py:161} INFO - Started process (PID=65173) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:50.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:15:50.868+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:50.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:50.903+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:15:50.978+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:50.977+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:15:51.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:15:51.022+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:15:51.082+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:16:21.418+0000] {processor.py:161} INFO - Started process (PID=65204) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:21.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:16:21.425+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:21.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:21.459+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:21.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:21.537+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:16:21.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:21.581+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:16:21.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T12:16:51.909+0000] {processor.py:161} INFO - Started process (PID=65236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:51.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:16:51.915+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:51.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:51.951+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:16:52.024+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:52.024+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:16:52.064+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:16:52.063+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:16:52.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:17:03.318+0000] {processor.py:161} INFO - Started process (PID=65252) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:03.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:17:03.324+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:03.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:03.382+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:03.745+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:03.744+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:17:03.786+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:03.786+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:17:03.854+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.547 seconds
[2024-05-01T12:17:34.154+0000] {processor.py:161} INFO - Started process (PID=65298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:34.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:17:34.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:34.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:34.223+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:17:34.307+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:34.306+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:17:34.354+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:17:34.353+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:17:34.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.281 seconds
[2024-05-01T12:18:05.038+0000] {processor.py:161} INFO - Started process (PID=65329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:05.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:18:05.044+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:05.043+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:05.091+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:05.160+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:05.159+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:18:05.201+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:05.200+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:18:05.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:18:35.974+0000] {processor.py:161} INFO - Started process (PID=65361) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:35.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:18:35.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:35.980+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:36.028+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:18:36.105+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:36.104+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:18:36.151+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:18:36.150+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:18:36.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.247 seconds
[2024-05-01T12:19:07.131+0000] {processor.py:161} INFO - Started process (PID=65392) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:07.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:19:07.138+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:07.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:07.185+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:07.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:07.259+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:19:07.298+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:07.297+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:19:07.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.239 seconds
[2024-05-01T12:19:38.154+0000] {processor.py:161} INFO - Started process (PID=65423) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:38.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:19:38.160+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:38.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:38.208+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:38.281+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:38.280+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:19:38.319+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:38.318+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:19:38.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T12:19:49.577+0000] {processor.py:161} INFO - Started process (PID=65433) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:49.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:19:49.584+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:49.583+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:49.658+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:19:49.997+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:49.996+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:19:50.030+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:19:50.029+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:19:50.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.531 seconds
[2024-05-01T12:20:20.260+0000] {processor.py:161} INFO - Started process (PID=65479) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:20.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:20:20.268+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:20.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:20.317+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:20.392+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:20.391+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:20:20.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:20.440+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:20:20.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.262 seconds
[2024-05-01T12:20:51.247+0000] {processor.py:161} INFO - Started process (PID=65510) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:51.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:20:51.252+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:51.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:51.301+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:20:51.372+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:51.372+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:20:51.413+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:20:51.412+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:20:51.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T12:21:22.431+0000] {processor.py:161} INFO - Started process (PID=65541) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:22.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:21:22.437+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:22.436+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:22.484+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:22.553+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:22.553+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:21:22.592+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:22.591+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:21:22.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T12:21:53.480+0000] {processor.py:161} INFO - Started process (PID=65572) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:53.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:21:53.485+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:53.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:53.532+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:21:53.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:53.601+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:21:53.655+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:21:53.655+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:21:53.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T12:22:05.384+0000] {processor.py:161} INFO - Started process (PID=65598) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:05.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:22:05.390+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:05.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:05.446+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:05.825+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:05.824+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:22:05.858+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:05.857+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:22:05.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.550 seconds
[2024-05-01T12:22:36.694+0000] {processor.py:161} INFO - Started process (PID=65644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:36.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:22:36.701+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:36.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:36.750+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:36.820+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:36.820+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:22:36.862+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:36.862+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:22:36.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T12:22:57.539+0000] {processor.py:161} INFO - Started process (PID=65660) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:57.542+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:22:57.545+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:57.544+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:57.604+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:22:57.947+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:57.947+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:22:57.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:22:57.980+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:22:58.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.516 seconds
[2024-05-01T12:23:28.517+0000] {processor.py:161} INFO - Started process (PID=65706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:28.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:23:28.524+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:28.522+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:28.570+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:28.650+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:28.649+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:23:28.696+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:28.695+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:23:28.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.246 seconds
[2024-05-01T12:23:59.446+0000] {processor.py:161} INFO - Started process (PID=65737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:59.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:23:59.456+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:59.454+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:59.505+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:23:59.575+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:59.574+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:23:59.616+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:23:59.615+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:23:59.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T12:24:30.473+0000] {processor.py:161} INFO - Started process (PID=65768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:24:30.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:24:30.479+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:24:30.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:24:30.527+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:24:30.596+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:24:30.595+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:24:30.634+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:24:30.634+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:24:30.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:25:01.399+0000] {processor.py:161} INFO - Started process (PID=65799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:01.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:25:01.406+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:01.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:01.453+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:01.521+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:01.521+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:25:01.562+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:01.562+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:25:01.623+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T12:25:32.060+0000] {processor.py:161} INFO - Started process (PID=65830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:32.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:25:32.065+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:32.064+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:32.113+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:25:32.185+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:32.184+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:25:32.223+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:25:32.222+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:25:32.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T12:26:03.066+0000] {processor.py:161} INFO - Started process (PID=65861) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:03.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:26:03.072+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:03.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:03.120+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:03.188+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:03.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:26:03.226+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:03.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:26:03.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T12:26:34.029+0000] {processor.py:161} INFO - Started process (PID=65892) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:34.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:26:34.035+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:34.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:34.084+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:26:34.154+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:34.154+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:26:34.196+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:26:34.195+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:26:34.299+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.280 seconds
[2024-05-01T12:27:05.013+0000] {processor.py:161} INFO - Started process (PID=65923) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:05.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:27:05.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:05.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:05.067+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:05.138+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:05.138+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:27:05.180+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:05.179+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:27:05.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T12:27:36.029+0000] {processor.py:161} INFO - Started process (PID=65954) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:36.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:27:36.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:36.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:36.086+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:27:36.157+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:36.156+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:27:36.200+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:27:36.199+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:27:36.256+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T12:28:07.076+0000] {processor.py:161} INFO - Started process (PID=65985) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:07.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:28:07.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:07.084+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:07.146+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:07.215+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:07.214+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:28:07.253+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:07.252+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:28:07.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.255 seconds
[2024-05-01T12:28:38.099+0000] {processor.py:161} INFO - Started process (PID=66016) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:38.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:28:38.104+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:38.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:38.152+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:28:38.223+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:38.222+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:28:38.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:28:38.260+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:28:38.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T12:29:09.369+0000] {processor.py:161} INFO - Started process (PID=66047) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:09.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:29:09.375+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:09.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:09.422+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:09.491+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:09.491+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:29:09.530+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:09.529+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:29:09.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.225 seconds
[2024-05-01T12:29:40.297+0000] {processor.py:161} INFO - Started process (PID=66079) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:40.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:29:40.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:40.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:40.367+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:29:40.453+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:40.452+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:29:40.499+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:29:40.498+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:29:40.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.278 seconds
[2024-05-01T12:30:11.283+0000] {processor.py:161} INFO - Started process (PID=66112) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:11.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:30:11.292+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:11.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:11.346+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:11.415+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:11.414+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:30:11.455+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:11.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:30:11.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.239 seconds
[2024-05-01T12:30:42.339+0000] {processor.py:161} INFO - Started process (PID=66143) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:42.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:30:42.346+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:42.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:42.393+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:30:42.465+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:42.464+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:30:42.503+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:30:42.502+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:30:42.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T12:31:13.058+0000] {processor.py:161} INFO - Started process (PID=66174) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:13.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:31:13.085+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:13.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:13.139+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:13.220+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:13.220+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:31:13.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:13.262+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:31:13.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.277 seconds
[2024-05-01T12:31:44.284+0000] {processor.py:161} INFO - Started process (PID=66205) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:44.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:31:44.291+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:44.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:44.338+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:31:44.408+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:44.407+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:31:44.446+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:31:44.445+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:31:44.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T12:32:15.223+0000] {processor.py:161} INFO - Started process (PID=66236) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:15.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:32:15.229+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:15.227+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:15.276+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:15.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:15.348+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:32:15.387+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:15.386+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:32:15.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:32:46.235+0000] {processor.py:161} INFO - Started process (PID=66267) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:46.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:32:46.241+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:46.240+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:46.288+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:32:46.358+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:46.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:32:46.407+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:32:46.406+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:32:46.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.251 seconds
[2024-05-01T12:33:17.222+0000] {processor.py:161} INFO - Started process (PID=66298) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:17.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:33:17.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:17.226+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:17.275+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:17.343+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:17.342+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:33:17.381+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:17.380+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:33:17.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.223 seconds
[2024-05-01T12:33:48.165+0000] {processor.py:161} INFO - Started process (PID=66329) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:48.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:33:48.172+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:48.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:48.221+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:33:48.291+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:48.290+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:33:48.332+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:33:48.331+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:33:48.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:34:19.156+0000] {processor.py:161} INFO - Started process (PID=66360) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:19.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:34:19.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:19.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:19.209+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:19.277+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:19.277+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:34:19.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:19.314+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:34:19.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:34:50.200+0000] {processor.py:161} INFO - Started process (PID=66391) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:50.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:34:50.207+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:50.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:50.253+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:34:50.322+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:50.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:34:50.363+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:34:50.362+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:34:50.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:35:21.201+0000] {processor.py:161} INFO - Started process (PID=66422) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:21.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:35:21.208+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:21.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:21.255+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:21.325+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:21.324+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:35:21.363+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:21.362+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:35:21.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T12:35:52.171+0000] {processor.py:161} INFO - Started process (PID=66453) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:52.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:35:52.177+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:52.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:52.224+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:35:52.293+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:52.293+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:35:52.331+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:35:52.330+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:35:52.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T12:36:23.119+0000] {processor.py:161} INFO - Started process (PID=66484) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:23.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:36:23.125+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:23.124+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:23.178+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:23.255+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:23.254+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:36:23.294+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:23.293+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:36:23.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T12:36:54.078+0000] {processor.py:161} INFO - Started process (PID=66515) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:54.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:36:54.086+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:54.085+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:54.136+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:36:54.208+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:54.207+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:36:54.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:36:54.245+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:36:54.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T12:37:25.029+0000] {processor.py:161} INFO - Started process (PID=66547) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:25.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:37:25.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:25.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:25.084+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:25.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:25.155+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:37:25.196+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:25.196+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:37:25.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T12:37:56.022+0000] {processor.py:161} INFO - Started process (PID=66578) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:56.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:37:56.028+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:56.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:56.081+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:37:56.156+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:56.155+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:37:56.194+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:37:56.194+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:37:56.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.239 seconds
[2024-05-01T12:38:26.958+0000] {processor.py:161} INFO - Started process (PID=66609) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:26.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:38:26.965+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:26.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:27.012+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:27.081+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:27.081+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:38:27.123+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:27.122+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:38:27.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.259 seconds
[2024-05-01T12:38:57.914+0000] {processor.py:161} INFO - Started process (PID=66640) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:57.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:38:57.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:57.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:57.968+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:38:58.037+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:58.037+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:38:58.079+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:38:58.078+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:38:58.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:39:28.966+0000] {processor.py:161} INFO - Started process (PID=66672) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:28.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:39:28.972+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:28.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:29.024+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:29.103+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:29.102+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:39:29.141+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:29.141+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:39:29.198+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T12:39:59.462+0000] {processor.py:161} INFO - Started process (PID=66703) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:59.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:39:59.469+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:59.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:59.516+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:39:59.591+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:59.590+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:39:59.629+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:39:59.628+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:39:59.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T12:40:30.020+0000] {processor.py:161} INFO - Started process (PID=66734) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:40:30.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:40:30.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:40:30.024+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:40:30.073+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:40:30.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:40:30.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:40:30.183+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:40:30.183+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:40:30.239+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T12:41:00.376+0000] {processor.py:161} INFO - Started process (PID=66766) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:00.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:41:00.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:00.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:00.430+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:00.502+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:00.501+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:41:00.542+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:00.542+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:41:00.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T12:41:31.310+0000] {processor.py:161} INFO - Started process (PID=66797) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:31.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:41:31.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:31.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:31.362+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:41:31.431+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:31.430+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:41:31.470+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:41:31.470+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:41:31.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
[2024-05-01T12:42:02.244+0000] {processor.py:161} INFO - Started process (PID=66834) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:02.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:42:02.251+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:02.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:02.303+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:02.374+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:02.373+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:42:02.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:02.411+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:42:02.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.238 seconds
[2024-05-01T12:42:33.223+0000] {processor.py:161} INFO - Started process (PID=66865) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:33.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:42:33.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:33.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:33.277+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:42:33.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:33.347+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:42:33.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:42:33.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:42:33.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:43:04.257+0000] {processor.py:161} INFO - Started process (PID=66896) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:04.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:43:04.263+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:04.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:04.311+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:04.383+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:04.382+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:43:04.434+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:04.432+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:43:04.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.251 seconds
[2024-05-01T12:43:35.012+0000] {processor.py:161} INFO - Started process (PID=66927) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:35.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:43:35.018+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:35.017+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:35.065+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:43:35.144+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:35.143+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:43:35.186+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:43:35.185+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:43:35.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T12:44:05.950+0000] {processor.py:161} INFO - Started process (PID=66958) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:05.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:44:05.957+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:05.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:06.006+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:06.075+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:06.074+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:44:06.113+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:06.112+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:44:06.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:44:36.925+0000] {processor.py:161} INFO - Started process (PID=66989) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:36.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:44:36.932+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:36.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:36.979+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:44:37.051+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:37.050+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:44:37.092+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:44:37.092+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:44:37.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T12:45:07.885+0000] {processor.py:161} INFO - Started process (PID=67020) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:07.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:45:07.892+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:07.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:07.939+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:08.068+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:08.067+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:45:08.108+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:08.107+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:45:08.163+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.289 seconds
[2024-05-01T12:45:38.575+0000] {processor.py:161} INFO - Started process (PID=67051) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:38.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:45:38.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:38.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:38.629+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:45:38.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:38.699+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:45:38.742+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:45:38.741+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:45:38.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.244 seconds
[2024-05-01T12:46:09.830+0000] {processor.py:161} INFO - Started process (PID=67082) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:09.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:46:09.836+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:09.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:09.883+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:09.954+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:09.953+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:46:09.996+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:09.995+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:46:10.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:46:40.860+0000] {processor.py:161} INFO - Started process (PID=67114) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:40.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:46:40.874+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:40.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:40.943+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:46:41.023+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:41.022+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:46:41.060+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:46:41.060+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:46:41.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T12:47:11.816+0000] {processor.py:161} INFO - Started process (PID=67145) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:11.820+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:47:11.823+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:11.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:11.871+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:11.941+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:11.940+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:47:11.981+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:11.981+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:47:12.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T12:47:42.663+0000] {processor.py:161} INFO - Started process (PID=67176) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:42.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:47:42.669+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:42.668+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:42.716+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:47:42.790+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:42.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:47:42.829+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:47:42.828+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:47:42.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T12:48:13.218+0000] {processor.py:161} INFO - Started process (PID=67208) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:13.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:48:13.224+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:13.223+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:13.272+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:13.342+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:13.341+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:48:13.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:13.379+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:48:13.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T12:48:43.792+0000] {processor.py:161} INFO - Started process (PID=67239) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:43.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:48:43.799+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:43.798+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:43.846+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:48:43.918+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:43.917+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:48:43.955+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:48:43.955+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:48:44.022+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T12:49:14.323+0000] {processor.py:161} INFO - Started process (PID=67270) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:14.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:49:14.330+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:14.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:14.379+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:14.451+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:14.450+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:49:14.492+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:14.491+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:49:14.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.237 seconds
[2024-05-01T12:49:44.873+0000] {processor.py:161} INFO - Started process (PID=67302) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:44.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:49:44.880+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:44.879+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:44.927+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:49:44.999+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:44.999+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:49:45.039+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:49:45.038+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:49:45.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T12:50:15.439+0000] {processor.py:161} INFO - Started process (PID=67334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:15.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:50:15.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:15.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:15.493+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:15.563+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:15.563+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:50:15.602+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:15.601+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:50:15.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:50:45.912+0000] {processor.py:161} INFO - Started process (PID=67365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:45.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:50:45.918+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:45.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:45.965+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:50:46.036+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:46.035+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:50:46.078+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:50:46.077+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:50:46.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.286 seconds
[2024-05-01T12:51:17.252+0000] {processor.py:161} INFO - Started process (PID=67396) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:17.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:51:17.261+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:17.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:17.310+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:17.380+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:17.379+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:51:17.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:17.419+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:51:17.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T12:51:48.240+0000] {processor.py:161} INFO - Started process (PID=67427) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:48.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:51:48.246+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:48.245+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:48.293+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:51:48.364+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:48.363+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:51:48.402+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:51:48.401+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:51:48.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T12:52:18.574+0000] {processor.py:161} INFO - Started process (PID=67458) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:18.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:52:18.580+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:18.579+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:18.627+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:18.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:18.700+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:52:18.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:18.738+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:52:18.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T12:52:49.093+0000] {processor.py:161} INFO - Started process (PID=67489) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:49.097+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:52:49.100+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:49.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:49.148+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:52:49.222+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:49.221+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:52:49.267+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:52:49.267+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:52:49.343+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.260 seconds
[2024-05-01T12:53:19.681+0000] {processor.py:161} INFO - Started process (PID=67520) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:19.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:53:19.688+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:19.687+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:19.735+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:19.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:19.806+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:53:19.849+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:19.848+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:53:19.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T12:53:50.219+0000] {processor.py:161} INFO - Started process (PID=67551) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:50.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:53:50.225+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:50.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:50.273+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:53:50.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:50.347+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:53:50.386+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:53:50.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:53:50.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T12:54:20.804+0000] {processor.py:161} INFO - Started process (PID=67582) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:20.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:54:20.812+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:20.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:20.865+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:20.937+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:20.936+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:54:20.975+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:20.975+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:54:21.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.249 seconds
[2024-05-01T12:54:51.349+0000] {processor.py:161} INFO - Started process (PID=67613) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:51.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:54:51.356+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:51.355+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:51.403+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:54:51.475+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:51.475+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:54:51.533+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:54:51.532+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:54:51.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.260 seconds
[2024-05-01T12:55:21.746+0000] {processor.py:161} INFO - Started process (PID=67644) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:21.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:55:21.754+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:21.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:21.806+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:21.879+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:21.878+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:55:21.917+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:21.917+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:55:21.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.243 seconds
[2024-05-01T12:55:52.649+0000] {processor.py:161} INFO - Started process (PID=67675) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:52.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:55:52.655+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:52.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:52.704+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:55:52.784+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:52.783+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:55:52.832+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:55:52.831+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:55:52.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.274 seconds
[2024-05-01T12:56:23.652+0000] {processor.py:161} INFO - Started process (PID=67706) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:23.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:56:23.658+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:23.657+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:23.707+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:23.777+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:23.776+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:56:23.814+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:23.814+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:56:23.870+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.229 seconds
[2024-05-01T12:56:54.451+0000] {processor.py:161} INFO - Started process (PID=67737) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:54.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:56:54.458+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:54.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:54.507+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:56:54.578+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:54.578+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:56:54.619+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:56:54.618+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:56:54.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T12:57:25.701+0000] {processor.py:161} INFO - Started process (PID=67768) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:25.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:57:25.707+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:25.706+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:25.755+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:25.850+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:25.848+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:57:25.927+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:25.927+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:57:25.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.293 seconds
[2024-05-01T12:57:56.615+0000] {processor.py:161} INFO - Started process (PID=67799) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:56.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:57:56.622+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:56.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:56.669+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:57:56.738+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:56.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:57:56.776+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:57:56.776+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:57:56.836+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T12:58:27.568+0000] {processor.py:161} INFO - Started process (PID=67830) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:27.572+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:58:27.576+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:27.574+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:27.623+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:27.697+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:27.697+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:58:27.735+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:27.734+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:58:27.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T12:58:58.295+0000] {processor.py:161} INFO - Started process (PID=67862) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:58.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:58:58.303+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:58.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:58.351+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:58:58.423+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:58.423+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:58:58.462+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:58:58.461+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:58:58.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T12:59:29.221+0000] {processor.py:161} INFO - Started process (PID=67893) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T12:59:29.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T12:59:29.227+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:59:29.226+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:59:29.277+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T12:59:29.347+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:59:29.346+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T12:59:29.387+0000] {logging_mixin.py:188} INFO - [2024-05-01T12:59:29.386+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T12:59:29.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.231 seconds
[2024-05-01T13:00:00.181+0000] {processor.py:161} INFO - Started process (PID=67924) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:00.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:00:00.187+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:00.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:00.235+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:00.304+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:00.304+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:00:00.342+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:00.342+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:00:00.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T13:00:31.124+0000] {processor.py:161} INFO - Started process (PID=67956) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:31.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:00:31.132+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:31.130+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:31.179+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:00:31.248+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:31.248+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:00:31.298+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:00:31.298+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:00:31.360+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.247 seconds
[2024-05-01T13:01:02.092+0000] {processor.py:161} INFO - Started process (PID=67987) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:02.096+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:01:02.099+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:02.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:02.147+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:02.218+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:02.218+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:01:02.257+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:02.256+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:01:02.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T13:01:33.156+0000] {processor.py:161} INFO - Started process (PID=68018) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:33.160+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:01:33.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:33.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:33.209+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:01:33.279+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:33.278+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:01:33.317+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:01:33.317+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:01:33.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T13:02:04.220+0000] {processor.py:161} INFO - Started process (PID=68049) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:04.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:02:04.230+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:04.228+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:04.293+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:04.377+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:04.376+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:02:04.440+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:04.439+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:02:04.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.303 seconds
[2024-05-01T13:02:35.153+0000] {processor.py:161} INFO - Started process (PID=68080) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:35.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:02:35.160+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:35.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:35.220+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:02:35.310+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:35.309+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:02:35.356+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:02:35.355+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:02:35.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.285 seconds
[2024-05-01T13:03:06.259+0000] {processor.py:161} INFO - Started process (PID=68111) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:06.263+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:03:06.266+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:06.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:06.314+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:06.385+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:06.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:03:06.426+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:06.425+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:03:06.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T13:03:37.294+0000] {processor.py:161} INFO - Started process (PID=68142) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:37.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:03:37.300+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:37.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:37.347+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:03:37.416+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:37.416+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:03:37.454+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:03:37.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:03:37.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.226 seconds
[2024-05-01T13:04:07.968+0000] {processor.py:161} INFO - Started process (PID=68173) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:07.972+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:04:07.975+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:07.974+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:08.022+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:08.094+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:08.093+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:04:08.132+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:08.132+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:04:08.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T13:04:39.241+0000] {processor.py:161} INFO - Started process (PID=68210) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:39.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:04:39.248+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:39.246+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:39.304+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:04:39.376+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:39.375+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:04:39.414+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:04:39.413+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:04:39.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T13:05:10.196+0000] {processor.py:161} INFO - Started process (PID=68241) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:10.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:05:10.202+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:10.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:10.250+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:10.348+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:10.347+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:05:10.398+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:10.397+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:05:10.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.270 seconds
[2024-05-01T13:05:41.157+0000] {processor.py:161} INFO - Started process (PID=68272) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:41.161+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:05:41.163+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:41.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:41.210+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:05:41.280+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:41.279+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:05:41.320+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:05:41.319+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:05:41.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T13:06:11.532+0000] {processor.py:161} INFO - Started process (PID=68303) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:11.535+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:06:11.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:11.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:11.585+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:11.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:11.656+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:06:11.696+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:11.695+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:06:11.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.230 seconds
[2024-05-01T13:06:42.046+0000] {processor.py:161} INFO - Started process (PID=68334) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:42.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:06:42.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:42.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:42.100+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:06:42.172+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:42.172+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:06:42.213+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:06:42.212+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:06:42.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.271 seconds
[2024-05-01T13:07:12.650+0000] {processor.py:161} INFO - Started process (PID=68365) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:12.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:07:12.656+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:12.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:12.703+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:12.776+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:12.776+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:07:12.814+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:12.813+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:07:12.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T13:07:43.142+0000] {processor.py:161} INFO - Started process (PID=68397) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:43.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:07:43.149+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:43.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:43.197+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:07:43.269+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:43.269+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:07:43.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:07:43.307+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:07:43.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.236 seconds
[2024-05-01T13:08:13.493+0000] {processor.py:161} INFO - Started process (PID=68428) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:13.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:08:13.500+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:13.499+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:13.590+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:13.700+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:13.700+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:08:13.753+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:13.752+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:08:13.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.326 seconds
[2024-05-01T13:08:44.663+0000] {processor.py:161} INFO - Started process (PID=68459) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:44.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:08:44.671+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:44.670+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:44.719+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:08:44.791+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:44.790+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:08:44.831+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:08:44.830+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:08:44.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T13:09:15.322+0000] {processor.py:161} INFO - Started process (PID=68490) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:15.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:09:15.328+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:15.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:15.375+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:15.447+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:15.447+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:09:15.488+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:15.487+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:09:15.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T13:09:46.228+0000] {processor.py:161} INFO - Started process (PID=68521) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:46.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:09:46.235+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:46.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:46.282+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:09:46.353+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:46.353+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:09:46.391+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:09:46.390+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:09:46.451+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.233 seconds
[2024-05-01T13:10:17.309+0000] {processor.py:161} INFO - Started process (PID=68552) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:17.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:10:17.316+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:17.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:17.365+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:17.435+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:17.435+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:10:17.477+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:17.476+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:10:17.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.663 seconds
[2024-05-01T13:10:48.135+0000] {processor.py:161} INFO - Started process (PID=68583) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:48.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:10:48.142+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:48.140+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:48.189+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:10:48.260+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:48.259+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:10:48.300+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:10:48.299+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:10:48.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T13:11:19.016+0000] {processor.py:161} INFO - Started process (PID=68614) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:19.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:11:19.022+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:19.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:19.069+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:19.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:19.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:11:19.178+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:19.177+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:11:19.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.228 seconds
[2024-05-01T13:11:49.915+0000] {processor.py:161} INFO - Started process (PID=68645) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:49.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:11:49.921+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:49.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:49.968+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:11:50.041+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:50.040+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:11:50.553+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:11:50.552+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:11:50.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.700 seconds
[2024-05-01T13:12:20.849+0000] {processor.py:161} INFO - Started process (PID=68676) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:20.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:12:20.856+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:20.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:20.912+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:20.986+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:20.985+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:12:21.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:21.024+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:12:21.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.240 seconds
[2024-05-01T13:12:51.816+0000] {processor.py:161} INFO - Started process (PID=68707) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:51.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:12:51.822+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:51.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:51.869+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:12:51.939+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:51.938+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:12:52.401+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:12:52.401+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:12:52.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.652 seconds
[2024-05-01T13:13:22.592+0000] {processor.py:161} INFO - Started process (PID=68738) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:22.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:13:22.600+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:22.599+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:23.078+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:23.137+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:23.137+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:13:23.171+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:23.170+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:13:23.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.642 seconds
[2024-05-01T13:13:53.320+0000] {processor.py:161} INFO - Started process (PID=68769) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:53.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:13:53.328+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:53.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:53.392+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:13:53.463+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:53.463+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:13:53.502+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:13:53.501+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:13:53.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.256 seconds
[2024-05-01T13:14:24.134+0000] {processor.py:161} INFO - Started process (PID=68801) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:24.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:14:24.140+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:24.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:24.188+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:24.687+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:24.686+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:14:24.720+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:24.719+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:14:24.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.650 seconds
[2024-05-01T13:14:55.632+0000] {processor.py:161} INFO - Started process (PID=68833) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:55.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:14:55.639+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:55.637+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:55.686+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:14:55.758+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:55.757+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:14:55.807+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:14:55.806+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:14:55.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T13:15:26.047+0000] {processor.py:161} INFO - Started process (PID=68868) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:26.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:15:26.053+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:26.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:26.100+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:26.172+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:26.171+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:15:26.212+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:26.211+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:15:26.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T13:15:56.534+0000] {processor.py:161} INFO - Started process (PID=68898) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:56.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:15:56.542+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:56.541+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:56.589+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:15:56.663+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:56.662+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:15:56.702+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:15:56.701+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:15:56.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.234 seconds
[2024-05-01T13:16:26.986+0000] {processor.py:161} INFO - Started process (PID=68929) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:26.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:16:26.993+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:26.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:27.040+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:27.111+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:27.110+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:16:27.152+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:27.151+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:16:27.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T13:16:57.464+0000] {processor.py:161} INFO - Started process (PID=68961) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:57.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:16:57.471+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:57.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:57.518+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:16:57.592+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:57.592+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:16:57.631+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:16:57.630+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:16:57.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T13:17:27.951+0000] {processor.py:161} INFO - Started process (PID=68992) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:27.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:17:27.960+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:27.959+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:28.015+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:28.108+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:28.108+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:17:28.147+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:28.146+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:17:28.207+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.269 seconds
[2024-05-01T13:17:58.309+0000] {processor.py:161} INFO - Started process (PID=69023) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:58.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:17:58.315+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:58.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:58.410+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:17:58.538+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:58.537+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:17:58.585+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:17:58.584+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:17:58.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.352 seconds
[2024-05-01T13:18:28.892+0000] {processor.py:161} INFO - Started process (PID=69054) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:28.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:18:28.901+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:28.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:28.948+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:29.019+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:29.018+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:18:29.058+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:29.057+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:18:29.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T13:18:59.405+0000] {processor.py:161} INFO - Started process (PID=69085) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:59.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:18:59.412+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:59.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:59.459+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:18:59.536+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:59.536+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:18:59.582+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:18:59.581+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:18:59.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.245 seconds
[2024-05-01T13:19:29.861+0000] {processor.py:161} INFO - Started process (PID=69116) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:19:29.865+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:19:29.868+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:19:29.867+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:19:29.915+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:19:29.987+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:19:29.986+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:19:30.025+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:19:30.024+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:19:30.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.241 seconds
[2024-05-01T13:20:00.302+0000] {processor.py:161} INFO - Started process (PID=69147) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:00.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:20:00.308+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:00.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:00.355+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:00.426+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:00.425+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:20:00.467+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:00.466+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:20:00.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.232 seconds
[2024-05-01T13:20:30.796+0000] {processor.py:161} INFO - Started process (PID=69178) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:30.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:20:30.801+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:30.800+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:30.849+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:20:30.929+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:30.929+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:20:30.970+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:20:30.969+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:20:31.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.242 seconds
[2024-05-01T13:21:01.317+0000] {processor.py:161} INFO - Started process (PID=69209) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:01.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:21:01.324+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:01.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:01.371+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:01.445+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:01.445+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:21:01.484+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:01.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:21:01.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T13:21:31.801+0000] {processor.py:161} INFO - Started process (PID=69240) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:31.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:21:31.806+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:31.805+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:31.853+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:21:31.926+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:31.925+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:21:32.004+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:21:32.002+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:21:32.075+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.283 seconds
[2024-05-01T13:22:02.300+0000] {processor.py:161} INFO - Started process (PID=69272) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:02.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:22:02.306+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:02.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:02.353+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:02.423+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:02.422+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:22:02.461+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:02.460+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:22:02.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T13:22:32.827+0000] {processor.py:161} INFO - Started process (PID=69304) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:32.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:22:32.833+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:32.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:32.880+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:22:32.949+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:32.949+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:22:32.990+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:22:32.990+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:22:33.053+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.235 seconds
[2024-05-01T13:23:03.413+0000] {processor.py:161} INFO - Started process (PID=69335) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:03.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:23:03.419+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:03.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:03.466+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:03.536+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:03.535+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:23:03.574+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:03.573+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:23:03.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.227 seconds
[2024-05-01T13:23:33.941+0000] {processor.py:161} INFO - Started process (PID=69366) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:33.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:23:33.948+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:33.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:34.002+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:23:34.117+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:34.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:23:34.162+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:23:34.162+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:23:34.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.293 seconds
[2024-05-01T13:24:04.525+0000] {processor.py:161} INFO - Started process (PID=69397) to work on /opt/airflow/dags/get_and_load.py
[2024-05-01T13:24:04.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/get_and_load.py for tasks to queue
[2024-05-01T13:24:04.540+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:24:04.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:24:04.591+0000] {processor.py:840} INFO - DAG(s) 'load_data_to_bq' retrieved from /opt/airflow/dags/get_and_load.py
[2024-05-01T13:24:04.674+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:24:04.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2024-05-01T13:24:04.722+0000] {logging_mixin.py:188} INFO - [2024-05-01T13:24:04.721+0000] {dag.py:3834} INFO - Setting next_dagrun for load_data_to_bq to None, run_after=None
[2024-05-01T13:24:04.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/get_and_load.py took 0.275 seconds
